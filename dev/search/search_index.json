{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"rvc2api Documentation","text":"<p>Welcome to the rvc2api documentation. This site provides comprehensive information about the rvc2api project, a Python-based API and WebSocket service for RV-C (Recreational Vehicle Controller Area Network) systems.</p> <p>Documentation Versions</p> <p>You're viewing the documentation for the version displayed in the top navigation bar.</p> <pre><code>- **latest**: Most recent stable release\n- **dev**: Latest development version (main branch)\n- **x.y.z**: Specific released versions\n\nTo switch versions, use the version dropdown in the navigation.\n</code></pre>"},{"location":"#what-is-rvc2api","title":"What is rvc2api?","text":"<p>rvc2api is a modern API for RV-C CANbus systems, allowing you to:</p> <ul> <li>Monitor and control your RV's devices (lights, tanks, thermostats, etc.)</li> <li>Get real-time updates via WebSockets</li> <li>Access a clean and consistent API</li> <li>Use a modern React frontend</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code># Clone the repository\ngit clone https://github.com/carpenike/rvc2api.git &amp;&amp; cd rvc2api\n\n# Install dependencies\npoetry install\ncd web_ui &amp;&amp; npm install\n</code></pre>"},{"location":"#running-the-application","title":"Running the Application","text":"<p>Start the backend:</p> <pre><code>poetry run python src/core_daemon/main.py\n</code></pre> <p>Start the frontend (in a separate terminal):</p> <pre><code>cd web_ui &amp;&amp; npm run dev\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>FastAPI backend: Modern, async API with automatic OpenAPI documentation</li> <li>React frontend: Clean, responsive UI built with TypeScript and Vite</li> <li>WebSocket support: Real-time updates for state changes</li> <li>RV-C decoding: Interpreting and generating CAN bus messages</li> <li>Entity-based API: Unified API surface for all device types</li> </ul>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<p>This documentation is organized into several sections:</p> <ul> <li>Getting Started: Environment setup and development basics</li> <li>API Reference: Comprehensive API documentation</li> <li>API Overview: Structure and organization of the API</li> <li>Entity API: Endpoints for entity management and control</li> <li>WebSocket API: Real-time communication</li> <li>OpenAPI Specification: Auto-generated API documentation</li> <li>Architecture: System design and component organization</li> <li>Backend Architecture: Python API components</li> <li>Frontend Architecture: React UI components</li> <li>Feature Flags: Backend feature flag system and configuration</li> <li>Development Guides: In-depth development instructions</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions to rvc2api! Please see the GitHub repository and read CONTRIBUTING.md for guidelines on how to contribute.</p>"},{"location":"code-quality-tools/","title":"Code Quality Tools","text":"<p>This document outlines the code quality tools used in the <code>rvc2api</code> project.</p>"},{"location":"code-quality-tools/#python-code-quality-tools","title":"Python Code Quality Tools","text":""},{"location":"code-quality-tools/#ruff","title":"Ruff","text":"<p>Ruff is our primary Python linting tool. It's a fast, comprehensive linter written in Rust that replaces Flake8 and many of its plugins.</p>"},{"location":"code-quality-tools/#key-features","title":"Key features","text":"<ul> <li>10-100x faster than Flake8</li> <li>Includes functionality from multiple Flake8 plugins</li> <li>Can automatically fix many issues</li> <li>Import sorting (replacing isort)</li> <li>Configurable through <code>pyproject.toml</code></li> </ul>"},{"location":"code-quality-tools/#usage","title":"Usage","text":"<pre><code># Check your code\npoetry run ruff check .\n\n# Apply auto-fixes\npoetry run ruff check --fix .\n</code></pre>"},{"location":"code-quality-tools/#ruff-format","title":"Ruff Format","text":"<p>Ruff Format is our Python code formatter. It enforces a consistent style by reformatting your code to conform to its rules, similar to Black but integrated with the Ruff toolchain.</p>"},{"location":"code-quality-tools/#key-features_1","title":"Key features","text":"<ul> <li>Deterministic formatting</li> <li>Fast performance</li> <li>Integrated with Ruff linting</li> <li>Compatible with Black-style formatting</li> </ul>"},{"location":"code-quality-tools/#usage_1","title":"Usage","text":"<pre><code># Format your code\npoetry run ruff format src tests\n</code></pre>"},{"location":"code-quality-tools/#pyrightpylance","title":"Pyright/Pylance","text":"<p>Pyright is our standardized static type checker for Python, used in VS Code via the Pylance extension. We've standardized on Pyright as our sole type checker due to its superior performance and integration with modern Python tools.</p>"},{"location":"code-quality-tools/#key-features_2","title":"Key features","text":"<ul> <li>Fast, incremental type checking</li> <li>Excellent IDE integration</li> <li>Strong support for modern Python typing features</li> <li>Better performance for larger codebases</li> <li>Native support for FastAPI and Pydantic type annotations</li> </ul>"},{"location":"code-quality-tools/#usage_2","title":"Usage","text":"<pre><code># Type check your code\nnpx pyright src\n\n# Or in VS Code:\n# Use the built-in type checking with Pylance\n</code></pre>"},{"location":"code-quality-tools/#pre-commit-integration","title":"Pre-commit Integration","text":"<p>These tools are integrated into our pre-commit configuration, ensuring code quality checks run automatically before each commit.</p> <p>To set up pre-commit:</p> <pre><code># Install pre-commit hooks\npoetry run pre-commit install\n</code></pre>"},{"location":"code-quality-tools/#custom-type-stubs","title":"Custom Type Stubs","text":"<p>The project includes custom type stubs in the <code>typings/</code> directory to enhance type checking and IDE support, particularly for third-party libraries.</p>"},{"location":"code-quality-tools/#fastapi-type-stubs","title":"FastAPI Type Stubs","text":"<p>We maintain custom type stubs for FastAPI to provide better typing for WebSocket components and other FastAPI features.</p>"},{"location":"code-quality-tools/#organization","title":"Organization","text":"<ul> <li><code>typings/fastapi/__init__.py</code> - Implementation file with detailed docstrings</li> <li><code>typings/fastapi/__init__.pyi</code> - Type stub file with concise type definitions</li> </ul>"},{"location":"code-quality-tools/#special-configuration","title":"Special Configuration","text":"<p>These files have specific lint exceptions in <code>pyproject.toml</code>:</p> <pre><code>[tool.ruff.lint.per-file-ignores]\n# Allow function names that don't follow snake_case for FastAPI compatibility\n# Also allow exception names without Error suffix to match FastAPI's conventions\n\"typings/fastapi/__init__.py\" = [\"N802\", \"N818\"]\n\"typings/fastapi/__init__.pyi\" = [\"N802\", \"N818\"]\n# Allow relative imports in the typings directory for proper type stub organization\n\"typings/**/*.py\" = [\"TID252\"]\n\"typings/**/*.pyi\" = [\"TID252\"]\n</code></pre> <p>These exceptions allow:</p> <ul> <li>Non-snake_case function names (like <code>Body()</code>) to match FastAPI's API</li> <li>Exception names without the \"Error\" suffix (like <code>WebSocketDisconnect</code>) to match FastAPI's conventions</li> <li>Relative imports in type stub files for proper organization</li> </ul> <p>For more details, see <code>typings/fastapi/README.md</code>.</p>"},{"location":"code-quality-tools/#why-we-chose-these-tools","title":"Why We Chose These Tools","text":"<ul> <li>Ruff over Flake8: Ruff is significantly faster and includes all the functionality of Flake8 plus much more. It also has better integration with modern Python tooling.</li> <li>Ruff Format over Black: Ruff Format provides the same deterministic formatting as Black but is integrated with the Ruff toolchain, offering better performance and consistency with linting rules.</li> <li>Pyright over mypy for type checking: We've standardized on Pyright because it offers excellent performance, strong IDE integration via VS Code's Pylance extension, and better support for modern Python typing features, especially with FastAPI and Pydantic. It also provides faster type checking for large codebases.</li> <li>Custom Type Stubs: For better IDE support and type checking with libraries like FastAPI.</li> </ul>"},{"location":"code-quality-tools/#vs-code-integration","title":"VS Code Integration","text":"<p>VS Code tasks are configured for these tools:</p> <ul> <li>Format Code (Ruff): Formats Python code</li> <li>Lint (Ruff): Runs Ruff linting with fix capability</li> <li>Type Check (Pyright): Performs static type checking</li> </ul>"},{"location":"debian-repository/","title":"Debian Repository","text":"<p>This page provides instructions for using the rvc2api Debian package repository.</p>"},{"location":"debian-repository/#repository-structure","title":"Repository Structure","text":"<p>The Debian repository is hosted on GitHub Pages alongside this documentation. The repository follows standard Debian repository structure:</p> <pre><code>debian-repo/\n\u251c\u2500\u2500 dists/\n\u2502   \u2514\u2500\u2500 stable/\n\u2502       \u251c\u2500\u2500 main/\n\u2502       \u2502   \u251c\u2500\u2500 binary-amd64/\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 Packages\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 Packages.gz\n\u2502       \u2502   \u2514\u2500\u2500 binary-arm64/\n\u2502       \u2502       \u251c\u2500\u2500 Packages\n\u2502       \u2502       \u2514\u2500\u2500 Packages.gz\n\u2502       \u2514\u2500\u2500 Release\n\u2514\u2500\u2500 pool/\n    \u2514\u2500\u2500 main/\n        \u2514\u2500\u2500 r/\n            \u2514\u2500\u2500 rvc2api/\n                \u2514\u2500\u2500 *.deb\n</code></pre>"},{"location":"debian-repository/#adding-the-repository","title":"Adding the Repository","text":"<p>To add the repository to your Debian or Ubuntu system, follow these steps:</p> <pre><code># Add the repository GPG key\ncurl -fsSL https://username.github.io/rvc2api/debian-repo/KEY.gpg | sudo apt-key add -\n\n# Add the repository to your sources list\necho \"deb https://username.github.io/rvc2api/debian-repo stable main\" | sudo tee /etc/apt/sources.list.d/rvc2api.list\n\n# Update package lists\nsudo apt update\n</code></pre> <p>Replace <code>username</code> with the GitHub username or organization hosting the repository.</p>"},{"location":"debian-repository/#installing-packages","title":"Installing Packages","text":"<p>Once the repository is added, you can install packages with:</p> <pre><code>sudo apt install rvc2api\n</code></pre>"},{"location":"debian-repository/#available-packages","title":"Available Packages","text":"Package Name Description Architecture rvc2api RV-C API and WebSocket service amd64, arm64"},{"location":"debian-repository/#version-history","title":"Version History","text":"Version Release Date Changes 0.1.0 TBD Initial release"},{"location":"debian-repository/#building-from-source","title":"Building From Source","text":"<p>If you prefer to build the package from source, refer to the Development Environment documentation.</p> <pre><code>flowchart TD\n    A[Add Repository] --&gt; B[Update Package List]\n    B --&gt; C[Install Package]\n    C --&gt; D[Configure]\n    D --&gt; E[Start Service]\n\n    classDef install fill:#bbdefb,stroke:#1976d2,color:#212121;\n    classDef config fill:#c8e6c9,stroke:#388e3c,color:#212121;\n    classDef run fill:#ffecb3,stroke:#ffa000,color:#212121;\n\n    class A,B,C install;\n    class D config;\n    class E run;</code></pre>"},{"location":"devcontainer-vcan-guide/","title":"Using VSCode Devcontainer with vCAN","text":""},{"location":"devcontainer-vcan-guide/#testing-vcan-communication","title":"Testing vCAN Communication","text":""},{"location":"devcontainer-vcan-guide/#quick-setup-verification","title":"Quick Setup Verification","text":"<p>You can verify your vCAN setup quickly using the <code>test_vcan_setup.py</code> script:</p> <pre><code># Bash\npython dev_tools/test_vcan_setup.py\n\n# Fish\npython dev_tools/test_vcan_setup.py\n</code></pre> <p>This script:</p> <ol> <li>Opens a connection to the vcan0 interface</li> <li>Sends a test message</li> <li>Listens for the message</li> <li>Confirms successful communication</li> </ol>"},{"location":"devcontainer-vcan-guide/#manual-testing","title":"Manual Testing","text":"<p>For more detailed testing, you can use the <code>test_vcan.py</code> script in the <code>dev_tools</code> directory:</p>"},{"location":"devcontainer-vcan-guide/#sending-test-messages","title":"Sending Test Messages","text":"<pre><code>python dev_tools/test_vcan.py --action send --interface vcan0 --count 5 --interval 0.5\n</code></pre>"},{"location":"devcontainer-vcan-guide/#monitoring-can-messages","title":"Monitoring CAN Messages","text":"<pre><code>python dev_tools/test_vcan.py --action monitor --interface vcan0 --duration 60\n</code></pre> <p>For more comprehensive testing, open two terminal windows in VS Code:</p> <ol> <li>In one terminal, run the monitoring command</li> <li>In another terminal, run the sending commando use the devcontainer setup to develop and test the RVC2API project with virtual CAN bus support.</li> </ol>"},{"location":"devcontainer-vcan-guide/#prerequisites","title":"Prerequisites","text":"<ol> <li>VSCode installed</li> <li>Docker installed</li> <li>Colima installed (for macOS)</li> <li>Dev Containers Extension installed in VSCode</li> </ol>"},{"location":"devcontainer-vcan-guide/#setting-up-colima-with-vcan","title":"Setting Up Colima with vCAN","text":"<p>We've streamlined the setup process by integrating vCAN setup into the Colima setup script:</p> <pre><code>.devcontainer/setup-colima.sh\n</code></pre> <p>This script will:</p> <ol> <li>Install or configure Colima with proper resources</li> <li>Set up Docker context</li> <li>Install and configure vCAN interfaces in the VM</li> <li>Create systemd services to ensure vCAN interfaces persist on VM restart</li> </ol>"},{"location":"devcontainer-vcan-guide/#opening-the-project-in-a-devcontainer","title":"Opening the Project in a Devcontainer","text":"<ol> <li>Open VSCode</li> <li>Open the command palette (Cmd+Shift+P or Ctrl+Shift+P)</li> <li>Run \"Dev Containers: Open Folder in Container...\"</li> <li>Select your rvc2api project folder</li> </ol> <p>VSCode will build and start the container, which may take a few minutes on first run.</p>"},{"location":"devcontainer-vcan-guide/#verifying-vcan-setup","title":"Verifying vCAN Setup","text":"<p>Once the devcontainer is running, you can verify the vCAN interfaces:</p> <pre><code># Check if vcan interfaces are set up\nip link show vcan0\nip link show vcan1\n</code></pre>"},{"location":"devcontainer-vcan-guide/#testing-vcan-communication_1","title":"Testing vCAN Communication","text":"<p>You can use the <code>test_vcan.py</code> script in the <code>dev_tools</code> directory to test vCAN communication:</p>"},{"location":"devcontainer-vcan-guide/#sending-test-messages_1","title":"Sending Test Messages","text":"<pre><code>python dev_tools/test_vcan.py --action send --interface vcan0 --count 5 --interval 0.5\n</code></pre>"},{"location":"devcontainer-vcan-guide/#monitoring-can-messages_1","title":"Monitoring CAN Messages","text":"<pre><code>python dev_tools/test_vcan.py --action monitor --interface vcan0 --duration 60\n</code></pre> <p>For more comprehensive testing, open two terminal windows in VSCode:</p> <ol> <li>In one terminal, run the monitoring command</li> <li>In another terminal, run the sending command</li> </ol>"},{"location":"devcontainer-vcan-guide/#running-the-rvc2api-backend","title":"Running the RVC2API Backend","text":"<pre><code># Make sure the current directory is the project root\ncd /workspace\n\n# Copy the devcontainer environment variables\ncp .env.devcontainer .env\n\n# Start the backend server\npoetry run python src/core_daemon/main.py\n</code></pre>"},{"location":"devcontainer-vcan-guide/#running-the-frontend","title":"Running the Frontend","text":"<p>In another terminal:</p> <pre><code>cd /workspace/web_ui\nnpm run dev\n</code></pre>"},{"location":"devcontainer-vcan-guide/#automated-setup-with-scripts","title":"Automated Setup with Scripts","text":"<p>The project includes scripts to automate the setup of vcan interfaces:</p>"},{"location":"devcontainer-vcan-guide/#host-machine-setup-macos-with-colima","title":"Host Machine Setup (macOS with Colima)","text":"<p>Run the provided setup script:</p> <pre><code>./scripts/setup_colima_vcan.sh\n</code></pre> <p>This script will:</p> <ul> <li>SSH into your Colima VM</li> <li>Install necessary Linux headers</li> <li>Load the vcan kernel module</li> <li>Create vcan0 and vcan1 interfaces</li> <li>Configure systemd service for automatic vcan setup on VM restart</li> </ul>"},{"location":"devcontainer-vcan-guide/#devcontainer-setup","title":"Devcontainer Setup","text":"<p>Inside the devcontainer, you can verify and create vcan interfaces with:</p> <pre><code>./scripts/ensure_vcan_interfaces.sh\n</code></pre> <p>This script will:</p> <ul> <li>Check if vcan module is loaded</li> <li>Create vcan0 and vcan1 interfaces if missing</li> <li>Ensure interfaces are up and running</li> <li>Install can-utils tools if missing</li> </ul>"},{"location":"devcontainer-vcan-guide/#using-vs-code-tasks","title":"Using VS Code Tasks","text":"<p>The following VS Code tasks are available for vcan setup and testing:</p> <ol> <li>System: Setup Colima vcan - Run from host machine to set up Colima VM</li> <li>System: Ensure vcan Interfaces - Run inside devcontainer to verify/create interfaces</li> <li>System: Test vCAN Setup - Test the vcan interfaces by sending and receiving a message</li> </ol> <p>To run these tasks:</p> <ol> <li>Press <code>Cmd+Shift+P</code> (macOS) or <code>Ctrl+Shift+P</code> (Windows/Linux)</li> <li>Type \"Tasks: Run Task\" and select it</li> <li>Choose one of the vCAN-related tasks from the list</li> </ol>"},{"location":"devcontainer-vcan-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"devcontainer-vcan-guide/#diagnosing-vcan-issues","title":"Diagnosing vCAN Issues","text":"<p>Run the diagnostic script to check for common vCAN issues:</p> <pre><code>./.devcontainer/diagnose-vcan.sh\n</code></pre>"},{"location":"devcontainer-vcan-guide/#vcan-module-not-available","title":"vCAN Module Not Available","text":"<p>If you encounter issues with the vCAN module not being available, check if the kernel module is loaded:</p> <pre><code>lsmod | grep vcan\n</code></pre> <p>If it's not available, it could be due to limitations in the VM kernel used by Colima. In this case:</p> <ol> <li>Exit the devcontainer</li> <li>Stop Colima: <code>colima stop</code></li> <li>Try starting Colima with a different VM provider: <code>colima start --vm-type qemu</code></li> <li>Run the setup script: <code>./scripts/setup_colima_vcan.sh</code></li> <li>Open the devcontainer again</li> </ol>"},{"location":"development-environments/","title":"Development Environment Setup for rvc2api","text":"<p>This document outlines multiple approaches for setting up development environments for the rvc2api project.</p>"},{"location":"development-environments/#option-1-using-nix-development-shell-recommended","title":"Option 1: Using Nix Development Shell (Recommended)","text":"<p>The project includes a Nix flake that provides a fully configured development environment with all dependencies.</p>"},{"location":"development-environments/#prerequisites","title":"Prerequisites","text":"<ul> <li>Nix package manager with flakes enabled</li> </ul>"},{"location":"development-environments/#setup","title":"Setup","text":"<ol> <li>Enter the development shell:</li> </ol> <pre><code>nix develop\n</code></pre> <ol> <li> <p>This provides:</p> </li> <li> <p>Python with all project dependencies</p> </li> <li>Node.js for the frontend</li> <li>Poetry for Python package management</li> <li> <p>All necessary development tools</p> </li> <li> <p>Start developing:</p> </li> <li>Backend: <code>poetry run python src/core_daemon/main.py</code></li> <li>Frontend: <code>cd web_ui &amp;&amp; npm run dev</code></li> </ol>"},{"location":"development-environments/#benefits","title":"Benefits","text":"<ul> <li>Reproducible environment across all developers</li> <li>Exact versions of all dependencies are locked</li> <li>Works on any system where Nix is installed</li> <li>No global pollution of your system</li> </ul>"},{"location":"development-environments/#option-2-using-poetry2nix","title":"Option 2: Using poetry2nix","text":"<p>The project includes experimental support for poetry2nix, which offers more integrated management of Python dependencies within the Nix ecosystem.</p> <p>See Poetry2Nix Integration for setup instructions.</p>"},{"location":"development-environments/#option-3-using-poetry-directly","title":"Option 3: Using Poetry Directly","text":"<p>If you don't want to use Nix, you can use Poetry directly to manage the Python environment.</p>"},{"location":"development-environments/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>Python 3.12 or later</li> <li>Poetry</li> <li>Node.js (for frontend development)</li> </ul>"},{"location":"development-environments/#setup_1","title":"Setup","text":"<ol> <li>Install Python dependencies:</li> </ol> <pre><code>poetry install\n</code></pre> <ol> <li>Install frontend dependencies:</li> </ol> <pre><code>cd web_ui &amp;&amp; npm install\n</code></pre> <ol> <li>Start the backend server:</li> </ol> <pre><code>poetry run python src/core_daemon/main.py\n</code></pre> <ol> <li>Start the frontend development server:</li> </ol> <pre><code>cd web_ui &amp;&amp; npm run dev\n</code></pre>"},{"location":"development-environments/#vs-code-integration","title":"VS Code Integration","text":"<p>The repository includes VS Code configuration files to make development easier:</p> <ul> <li>Tasks for common operations</li> <li>Launch configurations for debugging</li> <li>Recommended extensions</li> </ul> <p>To use these features:</p> <ol> <li>Open the project in VS Code</li> <li>Press <code>Ctrl+Shift+P</code> (or <code>Cmd+Shift+P</code> on macOS) and search for \"Tasks: Run Task\"</li> <li>Choose from available tasks like:</li> <li>Start Backend Server</li> <li>Start Frontend Dev Server</li> <li>Run Tests</li> <li>Format Code (Ruff)</li> <li>Lint (Ruff)</li> </ol>"},{"location":"development-environments/#environment-variables","title":"Environment Variables","text":"<p>The application uses the following environment variables which you may need to set for development:</p>"},{"location":"development-environments/#basic-configuration","title":"Basic Configuration","text":"<ul> <li><code>LOG_LEVEL</code>: Logging level (default: \"INFO\")</li> <li><code>RVC2API_TITLE</code>: API title (default: \"rvc2api\")</li> <li><code>RVC2API_SERVER_DESCRIPTION</code>: API description (default: \"RV-C to API Bridge\")</li> <li><code>RVC2API_ROOT_PATH</code>: Root path for API URLs (default: \"\")</li> </ul>"},{"location":"development-environments/#can-bus-configuration","title":"CAN Bus Configuration","text":"<ul> <li><code>CAN_CHANNELS</code>: Comma-separated list of CAN interfaces (default: \"can0,can1\")</li> <li><code>CAN_BUSTYPE</code>: CAN bus type (default: \"socketcan\")</li> <li><code>CAN_BITRATE</code>: CAN bus bitrate (default: \"500000\")</li> </ul>"},{"location":"development-environments/#integrations","title":"Integrations","text":"<ul> <li><code>ENABLE_PUSHOVER</code>: Enable Pushover notifications (default: \"0\")</li> <li><code>PUSHOVER_API_TOKEN</code>: Pushover API token</li> <li><code>PUSHOVER_USER_KEY</code>: Pushover user key</li> <li><code>PUSHOVER_DEVICE</code>: Pushover device name (optional)</li> <li><code>PUSHOVER_PRIORITY</code>: Pushover message priority (optional)</li> <li><code>ENABLE_UPTIMEROBOT</code>: Enable UptimeRobot integration (default: \"0\")</li> <li><code>UPTIMEROBOT_API_KEY</code>: UptimeRobot API key</li> </ul>"},{"location":"development-environments/#file-paths","title":"File Paths","text":"<ul> <li><code>CAN_SPEC_PATH</code>: Override path to RV-C specification file</li> <li><code>CAN_MAP_PATH</code>: Override path to device mapping file</li> <li><code>RVC2API_USER_COACH_INFO_PATH</code>: Path to user coach info YAML file</li> </ul>"},{"location":"development-environments/#model-context-protocol-tools","title":"Model Context Protocol Tools","text":"<p>For enhanced code exploration and understanding, the project is configured to work with Model Context Protocol (MCP) tools:</p> <ul> <li>See MCP Tools Setup for more information.</li> </ul>"},{"location":"docs-versioning-fixes/","title":"Documentation Versioning Fixes","text":"<p>This document provides information about fixes applied to the documentation versioning system.</p>"},{"location":"docs-versioning-fixes/#standardized-bash-scripts-and-pyprojecttoml","title":"Standardized Bash Scripts and pyproject.toml","text":"<p>To improve compatibility and standardize the project, the documentation versioning scripts have been converted from fish shell to bash, and the source of truth for version information has been moved from the <code>VERSION</code> file to <code>pyproject.toml</code>.</p>"},{"location":"docs-versioning-fixes/#1-bash-compatible-scripts","title":"1. Bash-Compatible Scripts","text":"<p>We've converted all scripts to standard bash syntax for better cross-platform compatibility:</p> <pre><code># New standard bash script\n#!/usr/bin/env bash\n\n# Get the current version from pyproject.toml\nfunction get_version() {\n    # Extract version from pyproject.toml using grep and cut\n    version=$(grep -m 1 \"^version\" pyproject.toml | cut -d= -f2 | tr -d ' \"')\n    echo \"$version\"\n}\n</code></pre>"},{"location":"docs-versioning-fixes/#2-using-pyprojecttoml-as-source-of-truth","title":"2. Using pyproject.toml as Source of Truth","text":"<p>Instead of relying on a separate <code>VERSION</code> file, we now extract the version directly from <code>pyproject.toml</code>:</p> <pre><code># Extract version from pyproject.toml\ncurrent_version=$(grep -m 1 \"^version\" pyproject.toml | cut -d= -f2 | tr -d ' \"')\n</code></pre>"},{"location":"docs-versioning-fixes/#3-mike-command-flags","title":"3. Mike Command Flags","text":"<p>The <code>--rebase</code> flag was causing issues with the <code>mike</code> command. We've removed it to ensure compatibility:</p> <pre><code># Original problematic command\npoetry run mike deploy --push --rebase $version\n\n# Fixed command\npoetry run mike deploy --push \"$current_version\"\n</code></pre>"},{"location":"docs-versioning-fixes/#4-vs-code-tasks","title":"4. VS Code Tasks","text":"<p>The VS Code tasks have been updated to use standard bash syntax:</p> <pre><code>{\n  \"label\": \"Docs: Deploy Current Version\",\n  \"command\": \"cd ${workspaceFolder} &amp;&amp; ./scripts/docs_version.sh deploy\"\n}\n</code></pre>"},{"location":"docs-versioning-fixes/#how-to-use-the-new-scripts","title":"How to Use the New Scripts","text":""},{"location":"docs-versioning-fixes/#setup-initial-versioning","title":"Setup Initial Versioning","text":"<p>If you're setting up versioning for the first time:</p> <pre><code>./scripts/setup_versioned_docs.sh\n</code></pre> <p>This script:</p> <ol> <li>Generates the OpenAPI schema</li> <li>Creates the gh-pages branch if it doesn't exist</li> <li>Deploys the current version (from pyproject.toml)</li> <li>Deploys the development version</li> <li>Sets the current version as default</li> </ol>"},{"location":"docs-versioning-fixes/#day-to-day-versioning-tasks","title":"Day-to-Day Versioning Tasks","text":"<p>For regular versioning tasks, use the helper script:</p> <pre><code># View all available versions\n./scripts/docs_version.sh list\n\n# Deploy the current version\n./scripts/docs_version.sh deploy\n\n# Serve the versioned documentation locally\n./scripts/docs_version.sh serve\n</code></pre>"},{"location":"docs-versioning-fixes/#vs-code-tasks","title":"VS Code Tasks","text":"<p>VS Code tasks have been updated to use the standardized bash scripts:</p> <ul> <li>Docs: Serve Versioned Documentation: Start a local mike server</li> <li>Docs: List Versions: List all deployed versions</li> <li>Docs: Deploy Current Version: Deploy using the version in pyproject.toml</li> <li>Docs: Set Default Version: Set the version in pyproject.toml as default</li> <li>Docs: Deploy Dev Version: Deploy the current state as \"dev\"</li> </ul>"},{"location":"docs-versioning-fixes/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<p>The GitHub Actions workflow has been updated to remove the <code>--rebase</code> flag and to extract the version from pyproject.toml when needed:</p> <pre><code># Set version from tag, input, or pyproject.toml\nif [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ] &amp;&amp; [ -n \"${{ github.event.inputs.version }}\" ]; then\n  # Use manually specified version from workflow dispatch\n  VERSION=\"${{ github.event.inputs.version }}\"\nelif [ \"${{ github.event_name }}\" != \"workflow_dispatch\" ]; then\n  # Extract version from tag\n  VERSION=${GITHUB_REF#refs/tags/v}\nelse\n  # Extract from pyproject.toml as fallback\n  VERSION=$(grep -m 1 \"^version\" pyproject.toml | cut -d= -f2 | tr -d ' \"')\nfi\n</code></pre>"},{"location":"docs-versioning-fixes/#integration-with-release-please","title":"Integration with release-please","text":"<p>The versioning system now integrates seamlessly with release-please:</p> <ol> <li>release-please updates the version in <code>pyproject.toml</code></li> <li>The documentation versioning scripts read from <code>pyproject.toml</code></li> <li>When a new release is created by release-please, the versioned documentation is automatically published</li> </ol>"},{"location":"docs-versioning-fixes/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter any issues:</p> <ol> <li>Permission denied when executing scripts: Make sure the scripts are executable: <code>chmod +x scripts/docs_version.sh scripts/setup_versioned_docs.sh</code></li> <li> <p>Error extracting version from pyproject.toml: Ensure the version is properly formatted in pyproject.toml with <code>version = \"x.y.z\"</code> format</p> </li> <li> <p>Error with the --rebase flag: Remove this flag from mike commands.</p> </li> <li> <p>GitHub Pages branch issues: Make sure you've run the setup script correctly and have appropriate permissions to push to gh-pages.</p> </li> <li> <p>Command sequence in fish shell: Use <code>and</code> instead of <code>&amp;&amp;</code> when you want to chain commands in a VS Code task for fish shell.</p> </li> </ol> <p>See Verifying Versioned Documentation for more troubleshooting steps.</p>"},{"location":"documentation-organization/","title":"Documentation Organization Guide","text":"<p>The rvc2api documentation is organized into two main sections: User Guide and Developer Guide. This structure helps different audiences find the information most relevant to their needs.</p> <pre><code>graph TD\n    Root[rvc2api Documentation] --&gt; User[User Guide]\n    Root --&gt; Dev[Developer Guide]\n    Root --&gt; Updates[Project Updates]\n    Root --&gt; Specs[Specifications]\n\n    User --&gt; UserGS[Getting Started]\n    User --&gt; UserArch[System Architecture]\n    User --&gt; UserAPI[API Reference]\n    User --&gt; UserRVC[RV-C Integration]\n    User --&gt; UserDeploy[Deployment]\n\n    Dev --&gt; DevArch[Architecture Details]\n    Dev --&gt; DevGuides[Development Guides]\n    Dev --&gt; DevQA[Quality Assurance]\n    Dev --&gt; DevBuild[Build System]\n    Dev --&gt; DevContrib[Contributing]\n\n    classDef user fill:#C8E6C9,stroke:#4CAF50\n    classDef dev fill:#BBDEFB,stroke:#2196F3\n    classDef meta fill:#FFECB3,stroke:#FFC107\n\n    class User,UserGS,UserArch,UserAPI,UserRVC,UserDeploy user\n    class Dev,DevArch,DevGuides,DevQA,DevBuild,DevContrib dev\n    class Updates,Specs,Root meta</code></pre>"},{"location":"documentation-organization/#user-guide","title":"User Guide","text":"<p>The User Guide is designed for users who want to deploy, configure, and use rvc2api. It focuses on:</p> <ul> <li>Getting started with the project</li> <li>High-level architecture overview</li> <li>API usage and integration</li> <li>RV-C protocol integration</li> <li>Deployment options</li> </ul> <p>This section answers questions like:</p> <ul> <li>\"How do I set up rvc2api?\"</li> <li>\"What APIs are available?\"</li> <li>\"How do I deploy this to my system?\"</li> <li>\"How does this integrate with my RV's systems?\"</li> </ul>"},{"location":"documentation-organization/#developer-guide","title":"Developer Guide","text":"<p>The Developer Guide is for contributors and developers working on extending or modifying rvc2api. It includes:</p> <ul> <li>Detailed architecture explanations</li> <li>Development workflows and practices</li> <li>Code quality standards and tools</li> <li>Build system details</li> <li>Contribution guidelines</li> </ul> <p>This section answers questions like:</p> <ul> <li>\"How is the code structured?\"</li> <li>\"What development tools should I use?\"</li> <li>\"How do I ensure my code meets project standards?\"</li> <li>\"What's the process for submitting changes?\"</li> </ul>"},{"location":"documentation-organization/#project-updates-and-specifications","title":"Project Updates and Specifications","text":"<p>Additionally, the documentation includes:</p> <ul> <li>Project Updates: Information about recent changes to the project</li> <li>Specifications: Detailed design specifications for major features</li> </ul>"},{"location":"documentation-organization/#target-audience","title":"Target Audience","text":"<p>When adding new documentation, consider your target audience:</p> If documenting... Add to... Focus on... API usages User Guide Clear examples and use cases Deployment options User Guide Step-by-step instructions Code architecture Developer Guide Design patterns and code organization Development workflows Developer Guide Tools and processes Major features Specifications Design decisions and implementation details"},{"location":"documentation-organization/#style-guidelines","title":"Style Guidelines","text":"<ul> <li>User Guide: Focus on clarity, examples, and step-by-step instructions</li> <li>Developer Guide: Include technical details, architecture decisions, and code examples</li> <li>All Documentation: Use visual diagrams (with Mermaid) to illustrate complex concepts</li> </ul>"},{"location":"documentation-updates-summary/","title":"Documentation Organization Changes","text":""},{"location":"documentation-updates-summary/#changes-implemented","title":"Changes Implemented","text":"<ol> <li> <p>Fixed MCP Tools formatting issues:</p> </li> <li> <p>Corrected formatting in <code>mcp-tools.instructions.md</code></p> </li> <li> <p>Resolved conflicting text and improper code block closure</p> </li> <li> <p>Consolidated VS Code tasks information:</p> </li> <li> <p>Removed detailed VS Code tasks from <code>dev-environment.instructions.md</code></p> </li> <li>Added reference to the dedicated <code>vscode-tasks.instructions.md</code> file</li> <li> <p>Ensured consistent task references across documentation</p> </li> <li> <p>Created dedicated style guide files:</p> </li> <li> <p>Added <code>python-code-style.instructions.md</code> with comprehensive Python styling guidelines</p> </li> <li>Added <code>typescript-code-style.instructions.md</code> with TypeScript/React styling guidelines</li> <li>Clearly distinguished between style guides (coding patterns) and configuration files (tooling setup)</li> <li> <p>Both style guide files follow the same structure for consistency</p> </li> <li> <p>Added cross-references between related files:</p> </li> <li> <p>Added \"See Also\" sections to Python backend, React frontend, style guides</p> </li> <li>Linked related documentation within each file</li> <li> <p>Improved navigation between related instruction files</p> </li> <li> <p>Updated the instructions README:</p> </li> <li> <p>Reorganized into logical categories (Architecture, Code Style, Workflow, etc.)</p> </li> <li>Added MCP tools integration section</li> <li> <p>Added VS Code tasks integration section</p> </li> <li> <p>Enhanced the main README:</p> </li> <li> <p>Added more detailed information about development tools</p> </li> <li>Emphasized the importance of using Context7 first</li> <li> <p>Added links to new documentation files</p> </li> <li> <p>Updated docs/enhanced-dev-environment.md:</p> </li> <li> <p>Added references to the new instruction files</p> </li> <li> <p>Organized links by category</p> </li> <li> <p>Updated docs/mcp-tools-setup.md:</p> </li> <li>Added best practices section with clear examples</li> <li>Incorporated \"When to Prioritize Context7\" section</li> <li>Added links to related documentation</li> </ol>"},{"location":"documentation-updates-summary/#organization-structure","title":"Organization Structure","text":"<p>The documentation is now organized in a more logical structure:</p> <ol> <li> <p>Core Architecture:</p> </li> <li> <p>project-overview.instructions.md</p> </li> <li>python-backend.instructions.md</li> <li> <p>react-frontend.instructions.md</p> </li> <li> <p>Code Style and Quality:</p> </li> <li> <p>python-code-style.instructions.md</p> </li> <li>typescript-code-style.instructions.md</li> <li>eslint-typescript-config.instructions.md</li> <li> <p>code-style.instructions.md (legacy)</p> </li> <li> <p>Development Workflow:</p> </li> <li> <p>dev-environment.instructions.md</p> </li> <li>vscode-tasks.instructions.md</li> <li>testing.instructions.md</li> <li> <p>pull-requests.instructions.md</p> </li> <li> <p>Tools and Configuration:</p> </li> <li> <p>mcp-tools.instructions.md</p> </li> <li> <p>env-vars.instructions.md</p> </li> <li> <p>Legacy Documentation:</p> </li> <li>webui.instructions.md</li> </ol>"},{"location":"documentation-updates-summary/#benefits","title":"Benefits","text":"<ol> <li>Reduced redundancy: Eliminated duplicate information</li> <li>Better navigation: Added cross-references between related files</li> <li>Consistent structure: Style guide files follow the same pattern</li> <li>Clear organization: Files grouped by logical categories</li> <li>Improved MCP guidance: Clearer emphasis on using Context7 first</li> <li>Balanced coverage: Equal treatment of frontend and backend documentation</li> <li>Complementary documentation: Maintained both <code>typescript-code-style.instructions.md</code> and <code>eslint-typescript-config.instructions.md</code> files with clear distinctions:</li> <li>Style guide focuses on coding patterns and practices</li> <li>Config file focuses on tooling setup and troubleshooting</li> </ol>"},{"location":"documentation-versioning-update/","title":"Documentation Versioning Updates","text":"<p>This document summarizes the changes made to the documentation versioning system.</p>"},{"location":"documentation-versioning-update/#changes-made","title":"Changes Made","text":"<ol> <li> <p>Bash Scripts: Converted fish-specific scripts to standard bash scripts for broader compatibility:</p> </li> <li> <p><code>scripts/docs_version.fish</code> \u2192 <code>scripts/docs_version.sh</code></p> </li> <li> <p><code>scripts/setup_versioned_docs.fish</code> \u2192 <code>scripts/setup_versioned_docs.sh</code></p> </li> <li> <p>Source of Truth: Changed the source of truth for version information:</p> </li> <li> <p>From: <code>VERSION</code> file</p> </li> <li> <p>To: <code>pyproject.toml</code> (where release-please already updates the version)</p> </li> <li> <p>GitHub Actions: Updated workflows to read version from pyproject.toml when needed:</p> </li> <li> <p>Added pyproject.toml version extraction to <code>deploy-versioned-docs.yml</code></p> </li> <li> <p>Removed <code>--rebase</code> flag from mike commands in <code>deploy-docs.yml</code></p> </li> <li> <p>VS Code Tasks: Updated VS Code tasks to use the new bash scripts:</p> </li> <li> <p>Added tasks for common documentation versioning operations</p> </li> <li>All tasks now indirectly read version from pyproject.toml</li> <li> <p>Made sure all Python-related tasks use poetry</p> </li> <li> <p>Error Handling: Fixed error output and broken pipe issues:</p> </li> <li> <p>Added proper error handling in bash scripts</p> </li> <li>Redirected stderr to suppress broken pipe errors</li> <li> <p>Added <code>set -e</code> and <code>set -o pipefail</code> for better error handling</p> </li> <li> <p>Documentation: Updated documentation to reflect these changes:</p> </li> <li>Updated <code>docs-versioning-fixes.md</code></li> <li>Updated <code>versioning-with-release-please.md</code></li> </ol>"},{"location":"documentation-versioning-update/#benefits","title":"Benefits","text":"<ol> <li> <p>Single Source of Truth: Version information is now stored only in pyproject.toml, eliminating the need to keep multiple files in sync.</p> </li> <li> <p>Better Integration with release-please: When release-please updates the version, the documentation versioning system automatically picks it up.</p> </li> <li> <p>Cross-Platform Compatibility: Standard bash scripts work in more environments than fish-specific scripts.</p> </li> <li> <p>Unified Version Management: Using the VERSION file as the single source of truth simplifies version management.</p> </li> </ol>"},{"location":"documentation-versioning-update/#testing","title":"Testing","text":"<p>The new scripts have been tested and work correctly:</p> <ul> <li><code>./scripts/docs_version.sh list</code> shows the available documentation versions</li> <li>The scripts correctly extract the version from the VERSION file</li> <li>VS Code tasks work properly with the new scripts</li> </ul>"},{"location":"documentation-versioning-update/#next-steps","title":"Next Steps","text":"<ol> <li> <p>Remove the Old Fish Scripts: Once everyone has migrated to the new bash scripts, we can remove the old fish scripts.</p> </li> <li> <p>\u2705 VERSION File Implementation: The VERSION file is now the single source of truth for version information.</p> </li> <li> <p>Update Documentation: Make sure all documentation references the new approach.</p> </li> <li> <p>Communicate the Change: Let contributors know about the change to using the VERSION file as the source of truth for version information.</p> </li> </ol>"},{"location":"enabling-github-pages/","title":"Enabling GitHub Pages","text":"<p>This guide provides step-by-step instructions for enabling GitHub Pages in your repository settings.</p>"},{"location":"enabling-github-pages/#prerequisites","title":"Prerequisites","text":"<p>Before enabling GitHub Pages, ensure you have:</p> <ol> <li>A GitHub repository with documentation in the <code>docs/</code> directory</li> <li>MkDocs configured with <code>mkdocs.yml</code> in the repository root</li> <li>GitHub Actions workflows for deploying docs (already included in this repository)</li> </ol>"},{"location":"enabling-github-pages/#steps-to-enable-github-pages","title":"Steps to Enable GitHub Pages","text":"<ol> <li>Go to your repository on GitHub</li> </ol> <p>Navigate to https://github.com/carpenike/rvc2api</p> <ol> <li>Open Repository Settings</li> </ol> <p>Click the \"Settings\" tab near the top of the page</p> <p></p> <ol> <li>Navigate to Pages Settings</li> </ol> <p>In the left sidebar, click on \"Pages\"</p> <p></p> <ol> <li>Configure Build and Deployment Source</li> </ol> <p>Under \"Build and deployment\", for the \"Source\" option, select \"GitHub Actions\"</p> <p></p> <ol> <li>Trigger Initial Deployment</li> </ol> <p>Go to the \"Actions\" tab of your repository and run the \"Deploy Documentation\" workflow:</p> <ul> <li>Click on \"Actions\"</li> <li>Find \"Deploy Documentation\" workflow</li> <li>Click \"Run workflow\" button</li> <li>Select the branch (usually \"main\")</li> <li> <p>Click \"Run workflow\" to confirm</p> </li> <li> <p>Verify Deployment</p> </li> </ul> <p>After the workflow completes successfully:</p> <ul> <li>Return to Settings \u2192 Pages</li> <li>You should see a message saying \"Your site is published at https://username.github.io/rvc2api/\"</li> <li>Click on the URL to verify the documentation is properly deployed</li> </ul>"},{"location":"enabling-github-pages/#add-custom-domain-optional","title":"Add Custom Domain (Optional)","text":"<p>To use a custom domain instead of the default github.io domain:</p> <ol> <li>Update CNAME File</li> </ol> <p>Edit the <code>docs/CNAME</code> file and uncomment/add your domain:</p> <pre><code>docs.example.com\n</code></pre> <ol> <li>Configure DNS Settings</li> </ol> <p>Add the following DNS records with your domain registrar:</p> <ul> <li>For an apex domain (example.com):<ul> <li>A records pointing to GitHub Pages IP addresses:</li> <li>185.199.108.153</li> <li>185.199.109.153</li> <li>185.199.110.153</li> <li>185.199.111.153</li> </ul> </li> <li> <p>For a subdomain (docs.example.com):</p> <ul> <li>CNAME record pointing to <code>username.github.io</code></li> </ul> </li> <li> <p>Configure Custom Domain in GitHub</p> </li> </ul> <p>In your repository settings under Pages:</p> <ul> <li>Enter your custom domain in the \"Custom domain\" field</li> <li>Click \"Save\"</li> <li>Check \"Enforce HTTPS\" (recommended)</li> </ul>"},{"location":"enabling-github-pages/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Changes Not Reflecting: Check the Actions tab for any workflow failures</li> <li>Custom Domain Not Working: Verify DNS propagation using <code>dig</code> or an online DNS lookup tool</li> <li>HTTPS Issues: Ensure DNS is properly configured and wait up to 24 hours for the certificate to be issued</li> </ul>"},{"location":"enhanced-dev-environment/","title":"Enhanced Development Environment for rvc2api","text":"<p>This update introduces several improvements to the development environment for the rvc2api project:</p>"},{"location":"enhanced-dev-environment/#1-vs-code-tasks-integration","title":"1. VS Code Tasks Integration","text":"<p>A comprehensive set of VS Code tasks has been added to streamline development workflows:</p> <ul> <li> <p>Backend Development</p> </li> <li> <p>Start Backend Server</p> </li> <li>Run Tests</li> <li>Format Code (Ruff)</li> <li> <p>Lint (Ruff)</p> </li> <li> <p>Frontend Development</p> </li> <li> <p>Start Frontend Dev Server</p> </li> <li> <p>Build Frontend</p> </li> <li> <p>Integrated Development</p> </li> <li> <p>Start Full Development Environment (backend + frontend)</p> </li> <li> <p>Nix Integration</p> </li> <li> <p>Enter Nix Development Shell</p> </li> <li> <p>MCP Tools</p> </li> <li>Restart MCP - context7 Server</li> <li>MCP Tools Status</li> </ul>"},{"location":"enhanced-dev-environment/#2-poetry2nix-integration-proposed","title":"2. poetry2nix Integration (Proposed)","text":"<p>A poetry2nix integration has been proposed to improve the connection between Poetry and Nix:</p> <ul> <li>Single source of truth for dependencies in <code>pyproject.toml</code></li> <li>Improved reproducibility between development and production</li> <li>Better handling of Python package dependencies</li> </ul> <p>See the following resources for implementation details:</p> <ul> <li>Comprehensive guide: <code>docs/poetry2nix-integration.md</code></li> <li>Example implementation: <code>flake.nix.poetry2nix</code></li> </ul>"},{"location":"enhanced-dev-environment/#3-mcp-tools-documentation","title":"3. MCP Tools Documentation","text":"<p>Documentation on how to use MCP tools (Model Context Protocol) for AI-assisted development:</p> <ul> <li>Setup instructions for @context7, @perplexity, and @github tools</li> <li>Usage examples for each tool</li> <li>Troubleshooting common issues</li> </ul> <p>See <code>docs/mcp-tools-setup.md</code> for details.</p>"},{"location":"enhanced-dev-environment/#4-vs-code-extensions-integration","title":"4. VS Code Extensions Integration","text":"<p>A comprehensive set of VS Code extensions has been recommended for the project:</p> <ul> <li>Python Development: Python, Pylance, Black, Ruff, FastAPI snippets, etc.</li> <li>Nix Development: Nix IDE, environment selector, direnv integration</li> <li>Frontend Development: ESLint, Prettier, Tailwind CSS, React snippets, etc.</li> <li>General Tools: GitHub Copilot, YAML, JSON5, etc.</li> </ul> <p>See <code>docs/vscode-extensions.md</code> for a detailed list and descriptions.</p>"},{"location":"enhanced-dev-environment/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Install Recommended VS Code Extensions</p> </li> <li> <p>Press <code>Cmd+Shift+P</code> (macOS) or <code>Ctrl+Shift+P</code> (Windows/Linux)</p> </li> <li>Choose \"Extensions: Show Recommended Extensions\"</li> <li>Install the recommended extensions</li> <li> <p>See <code>docs/vscode-extensions.md</code> for details on each extension</p> </li> <li> <p>Use VS Code Tasks</p> </li> <li> <p>Press <code>Cmd+Shift+P</code> (macOS) or <code>Ctrl+Shift+P</code> (Windows/Linux)</p> </li> <li>Choose \"Tasks: Run Task\"</li> <li> <p>Select a task from the list (e.g., \"Start Full Development Environment\")</p> </li> <li> <p>Explore poetry2nix Integration</p> </li> <li> <p>Review <code>docs/poetry2nix-integration.md</code> for implementation guidance</p> </li> <li> <p>Compare your current <code>flake.nix</code> with <code>flake.nix.poetry2nix</code></p> </li> <li> <p>Set Up MCP Tools</p> </li> <li>Follow the instructions in <code>docs/mcp-tools-setup.md</code></li> <li>Try using the MCP-related tasks to start and check server status</li> </ol>"},{"location":"enhanced-dev-environment/#next-steps","title":"Next Steps","text":"<ol> <li>Test the tasks.json configuration and adjust as needed</li> <li>Consider implementing the poetry2nix integration</li> <li>Keep MCP servers updated for the best AI assistance experience</li> </ol>"},{"location":"enhanced-dev-environment/#detailed-documentation","title":"Detailed Documentation","text":"<p>For GitHub Copilot and development guidance, see the <code>.github/instructions/</code> directory:</p> <ul> <li> <p>Code Style and Architecture</p> </li> <li> <p>Python Backend Architecture</p> </li> <li>React Frontend Architecture</li> <li>Python Code Style Guidelines</li> <li> <p>TypeScript Code Style Guidelines</p> </li> <li> <p>Development Workflow</p> </li> <li> <p>VS Code Tasks Documentation</p> </li> <li>Development Environment</li> <li> <p>Pull Request Expectations</p> </li> <li> <p>Tools and Configuration</p> </li> <li>MCP Tools Guide</li> <li>ESLint/TypeScript Config</li> <li>Environment Variables</li> </ul>"},{"location":"enhanced-dev-environment/#known-issues","title":"Known Issues","text":"<ul> <li>The poetry2nix integration is provided as a proof-of-concept and will need testing</li> <li>MCP server management may require additional customization based on your specific setup</li> <li>Task configurations may need adjustments depending on your specific environment</li> </ul>"},{"location":"environment-variable-integration/","title":"Environment Variable Integration for NixOS Module","text":"<p>This document provides a summary of the enhancements made to the <code>rvc2api</code> NixOS module to comprehensively support all environment variables and configuration options.</p>"},{"location":"environment-variable-integration/#added-configuration-options","title":"Added Configuration Options","text":"<p>The following configuration options have been added to the NixOS module:</p>"},{"location":"environment-variable-integration/#server-configuration","title":"Server Configuration","text":"<ul> <li><code>host</code>: Host IP to bind the API server to (default: \"0.0.0.0\")</li> <li><code>port</code>: Port to run the API server on (default: 8000)</li> <li><code>logLevel</code>: Logging level (default: \"INFO\")</li> </ul>"},{"location":"environment-variable-integration/#controller-configuration","title":"Controller Configuration","text":"<ul> <li><code>controllerSourceAddr</code>: Controller source address in hex (default: \"0xF9\")</li> </ul>"},{"location":"environment-variable-integration/#github-integration","title":"GitHub Integration","text":"<ul> <li><code>githubUpdateRepo</code>: GitHub repository to check for updates (format: owner/repo)</li> </ul>"},{"location":"environment-variable-integration/#previously-supported-options","title":"Previously Supported Options","text":"<ul> <li>All Pushover notification settings</li> <li>UptimeRobot monitoring settings</li> <li>CANbus configuration (channels, bustype, bitrate)</li> <li>RV-C spec and device mapping paths and model selector</li> <li>User coach info path</li> </ul>"},{"location":"environment-variable-integration/#environment-variable-mapping","title":"Environment Variable Mapping","text":"<p>All environment variables used by the application are now properly mapped in the NixOS module:</p> NixOS Configuration Environment Variable <code>settings.host</code> <code>RVC2API_HOST</code> <code>settings.port</code> <code>RVC2API_PORT</code> <code>settings.logLevel</code> <code>LOG_LEVEL</code> <code>settings.controllerSourceAddr</code> <code>CONTROLLER_SOURCE_ADDR</code> <code>settings.githubUpdateRepo</code> <code>GITHUB_UPDATE_REPO</code> <code>settings.modelSelector</code> <code>CAN_MODEL_SELECTOR</code> <code>settings.pushover.enable</code> <code>ENABLE_PUSHOVER</code> <code>settings.pushover.apiToken</code> <code>PUSHOVER_API_TOKEN</code> <code>settings.pushover.userKey</code> <code>PUSHOVER_USER_KEY</code> <code>settings.pushover.device</code> <code>PUSHOVER_DEVICE</code> <code>settings.pushover.priority</code> <code>PUSHOVER_PRIORITY</code> <code>settings.uptimerobot.enable</code> <code>ENABLE_UPTIMEROBOT</code> <code>settings.uptimerobot.apiKey</code> <code>UPTIMEROBOT_API_KEY</code> <code>settings.canbus.channels</code> <code>CAN_CHANNELS</code> <code>settings.canbus.bustype</code> <code>CAN_BUSTYPE</code> <code>settings.canbus.bitrate</code> <code>CAN_BITRATE</code> <code>settings.rvcSpecPath</code> <code>CAN_SPEC_PATH</code> <code>settings.deviceMappingPath</code> <code>CAN_MAP_PATH</code> <code>settings.userCoachInfoPath</code> <code>RVC2API_USER_COACH_INFO_PATH</code>"},{"location":"environment-variable-integration/#documentation-updates","title":"Documentation Updates","text":"<ul> <li>Created comprehensive documentation in <code>docs/nixos-module.md</code></li> <li>Updated <code>docs/nixos-integration.md</code> with improved examples</li> <li>Included references to the NixOS module in the main <code>README.md</code></li> <li>Created a unified <code>docs/development-environments.md</code> document explaining all setup options</li> </ul>"},{"location":"environment-variable-integration/#next-steps","title":"Next Steps","text":"<p>Now that the NixOS module has all the configuration options fully integrated:</p> <ol> <li>Users can deploy the service with all necessary configuration options</li> <li>Documentation provides clear examples for both basic and advanced configurations</li> <li>All environment variables used by the application are properly mapped</li> <li>Integration with both development and production environments is seamless</li> </ol> <p>The improved module structure follows NixOS best practices and provides a clean, declarative way to configure the service.</p>"},{"location":"eslint-typescript-config/","title":"ESLint and TypeScript Configuration","text":"<p>This document details the ESLint and TypeScript configuration used in the rvc2api project's React frontend.</p>"},{"location":"eslint-typescript-config/#eslint-configuration","title":"ESLint Configuration","text":""},{"location":"eslint-typescript-config/#flat-configuration-format","title":"Flat Configuration Format","text":"<p>The project uses ESLint v9+ with the new flat configuration format, which provides better performance and more flexibility:</p> <ul> <li><code>web_ui/eslint.config.js</code>: Main configuration file</li> <li><code>web_ui/eslint.config.mjs</code>: Alternative format for module support</li> </ul>"},{"location":"eslint-typescript-config/#key-eslint-rules","title":"Key ESLint Rules","text":"<pre><code>{\n  // General formatting rules\n  \"quotes\": [\"error\", \"double\"],\n  \"semi\": [\"error\", \"always\"],\n  \"comma-dangle\": [\"error\", \"never\"],\n  \"no-trailing-spaces\": \"error\",\n  \"eol-last\": [\"error\", \"always\"]\n}\n</code></pre>"},{"location":"eslint-typescript-config/#plugins","title":"Plugins","text":"<p>The ESLint configuration uses several plugins:</p> <ul> <li><code>typescript-eslint</code>: For TypeScript linting</li> <li><code>eslint-plugin-react-hooks</code>: For React hooks linting rules</li> <li><code>eslint-plugin-react-refresh</code>: For React Fast Refresh compatibility</li> <li><code>eslint-plugin-jsdoc</code>: For JSDoc comment validation</li> </ul>"},{"location":"eslint-typescript-config/#typescript-configuration","title":"TypeScript Configuration","text":""},{"location":"eslint-typescript-config/#project-references","title":"Project References","text":"<p>The TypeScript configuration uses project references to separate concerns:</p> <ul> <li><code>tsconfig.json</code>: Root configuration that references the specific configuration files</li> <li><code>tsconfig.app.json</code>: Configuration for the main application code</li> <li><code>tsconfig.node.json</code>: Configuration for Node.js specific code</li> <li><code>tsconfig.test.json</code>: Configuration for tests</li> </ul>"},{"location":"eslint-typescript-config/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"eslint-typescript-config/#interface-parsing-errors","title":"Interface Parsing Errors","text":"<p>ESLint may produce parsing errors for TypeScript files that have standalone interfaces but no imports. This occurs because ESLint treats files with no imports/exports as script files rather than modules.</p> <p>Solution: Ensure all TypeScript files with interfaces have at least one import statement. We provide a utility script to fix this automatically:</p> <pre><code>npm run fix:interfaces\n</code></pre> <p>This script adds a React import to interface files that don't have any imports.</p>"},{"location":"eslint-typescript-config/#trailing-commas","title":"Trailing Commas","text":"<p>ESLint is configured to disallow trailing commas in objects, arrays, and function parameters. We provide a utility script to fix trailing comma issues:</p> <pre><code>npm run fix:style\n</code></pre>"},{"location":"eslint-typescript-config/#pre-commit-hook-configuration","title":"Pre-commit Hook Configuration","text":"<p>The pre-commit hook is configured to run ESLint automatically with the <code>--fix</code> option:</p> <pre><code>- repo: https://github.com/pre-commit/mirrors-eslint\n  rev: v8.56.0\n  hooks:\n    - id: eslint\n      files: \\.(js|ts|tsx)$\n      types: [file]\n      args: [\"--fix\", \"--config\", \"web_ui/eslint.config.js\"]\n      additional_dependencies:\n        - eslint@9.25.0\n        - eslint-plugin-react-hooks@5.2.0\n        - eslint-plugin-react-refresh@0.4.19\n        - typescript@5.8.3\n        - typescript-eslint@8.30.1\n        - \"@eslint/js@9.26.0\"\n        - globals@16.0.0\n        - eslint-plugin-jsdoc@50.6.17\n      exclude: ^web_ui/(dist|node_modules)/\n</code></pre>"},{"location":"eslint-typescript-config/#fix-scripts","title":"Fix Scripts","text":""},{"location":"eslint-typescript-config/#fix-typescript-interfacessh","title":"fix-typescript-interfaces.sh","text":"<p>This script ensures that all TypeScript files with interface definitions have proper imports:</p> <pre><code>#!/bin/bash\n# Fix TypeScript parsing issues with interfaces\n\necho \"Ensuring TypeScript imports are properly handled...\"\n\n# Make sure imports are properly formatted for TypeScript files with interfaces\nfor file in $(find ./src -name \"*.ts\" -o -name \"*.tsx\"); do\n  # Skip compiled JS files\n  if [[ $file == *\".js\" ]]; then\n    continue\n  fi\n\n  # Fix interface definitions causing parsing errors by ensuring proper imports\n  if grep -q \"interface \" \"$file\"; then\n    # Check if the file is using imports already\n    if ! grep -q \"import \" \"$file\"; then\n      echo \"Adding import to $file\"\n      # Create a temporary file with the import added at the top\n      TMP_FILE=$(mktemp)\n      echo '// Ensure file is treated as a module' &gt; \"$TMP_FILE\"\n      echo 'import type { FC } from \"react\";' &gt;&gt; \"$TMP_FILE\"\n      echo '' &gt;&gt; \"$TMP_FILE\"\n      cat \"$file\" &gt;&gt; \"$TMP_FILE\"\n      # Replace original file with temporary file\n      mv \"$TMP_FILE\" \"$file\"\n    fi\n  fi\n\n  # Fix trailing commas in objects and arrays\n  if grep -q \",$\" \"$file\"; then\n    echo \"Fixing trailing commas in $file\"\n    TMP_FILE=$(mktemp)\n    sed 's/,[ \\t]*$//' \"$file\" &gt; \"$TMP_FILE\"\n    mv \"$TMP_FILE\" \"$file\"\n  fi\ndone\n\n# Also check JS config files\nfor file in $(find . -maxdepth 2 -name \"*.js\" -o -name \"*.config.js\" -o -name \"*.config.ts\"); do\n  # Fix trailing commas in objects and arrays\n  if grep -q \",$\" \"$file\"; then\n    echo \"Fixing trailing commas in $file\"\n    TMP_FILE=$(mktemp)\n    sed 's/,[ \\t]*$//' \"$file\" &gt; \"$TMP_FILE\"\n    mv \"$TMP_FILE\" \"$file\"\n  fi\ndone\n\necho \"TypeScript interface fixes applied!\"\n</code></pre>"},{"location":"eslint-typescript-config/#fix-eslint-issuessh","title":"fix-eslint-issues.sh","text":"<p>This script runs multiple fixes in sequence:</p> <pre><code>#!/bin/bash\n# Fix common ESLint issues in JS/TS files\n\n# Fix TypeScript interface issues first\necho \"Fixing TypeScript interface issues...\"\n./scripts/fix-typescript-interfaces.sh || true\n\n# Apply standard ESLint fixes\necho \"Applying ESLint fixes with new config...\"\nnpx eslint --config eslint.config.js . --ext .ts,.tsx --fix || true\n\necho \"Fixing trailing commas in configuration files...\"\n\n# Fix specific files\nFILES_TO_CHECK=(\n  \"postcss.config.js\"\n  \"tailwind.config.js\"\n  \"vite.config.ts\"\n  \"jest.config.ts\"\n  \"jest.config.js\"\n  \"src/utils/config.ts\"\n)\n\nfor file in \"${FILES_TO_CHECK[@]}\"; do\n  echo \"Checking $file...\"\n  if [ -f \"$file\" ]; then\n    # Generic fix for trailing commas at end of lines before closing brackets or braces\n    TMP_FILE=$(mktemp)\n    sed 's/,[ \\t]*\\([\\]}]\\)/\\1/g' \"$file\" &gt; \"$TMP_FILE\"\n    mv \"$TMP_FILE\" \"$file\"\n    echo \"Fixed $file\"\n  fi\ndone\n\necho \"Fixes applied!\"\n</code></pre>"},{"location":"eslint-typescript-config/#available-npm-scripts","title":"Available NPM Scripts","text":"<p>The following scripts are available in <code>package.json</code>:</p> <pre><code>{\n  \"scripts\": {\n    \"lint\": \"eslint --config eslint.config.js . --ext .ts,.tsx\",\n    \"lint:fix\": \"eslint --config eslint.config.js . --ext .ts,.tsx --fix\",\n    \"fix:style\": \"./scripts/fix-eslint-issues.sh\",\n    \"fix:interfaces\": \"./scripts/fix-typescript-interfaces.sh\",\n    \"typecheck\": \"tsc -p tsconfig.app.json --noEmit\"\n  }\n}\n</code></pre>"},{"location":"eslint-typescript-config/#troubleshooting","title":"Troubleshooting","text":"<p>If you continue to experience ESLint or TypeScript issues:</p> <ol> <li>Run <code>npm run fix:interfaces</code> to add imports to standalone interface files</li> <li>Run <code>npm run fix:style</code> to fix trailing commas and other common issues</li> <li>Check that your file is included in the appropriate tsconfig.json</li> <li>Ensure you're properly importing dependencies in each file</li> <li>For persistent issues, check GitHub issue #30</li> </ol>"},{"location":"frontend-development/","title":"Frontend Development Guide","text":"<p>This guide explains how to work with the React frontend in the rvc2api project.</p>"},{"location":"frontend-development/#architecture-overview","title":"Architecture Overview","text":"<p>The rvc2api project uses a modern web architecture:</p> <ul> <li>Backend: Python FastAPI server providing RESTful API and WebSocket endpoints</li> <li>Frontend: React-based Single Page Application (SPA) built with Vite</li> <li>Deployment: Caddy webserver serving static assets with API proxying</li> </ul>"},{"location":"frontend-development/#development-environment","title":"Development Environment","text":""},{"location":"frontend-development/#using-nix-recommended","title":"Using Nix (Recommended)","text":"<p>The project uses Nix flakes to provide a consistent development environment:</p> <pre><code># Enter the development environment\ncd /Users/ryan/src/rvc2api\nnix develop\n\n# The environment automatically sets up Node.js\n# Navigate to web_ui directory\ncd web_ui\n\n# Start the development server\nnpm run dev\n</code></pre>"},{"location":"frontend-development/#manual-setup-without-nix","title":"Manual Setup (Without Nix)","text":"<p>If you prefer not to use Nix, you can set up the environment manually:</p> <pre><code># Ensure you have Node.js 20+ installed\nnode --version\n\n# Install dependencies\ncd /Users/ryan/src/rvc2api/web_ui\nnpm install\n\n# Start the development server\nnpm run dev\n</code></pre>"},{"location":"frontend-development/#building-the-frontend","title":"Building the Frontend","text":""},{"location":"frontend-development/#development-build","title":"Development Build","text":"<p>During development, Vite provides fast rebuilds and HMR (Hot Module Replacement):</p> <pre><code>cd web_ui\nnpm run dev\n</code></pre> <p>This starts a development server at http://localhost:5173 with: - Hot Module Replacement for instant UI updates - API proxying to the backend - Source maps for debugging</p>"},{"location":"frontend-development/#production-build","title":"Production Build","text":"<p>For production builds, use either:</p> <pre><code># Using Nix\nnix run .#build-frontend\n\n# Or manually\ncd web_ui\nnpm run build\n</code></pre> <p>The build output is placed in <code>web_ui/dist/</code> and is ready to be served by Caddy.</p>"},{"location":"frontend-development/#project-structure","title":"Project Structure","text":"<pre><code>web_ui/\n\u251c\u2500\u2500 public/           # Static assets copied as-is\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 components/   # Reusable React components\n\u2502   \u251c\u2500\u2500 pages/        # Page components\n\u2502   \u251c\u2500\u2500 hooks/        # Custom React hooks\n\u2502   \u251c\u2500\u2500 api.ts        # API client functions\n\u2502   \u2514\u2500\u2500 main.tsx      # Application entry point\n\u251c\u2500\u2500 index.html        # HTML template\n\u251c\u2500\u2500 vite.config.ts    # Vite configuration\n\u2514\u2500\u2500 package.json      # Dependencies and scripts\n</code></pre>"},{"location":"frontend-development/#api-integration","title":"API Integration","text":"<p>The frontend communicates with the backend through:</p>"},{"location":"frontend-development/#rest-api","title":"REST API","text":"<p>For data fetching and commands:</p> <pre><code>// Example API call\nconst response = await fetch('/api/entities');\nconst entities = await response.json();\n</code></pre>"},{"location":"frontend-development/#websocket","title":"WebSocket","text":"<p>For real-time updates:</p> <pre><code>// Example WebSocket connection\nconst ws = new WebSocket(`ws://${window.location.host}/ws/entities`);\n\nws.addEventListener('message', (event) =&gt; {\n  const data = JSON.parse(event.data);\n  // Handle real-time update\n});\n</code></pre>"},{"location":"frontend-development/#deployment","title":"Deployment","text":"<p>After building, the static files in <code>web_ui/dist/</code> should be deployed to a webserver. The project uses Caddy for serving these files and proxying API requests to the backend.</p> <p>See React Deployment Guide for detailed deployment instructions.</p>"},{"location":"frontend-theming/","title":"Theme System Documentation","text":"<p>The RVC2API frontend supports a theming system that allows users to switch between different visual themes.</p>"},{"location":"frontend-theming/#available-themes","title":"Available Themes","text":"<p>The following themes are available:</p> <ul> <li>Default: The standard dark blue theme</li> <li>Dark: A darker blue-gray theme</li> <li>Light: A light theme with dark text on light background</li> </ul>"},{"location":"frontend-theming/#how-to-use","title":"How to Use","text":"<ol> <li>The theme selection dropdown is located in the top-right corner of the application</li> <li>Select a theme from the dropdown to immediately apply it</li> <li>Your theme selection is saved to localStorage and will persist between sessions</li> </ol>"},{"location":"frontend-theming/#how-themes-work","title":"How Themes Work","text":"<p>The theming system uses CSS variables defined in <code>src/styles/themes.css</code> and applied through Tailwind CSS classes. The theme is stored in localStorage and applied via a class on the HTML element.</p>"},{"location":"frontend-theming/#adding-new-themes","title":"Adding New Themes","text":"<p>To add a new theme:</p> <ol> <li>Edit <code>src/styles/themes.css</code> to add your new theme class with custom CSS variables</li> <li>Add your theme to the <code>themeOptions</code> array in <code>src/components/ThemeSelector.tsx</code></li> <li>Optionally customize Tailwind config if needed for new color options</li> </ol>"},{"location":"frontend-theming/#example-adding-a-night-theme","title":"Example: Adding a \"Night\" Theme","text":"<pre><code>/* In themes.css */\n.theme-night {\n  --rv-primary: #1E40AF;\n  --rv-secondary: #047857;\n  --rv-accent: #6D28D9;\n  --rv-background: #030712;\n  --rv-surface: #111827;\n  --rv-text: #E5E7EB;\n  --rv-error: #B91C1C;\n  --rv-warning: #B45309;\n  --rv-success: #047857;\n}\n</code></pre> <pre><code>// In ThemeSelector.tsx\nconst themeOptions: ThemeOption[] = [\n  { id: \"theme-default\", label: \"Default\", value: \"default\" },\n  { id: \"theme-dark\", label: \"Dark\", value: \"dark\" },\n  { id: \"theme-light\", label: \"Light\", value: \"light\" },\n  { id: \"theme-night\", label: \"Night\", value: \"night\" }\n];\n</code></pre>"},{"location":"frontend-theming/#technical-implementation","title":"Technical Implementation","text":"<ul> <li><code>ThemeContext.tsx</code>: Provides theme state management and localStorage persistence</li> <li><code>ThemeSelector.tsx</code>: UI component for selecting themes</li> <li><code>themes.css</code>: CSS variables for each theme</li> <li><code>tailwind.config.js</code>: Maps CSS variables to Tailwind color classes</li> </ul> <p>Changes are applied in real-time without requiring page reload.</p>"},{"location":"github-actions-summary/","title":"GitHub Actions Summary","text":"<p>This document provides a summary of the GitHub Actions workflows implemented for the rvc2api project.</p>"},{"location":"github-actions-summary/#implemented-workflows","title":"Implemented Workflows","text":""},{"location":"github-actions-summary/#documentation-deployment-deploy-docsyml","title":"Documentation Deployment (<code>deploy-docs.yml</code>)","text":"<p>This workflow automates the building and deploying of the project documentation to GitHub Pages.</p> <ul> <li>Triggers:</li> <li>Push to <code>main</code> branch that changes docs or mkdocs.yml</li> <li>Manual trigger via workflow_dispatch</li> <li>Steps:</li> <li>Checkout code</li> <li>Set up Python and Poetry</li> <li>Install dependencies</li> <li>Generate OpenAPI schema</li> <li>Build MkDocs documentation</li> <li>Deploy to GitHub Pages</li> <li>Features:</li> <li>Adds .nojekyll file to prevent Jekyll processing</li> <li>Preserves custom domain configuration (CNAME)</li> <li>Uses GitHub's built-in Pages deployment</li> </ul>"},{"location":"github-actions-summary/#debian-repository-deployment-deploy-deb-repoyml","title":"Debian Repository Deployment (<code>deploy-deb-repo.yml</code>)","text":"<p>This workflow template is prepared for building and deploying a Debian package repository.</p> <ul> <li>Triggers:</li> <li>Currently disabled, will be enabled for version tags when ready</li> <li>Manual trigger via workflow_dispatch for testing</li> <li>Steps:</li> <li>Create Debian repository structure</li> <li>(Placeholder for package building)</li> <li>Generate Packages and Release files</li> <li>Sign the repository with GPG</li> <li>Deploy to GitHub Pages under <code>/debian-repo/</code> path</li> </ul>"},{"location":"github-actions-summary/#combined-deployment-deploy-combinedyml","title":"Combined Deployment (<code>deploy-combined.yml</code>)","text":"<p>This workflow handles both documentation and Debian repository deployment in one job.</p> <ul> <li>Triggers:</li> <li>Push to <code>main</code> branch</li> <li>Push of version tags</li> <li>Manual trigger</li> <li>Components:</li> <li>Documentation build job (always runs)</li> <li>Debian repository build job (only runs for tags)</li> <li>Deployment job that combines outputs</li> </ul>"},{"location":"github-actions-summary/#documentation-testing-test-docsyml","title":"Documentation Testing (<code>test-docs.yml</code>)","text":"<p>This workflow tests the documentation build process without deployment.</p> <ul> <li>Triggers:</li> <li>Pull requests that change docs files</li> <li>Manual trigger</li> <li>Features:</li> <li>Validates that documentation builds successfully</li> <li>Performs basic link checking</li> <li>Identifies TODO comments</li> </ul>"},{"location":"github-actions-summary/#setting-up-github-pages","title":"Setting Up GitHub Pages","text":"<ol> <li>Go to your repository settings on GitHub</li> <li>Navigate to \"Pages\" in the left sidebar</li> <li>Under \"Build and deployment\", select \"GitHub Actions\"</li> <li>The first successful workflow run will deploy your site</li> </ol>"},{"location":"github-actions-summary/#debian-repository-signing","title":"Debian Repository Signing","text":"<p>To enable GPG signing for the Debian repository:</p> <ol> <li>Generate a GPG key using the provided script:</li> </ol> <pre><code>./scripts/generate_repo_key.sh\n</code></pre> <ol> <li>Add the key to GitHub secrets:</li> <li>Base64 encode the private key as instructed by the script</li> <li>Add it as a repository secret named <code>GPG_SIGNING_KEY</code></li> </ol>"},{"location":"github-actions-summary/#custom-domain-configuration","title":"Custom Domain Configuration","text":"<p>To use a custom domain with GitHub Pages:</p> <ol> <li>Uncomment and fill in the domain in the <code>docs/CNAME</code> file</li> <li>Configure your domain's DNS settings:</li> <li>Add A records pointing to GitHub Pages IP addresses</li> <li>Or add a CNAME record for a subdomain</li> </ol>"},{"location":"github-actions-summary/#manual-workflow-dispatch","title":"Manual Workflow Dispatch","text":"<p>All workflows can be manually triggered from the Actions tab in the GitHub repository, making it easy to test or deploy without waiting for code changes.</p>"},{"location":"github-actions/","title":"GitHub Actions Configuration","text":"<p>This page explains the GitHub Actions workflows used in the rvc2api project for continuous integration, documentation building, and package deployment.</p>"},{"location":"github-actions/#workflow-overview","title":"Workflow Overview","text":"<pre><code>flowchart TD\n    Push[Push to Main Branch] --&gt; CheckDocs{Changes to docs?}\n    Tag[Push Tag] --&gt; BuildDeb[Build Deb Packages]\n    CheckDocs --&gt;|Yes| BuildDocs[Build Documentation]\n    CheckDocs --&gt;|No| End[End]\n    BuildDocs --&gt; DeployPages[Deploy to GitHub Pages]\n    BuildDeb --&gt; DeployDebs[Add to Deb Repository]\n    DeployDebs --&gt; DeployPages\n\n    classDef trigger fill:#bbdefb,stroke:#1976d2,color:#212121;\n    classDef check fill:#fff9c4,stroke:#fbc02d,color:#212121;\n    classDef build fill:#c8e6c9,stroke:#388e3c,color:#212121;\n    classDef deploy fill:#ffecb3,stroke:#ffa000,color:#212121;\n    classDef end fill:#f5f5f5,stroke:#bdbdbd,color:#212121;\n\n    class Push,Tag trigger;\n    class CheckDocs check;\n    class BuildDocs,BuildDeb build;\n    class DeployPages,DeployDebs deploy;\n    class End end;</code></pre>"},{"location":"github-actions/#available-workflows","title":"Available Workflows","text":"<p>The project includes the following GitHub Actions workflows:</p> <ol> <li> <p>Documentation Deployment (<code>deploy-docs.yml</code>):</p> </li> <li> <p>Triggered on changes to documentation files or manual dispatch</p> </li> <li>Builds MkDocs documentation</li> <li> <p>Deploys to GitHub Pages</p> </li> <li> <p>Debian Repository (<code>deploy-deb-repo.yml</code>):</p> </li> <li> <p>Template for future Debian package repository deployment</p> </li> <li>Currently disabled by default</li> <li> <p>Will be triggered by new version tags when enabled</p> </li> <li> <p>Combined Deployment (<code>deploy-combined.yml</code>):</p> </li> <li>Handles both documentation and Debian packages</li> <li>Documentation is built on every push to main</li> <li>Debian packages are built when a version tag is pushed</li> <li>Both are deployed to appropriate locations on GitHub Pages</li> </ol>"},{"location":"github-actions/#github-pages-structure","title":"GitHub Pages Structure","text":"<p>The GitHub Pages deployment has the following structure:</p> <pre><code>username.github.io/rvc2api/\n\u251c\u2500\u2500 index.html               # Documentation home page\n\u251c\u2500\u2500 assets/                  # Documentation assets\n\u251c\u2500\u2500 api/                     # API documentation\n\u251c\u2500\u2500 architecture/            # Architecture documentation\n\u2514\u2500\u2500 debian-repo/             # Debian package repository\n    \u251c\u2500\u2500 dists/               # Distribution information\n    \u2514\u2500\u2500 pool/                # Package files\n</code></pre>"},{"location":"github-actions/#setting-up-github-pages","title":"Setting Up GitHub Pages","text":"<p>To enable GitHub Pages deployment:</p> <ol> <li>Go to your GitHub repository settings</li> <li>Navigate to \"Pages\" in the left sidebar</li> <li>Under \"Build and deployment\", select \"GitHub Actions\" as the source</li> <li>The first successful workflow run will deploy your site</li> </ol>"},{"location":"github-actions/#manual-workflow-dispatch","title":"Manual Workflow Dispatch","text":"<p>You can manually trigger workflows from the GitHub Actions tab:</p> <ol> <li>Go to the \"Actions\" tab in your repository</li> <li>Select the workflow you want to run</li> <li>Click \"Run workflow\" and select the branch</li> </ol>"},{"location":"github-actions/#custom-domain-configuration","title":"Custom Domain Configuration","text":"<p>If you want to use a custom domain:</p> <ol> <li>Add your custom domain in the GitHub repository settings under \"Pages\"</li> <li>Create a CNAME file in the docs directory with your domain</li> <li>Add the following DNS records for your domain:</li> <li>A record: <code>185.199.108.153</code></li> <li>A record: <code>185.199.109.153</code></li> <li>A record: <code>185.199.110.153</code></li> <li>A record: <code>185.199.111.153</code></li> <li>CNAME record: Subdomain pointing to <code>username.github.io</code></li> </ol>"},{"location":"github-pages-deployment/","title":"GitHub Pages Deployment","text":"<p>This document explains how the rvc2api project uses GitHub Pages to host both documentation and a Debian package repository.</p>"},{"location":"github-pages-deployment/#overview","title":"Overview","text":"<p>GitHub Pages serves as our hosting platform for:</p> <ol> <li>Project Documentation: Built with MkDocs</li> <li>Debian Package Repository: For easy installation of rvc2api on Debian-based systems</li> </ol> <pre><code>flowchart TD\n    GH[GitHub Repository] --&gt; Actions[GitHub Actions]\n    Actions --&gt; BuildDocs[Build Documentation]\n    Actions --&gt; BuildRepo[Build Debian Repository]\n    BuildDocs --&gt; Pages[GitHub Pages]\n    BuildRepo --&gt; Pages\n    Pages --&gt; DocSite[Documentation Site]\n    Pages --&gt; DebRepo[Debian Repository]\n\n    User[End User] --&gt; DocSite\n    User --&gt; DebRepo\n\n    classDef source fill:#bbdefb,stroke:#1976d2,color:#212121;\n    classDef build fill:#c8e6c9,stroke:#388e3c,color:#212121;\n    classDef deploy fill:#ffecb3,stroke:#ffa000,color:#212121;\n    classDef user fill:#f5f5f5,stroke:#bdbdbd,color:#212121;\n\n    class GH,Actions source;\n    class BuildDocs,BuildRepo build;\n    class Pages,DocSite,DebRepo deploy;\n    class User user;</code></pre>"},{"location":"github-pages-deployment/#documentation-deployment","title":"Documentation Deployment","text":"<p>Documentation is automatically deployed to GitHub Pages when changes are pushed to the <code>main</code> branch or the workflow is manually triggered.</p>"},{"location":"github-pages-deployment/#how-it-works","title":"How It Works","text":"<ol> <li>GitHub Actions workflow is triggered by changes to docs or <code>mkdocs.yml</code></li> <li>The workflow:</li> <li>Sets up Python and Poetry</li> <li>Installs project dependencies</li> <li>Builds the documentation with MkDocs</li> <li>Deploys the built site to GitHub Pages</li> </ol>"},{"location":"github-pages-deployment/#accessing-documentation","title":"Accessing Documentation","text":"<p>The documentation is available at:</p> <pre><code>https://carpenike.github.io/rvc2api/\n</code></pre>"},{"location":"github-pages-deployment/#debian-repository-deployment","title":"Debian Repository Deployment","text":"<p>The Debian repository is deployed to GitHub Pages when a new version tag is pushed.</p>"},{"location":"github-pages-deployment/#repository-structure","title":"Repository Structure","text":"<pre><code>https://carpenike.github.io/rvc2api/debian-repo/\n\u251c\u2500\u2500 dists/\n\u2502   \u2514\u2500\u2500 stable/\n\u2502       \u251c\u2500\u2500 main/\n\u2502       \u2502   \u251c\u2500\u2500 binary-amd64/\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 Packages\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 Packages.gz\n\u2502       \u2502   \u2514\u2500\u2500 binary-arm64/\n\u2502       \u2514\u2500\u2500 Release\n\u2502       \u2514\u2500\u2500 Release.gpg\n\u2502       \u2514\u2500\u2500 InRelease\n\u251c\u2500\u2500 pool/\n\u2502   \u2514\u2500\u2500 main/\n\u2502       \u2514\u2500\u2500 r/\n\u2502           \u2514\u2500\u2500 rvc2api/\n\u2502               \u2514\u2500\u2500 *.deb\n\u2514\u2500\u2500 KEY.gpg\n</code></pre>"},{"location":"github-pages-deployment/#using-the-debian-repository","title":"Using the Debian Repository","text":"<p>To use the repository:</p> <ol> <li>Add the GPG key:</li> </ol> <pre><code>curl -fsSL https://carpenike.github.io/rvc2api/debian-repo/KEY.gpg | sudo apt-key add -\n</code></pre> <ol> <li>Add the repository:</li> </ol> <pre><code>echo \"deb https://carpenike.github.io/rvc2api/debian-repo stable main\" | sudo tee /etc/apt/sources.list.d/rvc2api.list\n</code></pre> <ol> <li>Update and install:</li> </ol> <pre><code>sudo apt update\nsudo apt install rvc2api\n</code></pre>"},{"location":"github-pages-deployment/#setting-up-repository-signing","title":"Setting Up Repository Signing","text":"<p>To use the repository signing capabilities:</p> <ol> <li>Generate a GPG key using the provided script:</li> </ol> <pre><code>./scripts/generate_repo_key.sh\n</code></pre> <ol> <li>Add the generated key to your GitHub repository secrets:</li> <li>Follow the instructions from the script output</li> <li>Add the key as a GitHub secret named <code>GPG_SIGNING_KEY</code></li> </ol>"},{"location":"github-pages-deployment/#workflow-configuration","title":"Workflow Configuration","text":"<p>The GitHub Actions workflows are configured in the <code>.github/workflows/</code> directory:</p> <ul> <li><code>deploy-docs.yml</code>: Documentation-only workflow</li> <li><code>deploy-deb-repo.yml</code>: Debian repository workflow (triggered by version tags)</li> <li><code>deploy-combined.yml</code>: Combined workflow for both documentation and packages</li> </ul>"},{"location":"github-pages-deployment/#manual-deployment","title":"Manual Deployment","text":"<p>You can manually trigger the deployment workflows from the GitHub Actions tab in your repository.</p>"},{"location":"install-vcan-test-task/","title":"Installing the vCAN Test VS Code Task","text":"<p>You can add the vCAN testing task to your VS Code environment using one of these methods:</p>"},{"location":"install-vcan-test-task/#automated-installation","title":"Automated Installation","text":"<p>Run the provided script to automatically add the task to your tasks.json file:</p> <pre><code># Bash\n./scripts/add_vcan_test_task.sh\n\n# Fish\n./scripts/add_vcan_test_task.sh\n</code></pre> <p>This script will:</p> <ol> <li>Backup your current tasks.json</li> <li>Add the new task to the file</li> <li>Notify you when complete</li> </ol>"},{"location":"install-vcan-test-task/#manual-installation","title":"Manual Installation","text":"<p>If you prefer to add the task manually:</p> <ol> <li>Open the <code>.vscode/tasks.json</code> file in your project</li> <li>Add the following task configuration to the \"tasks\" array (before the closing <code>]</code>):</li> </ol> <pre><code>{\n  \"label\": \"System: Test vCAN Setup\",\n  \"type\": \"shell\",\n  \"command\": \"cd ${workspaceFolder} &amp;&amp; poetry run python dev_tools/test_vcan_setup.py\",\n  \"group\": \"none\",\n  \"detail\": \"Test vCAN setup by sending and receiving a message\",\n  \"presentation\": {\n    \"reveal\": \"always\",\n    \"panel\": \"dedicated\",\n    \"clear\": true,\n    \"focus\": false\n  }\n}\n</code></pre> <ol> <li>Save the file</li> </ol>"},{"location":"install-vcan-test-task/#using-the-task","title":"Using the Task","text":"<p>Once installed, access the task by pressing <code>Cmd+Shift+P</code> (macOS) or <code>Ctrl+Shift+P</code> (Windows/Linux) and typing \"Tasks: Run Task\", then selecting \"System: Test vCAN Setup\".</p>"},{"location":"mcp-tools-setup/","title":"MCP Tools Setup and Management for rvc2api","text":"<p>This guide explains how to set up and manage Model Context Protocol (MCP) tools for the rvc2api project. These tools provide context-aware AI assistance through GitHub Copilot Chat.</p>"},{"location":"mcp-tools-setup/#available-mcp-tools","title":"Available MCP Tools","text":"<p>The project utilizes three primary MCP tools:</p> <ol> <li>@context7: Provides project-aware code lookups</li> <li>@perplexity: Offers external research capabilities</li> <li>@github: Enables repository and issue information queries</li> </ol>"},{"location":"mcp-tools-setup/#setting-up-mcp-tools","title":"Setting Up MCP Tools","text":""},{"location":"mcp-tools-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>VS Code with GitHub Copilot and GitHub Copilot Chat extensions</li> <li>Required MCP server extensions installed</li> </ul>"},{"location":"mcp-tools-setup/#installation","title":"Installation","text":"<p>Install the necessary VS Code extensions:</p> <ul> <li>GitHub Copilot</li> <li>GitHub Copilot Chat</li> <li>Relevant MCP extensions:</li> <li>Context7 Extension (for @context7)</li> <li>GitHub Extension (for @github)</li> <li>Perplexity Extension (for @perplexity)</li> </ul>"},{"location":"mcp-tools-setup/#using-vs-code-tasks-for-mcp-tools","title":"Using VS Code Tasks for MCP Tools","text":"<p>The project includes VS Code tasks for managing MCP tools:</p>"},{"location":"mcp-tools-setup/#startingrestarting-mcp-servers","title":"Starting/Restarting MCP Servers","text":"<ol> <li>Press <code>Ctrl+Shift+P</code> (or <code>Cmd+Shift+P</code> on macOS)</li> <li>Select \"Tasks: Run Task\"</li> <li>Choose \"Restart MCP - context7 Server\"</li> </ol>"},{"location":"mcp-tools-setup/#checking-mcp-tool-status","title":"Checking MCP Tool Status","text":"<ol> <li>Press <code>Ctrl+Shift+P</code> (or <code>Cmd+Shift+P</code> on macOS)</li> <li>Select \"Tasks: Run Task\"</li> <li>Choose \"MCP Tools Status\"</li> </ol>"},{"location":"mcp-tools-setup/#using-mcp-tools-in-development","title":"Using MCP Tools in Development","text":""},{"location":"mcp-tools-setup/#context7-examples","title":"@context7 Examples","text":"<pre><code># Find implementations of WebSocket handling\n@context7 WebSocket connection handling\n\n# Learn about CANbus integration\n@context7 python-can integration\n\n# Understand API routes\n@context7 FastAPI route implementation\n</code></pre>"},{"location":"mcp-tools-setup/#perplexity-examples","title":"@perplexity Examples","text":"<pre><code># Research external technologies\n@perplexity RV-C protocol specification\n\n# Find best practices\n@perplexity FastAPI dependency injection patterns\n\n# Explore alternative libraries\n@perplexity python-can vs socketcan-python\n</code></pre>"},{"location":"mcp-tools-setup/#github-examples","title":"@github Examples","text":"<pre><code># Search for issues\n@github issues:rvc2api+websocket+reconnection\n\n# Find pull requests\n@github pr:rvc2api+react+frontend\n\n# Get repository statistics\n@github repo:rvc2api stats\n</code></pre>"},{"location":"mcp-tools-setup/#best-practices","title":"Best Practices","text":""},{"location":"mcp-tools-setup/#when-to-prioritize-context7","title":"When to Prioritize Context7","text":"<p>Always use Context7 for these scenarios:</p>"},{"location":"mcp-tools-setup/#working-with-external-libraries","title":"Working with External Libraries","text":"<pre><code>@context7 how to use FastAPI dependency injection\n@context7 React useState with TypeScript generics\n@context7 tailwind responsive design patterns\n</code></pre>"},{"location":"mcp-tools-setup/#version-specific-features","title":"Version-Specific Features","text":"<pre><code>@context7 Next.js 14 App Router middleware\n@context7 React 18 concurrent mode features\n@context7 Python 3.12 typing features\n</code></pre>"},{"location":"mcp-tools-setup/#library-api-questions","title":"Library API Questions","text":"<pre><code>@context7 FastAPI WebSocket authentication\n@context7 React useCallback correct dependencies\n@context7 tailwind dark mode configuration\n</code></pre> <p>Important: For any library or framework questions, always use <code>@context7</code> first before falling back to LLM-generated answers. This ensures you get current, correct API information rather than outdated or hallucinated answers.</p>"},{"location":"mcp-tools-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"mcp-tools-setup/#common-issues","title":"Common Issues","text":"<ol> <li> <p>MCP Server Not Responding</p> </li> <li> <p>Use the \"MCP: Restart Context7 Server\" task</p> </li> <li>Check if the server process is running with \"Status: Check MCP Tools\"</li> <li> <p>Restart VS Code</p> </li> <li> <p>Limited or Outdated Context</p> </li> <li> <p>The context server might need to re-index your codebase</p> </li> <li> <p>Try running the indexing command manually or restart the server</p> </li> <li> <p>External Research Failing</p> </li> <li>Check your internet connection</li> <li>Verify API keys or authentication if applicable</li> </ol>"},{"location":"mcp-tools-setup/#related-documentation","title":"Related Documentation","text":"<p>For more information about MCP tools and their integration with specific project areas, see:</p> <ul> <li>Python Backend Architecture - Backend-specific MCP usage</li> <li>React Frontend Architecture - Frontend-specific MCP usage</li> <li>MCP Tools Guide - Complete MCP tools reference</li> <li>VS Code Tasks - Tasks for managing MCP tools</li> </ul>"},{"location":"mcp-tools-setup/#advanced-configuration","title":"Advanced Configuration","text":"<p>For advanced configuration of MCP tools, refer to the specific documentation for each tool:</p> <ul> <li>Context7 Documentation</li> <li>GitHub Copilot Documentation</li> <li>Perplexity Documentation</li> </ul>"},{"location":"mixed-chunking-strategies/","title":"Mixed Chunking Strategies","text":"<p>This guide describes how to use the enhanced document chunking and FAISS indexing system that supports multiple document sources and chunking strategies in a single vector database.</p>"},{"location":"mixed-chunking-strategies/#overview","title":"Overview","text":"<p>The RVC2API project supports a unified approach to semantic search across multiple document types using a single FAISS index. This enables:</p> <ul> <li>Different chunking strategies for different document types</li> <li>Source-aware filtering of search results</li> <li>Consistent metadata across all documents</li> <li>Better search results by selecting the most appropriate chunking method for each document type</li> </ul>"},{"location":"mixed-chunking-strategies/#document-sources-and-chunking-strategies","title":"Document Sources and Chunking Strategies","text":"Document Type Recommended Chunking Description RV-C Specification <code>SECTION_OVERLAP</code> Chunks by specification sections with overlap between chunks Victron Manuals <code>PARAGRAPH</code> Chunks by natural paragraphs Firefly Docs <code>TOKEN</code> Fixed-size token chunking General PDFs <code>SLIDING_WINDOW</code> Sliding window with configurable overlap"},{"location":"mixed-chunking-strategies/#using-the-document-loader-api","title":"Using the Document Loader API","text":""},{"location":"mixed-chunking-strategies/#basic-usage","title":"Basic Usage","text":"<pre><code>from pathlib import Path\nfrom document_loader import ChunkingStrategy, load_chunk_with_metadata\n\n# Process chunks with consistent metadata\ndocs = load_chunk_with_metadata(\n    chunks_data=your_chunks,\n    source_path=Path(\"your-document.pdf\"),\n    chunking_strategy=ChunkingStrategy.SECTION_OVERLAP\n)\n</code></pre>"},{"location":"mixed-chunking-strategies/#filtering-search-results","title":"Filtering Search Results","text":"<pre><code>from document_loader import filter_results_by_source\n\n# Get results from a specific source\nfiltered_results = filter_results_by_source(\n    results=search_results,\n    source=\"rvc-spec-2023-11.pdf\",\n    limit=3\n)\n\n# Or by chunking strategy\nfiltered_results = filter_results_by_source(\n    results=search_results,\n    chunking=ChunkingStrategy.PARAGRAPH,\n    limit=3\n)\n</code></pre>"},{"location":"mixed-chunking-strategies/#command-line-tools","title":"Command-Line Tools","text":""},{"location":"mixed-chunking-strategies/#query-with-source-filtering","title":"Query with Source Filtering","text":"<pre><code>python dev_tools/query_faiss.py \"battery temperature\" --source \"rvc-spec-2023-11.pdf\"\n</code></pre>"},{"location":"mixed-chunking-strategies/#query-with-chunking-strategy-filtering","title":"Query with Chunking Strategy Filtering","text":"<pre><code>python dev_tools/query_faiss.py \"solar panel configuration\" --chunking \"paragraph\"\n</code></pre>"},{"location":"mixed-chunking-strategies/#specify-result-count","title":"Specify Result Count","text":"<pre><code>python dev_tools/query_faiss.py \"water tank level\" --count 5\n</code></pre>"},{"location":"mixed-chunking-strategies/#adding-new-document-sources","title":"Adding New Document Sources","text":"<p>To add a new document source with its own chunking strategy:</p> <ol> <li>Process your document into chunks with appropriate metadata</li> <li>Use <code>load_chunk_with_metadata()</code> to standardize metadata</li> <li>Add to the existing FAISS index or create a new one</li> <li>Use the <code>query_faiss.py</code> script with <code>--source</code> parameter to search</li> </ol>"},{"location":"mixed-chunking-strategies/#best-practices","title":"Best Practices","text":"<ol> <li>Source Naming: Use the standardized <code>normalize_source_name()</code> function to ensure consistent source names</li> <li>Metadata Fields: Always include <code>source</code>, <code>chunking</code>, and other relevant fields in your metadata</li> <li>Chunking Strategy: Select the most appropriate chunking strategy for each document type</li> <li>Mixed Index: When searching a mixed index, always consider filtering by source when relevant</li> </ol>"},{"location":"mixed-chunking-strategies/#example-adding-victron-manual","title":"Example: Adding Victron Manual","text":"<pre><code>import json\nfrom pathlib import Path\nfrom document_loader import ChunkingStrategy, load_chunk_with_metadata\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_community.embeddings import OpenAIEmbeddings\n\n# Process Victron manual with paragraph chunking\nwith open(\"victron_chunks.json\") as f:\n    victron_chunks = json.load(f)\n\n# Load with standardized metadata\ndocs = load_chunk_with_metadata(\n    chunks_data=victron_chunks,\n    source_path=Path(\"victron-multiplus-2023.pdf\"),\n    chunking_strategy=ChunkingStrategy.PARAGRAPH\n)\n\n# Load existing index and add new documents\nvectorstore = FAISS.load_local(\"resources/vector_store/rvc_spec_index\", OpenAIEmbeddings())\nvectorstore.add_documents(docs)\nvectorstore.save_local(\"resources/vector_store/combined_index\")\n</code></pre>"},{"location":"mixed-chunking-strategies/#advanced-usage","title":"Advanced Usage","text":"<p>See the implementation in <code>document_loader.py</code> for additional utilities and options for working with mixed document sources and chunking strategies.</p>"},{"location":"mkdocs-config-update/","title":"MkDocs Configuration Update (May 18, 2025)","text":"<p>This document summarizes the changes made to the MkDocs configuration structure to improve documentation building and organization, including the addition of Mermaid diagram support and documentation reorganization.</p>"},{"location":"mkdocs-config-update/#changes-implemented","title":"Changes Implemented","text":"<ol> <li> <p>Moved <code>mkdocs.yml</code> from <code>/docs</code> directory to project root:</p> </li> <li> <p>This is a standard best practice for MkDocs projects</p> </li> <li> <p>It resolves issues with the docs directory being both the configuration location and source directory</p> </li> <li> <p>Updated path configurations in mkdocs.yml:</p> </li> <li> <p>Changed <code>docs_dir</code> from <code>.</code> to <code>docs</code> (pointing to the docs directory from project root)</p> </li> <li> <p>Changed <code>site_dir</code> from <code>../site</code> to <code>site</code> (site output in project root)</p> </li> <li> <p>Added missing dependency:</p> </li> <li> <p>Added <code>mkdocs-autorefs = \"^0.5.0\"</code> to <code>pyproject.toml</code></p> </li> <li> <p>This dependency was needed for proper reference linking in documentation</p> </li> <li> <p>Updated VS Code tasks to reference the new mkdocs.yml location:</p> </li> <li> <p>Updated \"Server: Serve Documentation\" task</p> </li> <li>Updated \"Build: Documentation\" task</li> <li>Updated \"API: Update Documentation\" task</li> <li> <p>All tasks now run from project root directory</p> </li> <li> <p>Fixed YAML lint errors:</p> </li> <li> <p>Updated the <code>!!python/name:</code> tag format in the superfences configuration</p> </li> <li>Changed from <code>format: !!python/name:pymdownx.superfences.fence_code_format</code> to <code>format: \"pymdownx.superfences.fence_code_format\"</code></li> <li> <p>This preserves functionality while resolving VS Code YAML lint warnings</p> </li> <li> <p>Added Mermaid Diagram Support:</p> </li> <li> <p>Added <code>mkdocs-mermaid2-plugin</code> to the project dependencies</p> </li> <li>Configured the mermaid plugin in the plugins section of mkdocs.yml</li> <li>Created comprehensive diagram guidelines in the documentation instructions</li> <li> <p>Added sample diagrams to demonstrate proper usage in test-mermaid.md</p> </li> <li> <p>Reorganized Documentation Structure:</p> </li> <li>Clearly separated documentation into User Guide and Developer Guide sections</li> <li>Created a documentation-organization.md file explaining the structure</li> <li>Updated navigation in mkdocs.yml to reflect the new organization</li> <li>Added cross-linking between related documentation pages</li> </ol>"},{"location":"mkdocs-config-update/#key-added-diagrams","title":"Key Added Diagrams","text":"<p>Several important diagrams have been added throughout the documentation:</p> <ol> <li>System Architecture: Comprehensive component diagram in <code>architecture/overview.md</code></li> <li>Backend Architecture: Component flow chart in <code>architecture/backend.md</code></li> <li>WebSocket Communication: Sequence diagram in <code>api/websocket.md</code></li> <li>Frontend API Integration: Sequence diagram in <code>api/frontend-integration.md</code></li> <li>Environment Variables: Configuration flow diagram in <code>environment-variable-integration.md</code></li> <li>Frontend Architecture: Component diagram in <code>architecture/frontend.md</code></li> <li>Pull Request Workflow: Process diagram in <code>contributing/pull-requests.md</code></li> </ol>"},{"location":"mkdocs-config-update/#diagram-styling-standards","title":"Diagram Styling Standards","text":"<p>To ensure consistency across all diagrams, a standard color scheme was established:</p> Component Type Fill Color Stroke Color Frontend/UI #bbdefb #1976d2 API/Backend #c8e6c9 #388e3c Business Logic #fff9c4 #fbc02d Infrastructure #e1f5fe #0288d1 Hardware/Devices #ffccbc #e64a19 User/External #f5f5f5 #bdbdbd"},{"location":"mkdocs-config-update/#benefits","title":"Benefits","text":"<ol> <li>Standard MkDocs Structure: Following MkDocs best practices for configuration location</li> <li>Simplified Commands: Documentation commands can now run from project root</li> <li>Fixed Build Issues: Resolved issues with docs_dir configuration</li> <li>Improved Dependency Management: All documentation dependencies now properly specified in pyproject.toml</li> <li>Enhanced Visual Communication: Complex architecture and processes illustrated with diagrams</li> <li>Clearer Organization: Distinct separation between user and developer documentation</li> <li>Consistent Visual Language: Standardized diagram styling across all documentation</li> </ol>"},{"location":"mkdocs-config-update/#how-to-use","title":"How to Use","text":""},{"location":"mkdocs-config-update/#serving-documentation-locally","title":"Serving Documentation Locally","text":"<p>Use the VS Code task \"Server: Serve Documentation\" or run:</p> <pre><code>cd /Users/ryan/src/rvc2api\npoetry run mkdocs serve\n</code></pre> <p>Then visit http://localhost:8000 in your browser.</p>"},{"location":"mkdocs-config-update/#building-documentation","title":"Building Documentation","text":"<p>Use the VS Code task \"Build: Documentation\" or run:</p> <pre><code>cd /Users/ryan/src/rvc2api\npoetry run mkdocs build\n</code></pre> <p>Output will be in the <code>/Users/ryan/src/rvc2api/site</code> directory.</p>"},{"location":"mkdocs-config-update/#updating-api-documentation","title":"Updating API Documentation","text":"<p>Use the VS Code task \"API: Update Documentation\" or run:</p> <pre><code>cd /Users/ryan/src/rvc2api\npoetry run python scripts/export_openapi.py\npoetry run mkdocs build\n</code></pre> <p>This will export the OpenAPI schema and rebuild the documentation.</p>"},{"location":"mkdocs-versioning-integration/","title":"MkDocs Versioning with Release-Please","text":"<p>This document explains how the documentation versioning system is integrated with our release process using release-please.</p>"},{"location":"mkdocs-versioning-integration/#overview","title":"Overview","text":"<p>We use a combination of tools to maintain versioned documentation that automatically stays in sync with our software releases:</p> <ol> <li>mike: A versioning plugin for MkDocs that manages multiple versions of documentation</li> <li>release-please: Automates version bumps, changelog generation, and release creation</li> <li>GitHub Actions: Automates the deployment of versioned documentation</li> </ol> <p>This integration ensures that whenever a new version is released:</p> <ul> <li>A new documentation version is created with that version number</li> <li>The <code>VERSION</code> file is updated to reflect the new version</li> <li>Users can access both the latest and previous documentation versions</li> </ul>"},{"location":"mkdocs-versioning-integration/#how-it-works","title":"How It Works","text":""},{"location":"mkdocs-versioning-integration/#versioning-strategy","title":"Versioning Strategy","text":"<p>Documentation versions follow the same semantic versioning scheme as the codebase:</p> <ul> <li><code>latest</code>: Always points to the most recent stable release</li> <li><code>x.y.z</code>: Specific version numbers (e.g., <code>0.1.0</code>, <code>1.2.3</code>)</li> <li><code>dev</code>: Development version (latest on the main branch)</li> </ul>"},{"location":"mkdocs-versioning-integration/#automatic-version-updates","title":"Automatic Version Updates","text":"<p>When changes are pushed to the main branch:</p> <ol> <li>release-please analyzes commit messages to determine if a release is needed</li> <li> <p>If a release is created, release-please:</p> </li> <li> <p>Creates a new version tag (e.g., <code>v1.2.3</code>)</p> </li> <li>Updates CHANGELOG.md</li> <li>Updates version references in code</li> <li> <p>Updates the <code>VERSION</code> file with the new version number</p> </li> <li> <p>The new tag triggers the <code>deploy-versioned-docs.yml</code> workflow, which:</p> </li> <li>Builds the documentation with the correct version number</li> <li>Deploys it to GitHub Pages using mike</li> <li>Sets the version as the default/latest if appropriate</li> </ol>"},{"location":"mkdocs-versioning-integration/#manual-documentation-updates","title":"Manual Documentation Updates","text":"<p>Between releases, documentation updates are handled by:</p> <ol> <li>The <code>deploy-docs.yml</code> workflow, which updates the <code>dev</code> version</li> <li>This is triggered by changes to documentation files or manual workflow dispatch</li> </ol>"},{"location":"mkdocs-versioning-integration/#working-with-versioned-documentation","title":"Working with Versioned Documentation","text":""},{"location":"mkdocs-versioning-integration/#viewing-different-versions","title":"Viewing Different Versions","text":"<p>The documentation site includes a version picker (typically in the header) that allows users to switch between different versions.</p>"},{"location":"mkdocs-versioning-integration/#local-development","title":"Local Development","text":"<p>For local documentation development with versioning:</p> <pre><code># Serve the documentation with live reloading (current working directory)\npoetry run mkdocs serve\n\n# Build and deploy a specific version locally\npoetry run mike deploy 1.2.3\n\n# Set a version as default\npoetry run mike set-default 1.2.3 --push\n\n# Deploy the dev version\npoetry run mike deploy dev\n\n# Serve the versioned documentation locally\npoetry run mike serve\n</code></pre>"},{"location":"mkdocs-versioning-integration/#vs-code-tasks","title":"VS Code Tasks","text":"<p>VS Code tasks are provided for common documentation versioning operations:</p> <ul> <li>Docs: Serve Versioned Documentation: Start a local mike server with versioned docs</li> <li>Docs: Deploy Version: Deploy a specific version (prompts for version)</li> <li>Docs: List Versions: List all currently deployed versions</li> <li>Docs: Deploy Current Version: Deploy using the version from pyproject.toml</li> <li>Docs: Set Default Version: Set the current version from pyproject.toml as default</li> <li>Docs: Deploy Dev Version: Deploy the current state as the \"dev\" version</li> </ul>"},{"location":"mkdocs-versioning-integration/#configuration-details","title":"Configuration Details","text":""},{"location":"mkdocs-versioning-integration/#mkdocs-configuration","title":"MkDocs Configuration","text":"<p>In <code>mkdocs.yml</code>, the mike plugin is configured:</p> <pre><code>plugins:\n  # Other plugins...\n  - mike\n\nextra:\n  version:\n    provider: mike\n</code></pre>"},{"location":"mkdocs-versioning-integration/#github-actions-workflows","title":"GitHub Actions Workflows","text":"<ul> <li>release-please.yml: Handles version bumping and release creation</li> <li>deploy-versioned-docs.yml: Deploys version-specific documentation when a new tag is created</li> <li>deploy-docs.yml: Updates the \"dev\" documentation between releases</li> </ul>"},{"location":"mkdocs-versioning-integration/#integration-with-openapi","title":"Integration with OpenAPI","text":"<p>The OpenAPI schema is automatically generated before building the documentation:</p> <pre><code>- name: Generate OpenAPI schema\n  run: |\n    poetry run python scripts/export_openapi.py\n</code></pre> <p>This ensures that the API documentation is always up-to-date with the current version.</p>"},{"location":"mkdocs-versioning-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"mkdocs-versioning-integration/#common-issues","title":"Common Issues","text":"<ul> <li>Missing Version in Dropdown: Make sure the version was properly deployed with mike</li> <li>Wrong Default Version: Use <code>mike set-default</code> to correct it</li> <li>Build Failures: Check that the GitHub Actions workflow has the correct permissions</li> </ul>"},{"location":"mkdocs-versioning-integration/#manually-deploying-a-version","title":"Manually Deploying a Version","text":"<p>If needed, you can manually trigger the <code>deploy-versioned-docs.yml</code> workflow:</p> <ol> <li>Go to Actions \u2192 Deploy Versioned Documentation \u2192 Run workflow</li> <li>Enter the version number (without the 'v' prefix)</li> <li>Choose whether to set it as the default</li> </ol>"},{"location":"mkdocs-versioning-integration/#related-documentation","title":"Related Documentation","text":"<ul> <li>GitHub Pages Deployment</li> <li>GitHub Actions Summary</li> <li>Documentation Organization</li> </ul>"},{"location":"mkdocs-versioning/","title":"Documentation Versioning","text":"<p>rvc2api documentation uses version-specific documentation that matches the software releases. This approach ensures that users can access documentation that corresponds exactly to the version they are using.</p>"},{"location":"mkdocs-versioning/#how-documentation-versioning-works","title":"How Documentation Versioning Works","text":"<p>We use mike, a versioning plugin for MkDocs, to manage multiple versions of our documentation. This allows:</p> <ul> <li>Documentation to be versioned alongside code releases</li> <li>Users to easily switch between different versions</li> <li>The latest version to be marked as the default</li> <li>Older versions to remain accessible</li> </ul>"},{"location":"mkdocs-versioning/#versioning-strategy","title":"Versioning Strategy","text":"<p>Documentation versions follow the same semantic versioning scheme as the codebase:</p> <ul> <li><code>latest</code> - Always points to the most recent stable release</li> <li><code>x.y.z</code> - Specific version numbers (e.g., <code>0.1.0</code>, <code>1.2.3</code>)</li> <li><code>dev</code> - Development version (latest on the main branch)</li> </ul>"},{"location":"mkdocs-versioning/#how-documentation-is-released","title":"How Documentation is Released","text":"<p>Documentation is released automatically through our GitHub Actions workflows:</p> <ol> <li> <p>When a new version is released via release-please (e.g., tag <code>v1.2.3</code>):</p> </li> <li> <p>The <code>deploy-versioned-docs.yml</code> workflow is triggered</p> </li> <li>It builds the documentation with the correct version number</li> <li> <p>It deploys the documentation to GitHub Pages under the specific version</p> </li> <li> <p>For manual documentation updates between releases:</p> </li> <li>The <code>deploy-docs.yml</code> workflow updates the <code>dev</code> version</li> <li>This happens whenever changes are pushed to the <code>main</code> branch</li> </ol>"},{"location":"mkdocs-versioning/#viewing-different-documentation-versions","title":"Viewing Different Documentation Versions","text":"<p>When viewing the documentation site, you can use the version picker (typically in the header) to switch between different versions.</p>"},{"location":"mkdocs-versioning/#for-maintainers-manual-version-deployment","title":"For Maintainers: Manual Version Deployment","text":"<p>You can manually deploy a specific version of the documentation using the GitHub Actions workflow:</p> <ol> <li>Go to the \"Actions\" tab in the repository</li> <li>Select the \"Deploy Versioned Documentation\" workflow</li> <li>Click \"Run workflow\"</li> <li>Enter the version number (without the 'v' prefix, e.g., <code>1.2.3</code>)</li> <li>Choose whether to set it as the default version</li> <li>Click \"Run workflow\"</li> </ol>"},{"location":"mkdocs-versioning/#local-documentation-development","title":"Local Documentation Development","text":"<p>For local documentation development and testing with versioning:</p> <pre><code># Install dependencies\npoetry install\n\n# Generate OpenAPI schema\npoetry run python scripts/export_openapi.py\n\n# Serve the documentation with live reloading (development version)\npoetry run mkdocs serve\n\n# Build a specific version locally\npoetry run mike deploy 1.2.3 --push\n\n# Set a version as default\npoetry run mike set-default 1.2.3 --push\n\n# Serve the versioned documentation locally\npoetry run mike serve\n</code></pre>"},{"location":"mkdocs-versioning/#integration-with-release-please","title":"Integration with Release-Please","text":"<p>Our documentation versioning is integrated with release-please, which manages version numbers and the changelog. When release-please creates a new release:</p> <ol> <li>It increments the version in the <code>VERSION</code> file</li> <li>It creates a tag with the new version</li> <li>The tag triggers the versioned documentation workflow</li> <li>The documentation is built and deployed with the correct version number</li> </ol> <p>This ensures that documentation versions always match released software versions.</p>"},{"location":"nix-devcontainer-performance/","title":"Nix in Devcontainer Performance Guide","text":"<p>This document explains how Nix is set up in the devcontainer and provides guidance on performance optimization.</p>"},{"location":"nix-devcontainer-performance/#overview-of-nix-setup","title":"Overview of Nix Setup","text":"<p>The devcontainer is configured to use Nix in an optimized way:</p> <ol> <li> <p>Named Volume for Nix Store: Instead of a bind mount, the Nix store uses a Docker named volume (<code>rvc2api-nix-store</code>) for better performance and to avoid permission issues.</p> </li> <li> <p>Optimized Nix Configuration: Custom configuration in <code>~/.config/nix/nix.conf</code> improves caching and performance.</p> </li> <li> <p>Error Handling: Wrapper scripts automatically handle common Nix errors like \"File exists\" issues.</p> </li> </ol>"},{"location":"nix-devcontainer-performance/#common-commands","title":"Common Commands","text":""},{"location":"nix-devcontainer-performance/#using-nix","title":"Using Nix","text":"<ul> <li>Enter Nix Shell: <code>nix-develop</code> (aliased wrapper for error handling)</li> <li>Standard Command: <code>nix develop</code> (without error handling)</li> </ul>"},{"location":"nix-devcontainer-performance/#fixing-issues","title":"Fixing Issues","text":"<p>If you encounter Nix-related issues:</p> <ol> <li>Manual Fix for \"File exists\" Error:</li> </ol> <pre><code>sudo /workspace/.devcontainer/scripts/fix-nix-errors.sh\n</code></pre> <ol> <li>Reset Nix Configuration:</li> </ol> <pre><code>/workspace/.devcontainer/scripts/setup-nix-config.sh\n</code></pre> <ol> <li>VS Code Task: Use the \"Dev: Enter Nix Shell\" VS Code task, which uses the optimized wrapper</li> </ol>"},{"location":"nix-devcontainer-performance/#performance-tips","title":"Performance Tips","text":"<ol> <li> <p>Keep Nix Store Volume: Don't delete the Docker volume named <code>rvc2api-nix-store</code> between container rebuilds to maintain your cache.</p> </li> <li> <p>Use Flakes: Nix Flakes provide better caching and reproducibility.</p> </li> <li> <p>Consider GC: Run <code>nix-collect-garbage</code> periodically to clean up unused storage.</p> </li> </ol>"},{"location":"nix-devcontainer-performance/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter slow performance or errors:</p> <ol> <li> <p>Check Logs: Review <code>/workspace/nix_develop.log</code> and <code>/workspace/nix_fix.log</code> for issues.</p> </li> <li> <p>Update Configuration: Ensure <code>/workspace/.devcontainer/nix.conf</code> has appropriate settings.</p> </li> <li> <p>Restart Container: Sometimes a container restart will resolve permission issues.</p> </li> </ol>"},{"location":"nix-integration-simplified/","title":"Simplified Nix Integration for rvc2api","text":"<p>This document explains the changes to the Nix integration in rvc2api:</p>"},{"location":"nix-integration-simplified/#key-changes","title":"Key Changes","text":"<ol> <li>Version Source of Truth: Changed from <code>VERSION</code> file to <code>pyproject.toml</code></li> <li>The version is now extracted directly from <code>pyproject.toml</code> in <code>flake.nix</code></li> <li> <p>The <code>VERSION</code> file has been removed as it's no longer needed</p> </li> <li> <p>Simplified Development Environment:</p> </li> <li>Moved from a complex poetry2nix setup to a simpler direct Poetry approach</li> <li>The <code>nix develop</code> shell now uses Poetry directly for dependency management</li> <li> <p>This avoids the numerous package override issues encountered with poetry2nix</p> </li> <li> <p>Workflow Improvements:</p> </li> <li>Automatic Poetry virtualenv setup in the devShell</li> <li>Proper library paths for native dependencies</li> <li>Better shell experience with clear instructions</li> <li>Simplified dependency management</li> </ol>"},{"location":"nix-integration-simplified/#benefits","title":"Benefits","text":"<ul> <li>Single Source of Truth: Version information is now only maintained in <code>pyproject.toml</code></li> <li>Improved Reliability: The development environment is more reliable and simpler to maintain</li> <li>Reduced Complexity: Fewer overrides and complex configurations</li> <li>Better Developer Experience: The shell setup is automatic and provides helpful information</li> </ul>"},{"location":"nix-integration-simplified/#using-the-dev-environment","title":"Using the Dev Environment","text":"<ol> <li> <p>Enter the development shell:    <pre><code>nix develop\n</code></pre></p> </li> <li> <p>Run Python commands through Poetry:    <pre><code>poetry run python src/core_daemon/main.py\npoetry run pytest\n</code></pre></p> </li> <li> <p>Install additional dependencies:    <pre><code>poetry add &lt;package&gt;\n</code></pre></p> </li> </ol>"},{"location":"nix-integration-simplified/#how-versioning-works","title":"How Versioning Works","text":"<ol> <li>The version is defined in <code>pyproject.toml</code> under <code>[tool.poetry].version</code></li> <li>For releases, this version is updated by release-please</li> <li>The <code>flake.nix</code> reads this version using:    <pre><code>version = let\n  pyproject = builtins.fromTOML (builtins.readFile ./pyproject.toml);\nin pyproject.tool.poetry.version;\n</code></pre></li> </ol>"},{"location":"nix-integration-simplified/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues with the Nix environment:</p> <ol> <li> <p>Make sure you have the latest flake.nix and flake.lock by running:    <pre><code>git pull\n</code></pre></p> </li> <li> <p>Reset the environment with:    <pre><code>rm -rf .venv\nnix develop\n</code></pre></p> </li> <li> <p>For dependency issues, try updating Poetry's lock file:    <pre><code>poetry update\n</code></pre></p> </li> </ol>"},{"location":"nixos-integration/","title":"Using rvc2api in NixOS Configurations","text":"<p>This document explains how to include and configure rvc2api in other NixOS systems and flakes.</p>"},{"location":"nixos-integration/#overview","title":"Overview","text":"<p>rvc2api is packaged as a Nix flake with:</p> <ul> <li>A standalone Python package</li> <li>A NixOS module for system integration</li> <li>Configuration options for customization</li> </ul>"},{"location":"nixos-integration/#basic-usage","title":"Basic Usage","text":""},{"location":"nixos-integration/#including-rvc2api-in-your-flake","title":"Including rvc2api in Your Flake","text":"<p>Add rvc2api to your flake inputs:</p> <pre><code>{\n  inputs = {\n    nixpkgs.url = \"github:nixos/nixpkgs/nixos-unstable\";\n\n    # Add rvc2api as a dependency\n    rvc2api.url = \"github:carpenike/rvc2api\";\n    rvc2api.inputs.nixpkgs.follows = \"nixpkgs\"; # Optional: Use your nixpkgs\n  };\n\n  outputs = { self, nixpkgs, rvc2api, ... }: {\n    # Your outputs...\n  };\n}\n</code></pre>"},{"location":"nixos-integration/#as-a-package","title":"As a Package","text":"<p>To simply include rvc2api as a package:</p> <pre><code>environment.systemPackages = [\n  inputs.rvc2api.packages.${system}.rvc2api\n];\n</code></pre>"},{"location":"nixos-integration/#as-a-nixos-module","title":"As a NixOS Module","text":"<p>For a complete integration with configuration options:</p> <pre><code>{\n  imports = [\n    inputs.rvc2api.nixosModules.rvc2api\n  ];\n\n  rvc2api = {\n    enable = true;\n    settings = {\n      # See detailed configuration options in docs/nixos-module.md\n      canbus.channels = [ \"can0\" ];\n    };\n  };\n}\n</code></pre> <p>For complete configuration options, see the NixOS Module Documentation. ];</p>"},{"location":"nixos-integration/#enable-the-service","title":"Enable the service","text":"<p>rvc2api.enable = true;</p>"},{"location":"nixos-integration/#configure-options","title":"Configure options","text":"<p>rvc2api.settings = { pushover = { enable = true; apiToken = \"your-pushover-api-token\"; userKey = \"your-pushover-user-key\"; }; }; }</p> <pre><code>## Configuration Options\n\nrvc2api provides the following configuration options:\n\n### Basic Options\n\n```nix\nrvc2api = {\n  enable = true;        # Enable the rvc2api module\n  package = pkgs.rvc2api;  # Optional: override the package\n};\n</code></pre>"},{"location":"nixos-integration/#pushover-notifications","title":"Pushover Notifications","text":"<pre><code>rvc2api.settings.pushover = {\n  enable = true;        # Enable Pushover integration\n  apiToken = \"token\";   # Your Pushover API token\n  userKey = \"key\";      # Your Pushover user key\n};\n</code></pre>"},{"location":"nixos-integration/#development-usage","title":"Development Usage","text":"<p>To develop against rvc2api:</p> <pre><code># Enter the development shell\nnix develop github:carpenike/rvc2api\n\n# Or specify a specific attribute\nnix develop github:carpenike/rvc2api#ci  # For CI environment\n</code></pre>"},{"location":"nixos-integration/#architecture-support","title":"Architecture Support","text":"<p>rvc2api supports the following architectures:</p> <ul> <li>x86_64-linux</li> <li>aarch64-linux (Raspberry Pi 4, etc.)</li> </ul>"},{"location":"nixos-integration/#version-management","title":"Version Management","text":"<p>rvc2api follows semantic versioning with releases managed via GitHub's release-please automation. You can pin to specific tags in your flake for stability:</p> <pre><code>rvc2api.url = \"github:carpenike/rvc2api/v1.0.0\";\n</code></pre>"},{"location":"nixos-module/","title":"NixOS Module Configuration for rvc2api","text":"<p>This document provides detailed configuration options for the <code>rvc2api</code> NixOS module, which allows you to manage the rvc2api service as part of your NixOS system configuration.</p>"},{"location":"nixos-module/#basic-usage","title":"Basic Usage","text":"<p>To use the <code>rvc2api</code> module in your NixOS configuration:</p> <pre><code># In your configuration.nix or flake.nix\n{\n  imports = [\n    # Other imports...\n    inputs.rvc2api.nixosModules.rvc2api\n  ];\n\n  # Enable the service\n  rvc2api = {\n    enable = true;\n    settings = {\n      # Configuration options here\n    };\n  };\n}\n</code></pre>"},{"location":"nixos-module/#configuration-options","title":"Configuration Options","text":""},{"location":"nixos-module/#main-options","title":"Main Options","text":"Option Type Default Description <code>enable</code> boolean <code>false</code> Enable the rvc2api service <code>package</code> package <code>self.packages.&lt;system&gt;.rvc2api</code> The rvc2api package to use"},{"location":"nixos-module/#server-configuration","title":"Server Configuration","text":"<p>These settings control the API server.</p> Option Type Default Description <code>settings.host</code> string <code>\"0.0.0.0\"</code> Host IP to bind the API server to <code>settings.port</code> int <code>8000</code> Port to run the API server on <code>settings.logLevel</code> string <code>\"INFO\"</code> Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)"},{"location":"nixos-module/#controller-configuration","title":"Controller Configuration","text":"Option Type Default Description <code>settings.controllerSourceAddr</code> string <code>\"0xF9\"</code> Controller source address in hex"},{"location":"nixos-module/#pushover-integration","title":"Pushover Integration","text":"<p>Pushover is used for sending notifications from the service.</p> Option Type Default Description <code>settings.pushover.enable</code> boolean <code>false</code> Enable Pushover integration <code>settings.pushover.apiToken</code> string <code>\"\"</code> Pushover API token <code>settings.pushover.userKey</code> string <code>\"\"</code> Pushover user key <code>settings.pushover.device</code> null or string <code>null</code> Optional Pushover device name <code>settings.pushover.priority</code> null or int <code>null</code> Optional Pushover message priority"},{"location":"nixos-module/#uptimerobot-integration","title":"UptimeRobot Integration","text":"<p>UptimeRobot is used for monitoring service health.</p> Option Type Default Description <code>settings.uptimerobot.enable</code> boolean <code>false</code> Enable UptimeRobot integration <code>settings.uptimerobot.apiKey</code> string <code>\"\"</code> UptimeRobot API key"},{"location":"nixos-module/#can-bus-configuration","title":"CAN Bus Configuration","text":"<p>These settings control how the service interacts with the RV's CAN bus.</p> Option Type Default Description <code>settings.canbus.channels</code> list of strings <code>[ \"can0\" ]</code> SocketCAN interfaces to listen on <code>settings.canbus.bustype</code> string <code>\"socketcan\"</code> Python-CAN bus type <code>settings.canbus.bitrate</code> int <code>500000</code> CAN bus bitrate"},{"location":"nixos-module/#rv-c-spec-and-device-mapping","title":"RV-C Spec and Device Mapping","text":"<p>These settings allow customizing the RV-C specification and device mapping files.</p> Option Type Default Description <code>settings.rvcSpecPath</code> null or string <code>null</code> Override path to <code>rvc.json</code> (RVC spec file) <code>settings.deviceMappingPath</code> null or string <code>null</code> Override path to device mapping file <code>settings.modelSelector</code> null or string <code>null</code> Model selector for device mapping file <code>settings.userCoachInfoPath</code> null or string <code>null</code> Path to user coach info YAML file"},{"location":"nixos-module/#github-integration","title":"GitHub Integration","text":"Option Type Default Description <code>settings.githubUpdateRepo</code> null or string <code>null</code> GitHub repository to check for updates (format: owner/repo)"},{"location":"nixos-module/#example-configurations","title":"Example Configurations","text":""},{"location":"nixos-module/#basic-configuration","title":"Basic Configuration","text":"<pre><code>rvc2api = {\n  enable = true;\n  settings.canbus.channels = [ \"can0\" \"can1\" ];\n};\n</code></pre>"},{"location":"nixos-module/#complete-configuration","title":"Complete Configuration","text":"<pre><code>rvc2api = {\n  enable = true;\n\n  # Use a specific package version\n  package = pkgs.rvc2api;\n\n  settings = {\n    # Server configuration\n    host = \"0.0.0.0\";\n    port = 8000;\n    logLevel = \"INFO\";  # Or \"DEBUG\" for more verbose output\n\n    # Controller configuration\n    controllerSourceAddr = \"0xF9\";\n\n    # Pushover notifications\n    pushover = {\n      enable = true;\n      apiToken = \"your-api-token\";\n      userKey = \"your-user-key\";\n      device = \"mydevice\";\n      priority = 1;\n    };\n\n    # UptimeRobot monitoring\n    uptimerobot = {\n      enable = true;\n      apiKey = \"your-api-key\";\n    };\n\n    # CAN bus settings\n    canbus = {\n      channels = [ \"can0\" \"vcan0\" ];\n      bustype = \"socketcan\";\n      bitrate = 500000;\n    };\n\n    # Use a specific RV model's mapping file\n    modelSelector = \"2021_Entegra_Aspire_44R\";\n\n    # Or specify custom mapping paths\n    # rvcSpecPath = \"/path/to/custom/rvc.json\";\n    # deviceMappingPath = \"/path/to/custom/device_mapping.yml\";\n\n    # User coach information\n    userCoachInfoPath = \"/path/to/coach_info.yml\";\n\n    # GitHub update checker\n    githubUpdateRepo = \"carpenike/rvc2api\";\n  };\n};\n</code></pre>"},{"location":"nixos-module/#environment-variables","title":"Environment Variables","text":"<p>The NixOS module automatically sets up these environment variables for the systemd service:</p> Environment Variable Derived From <code>ENABLE_PUSHOVER</code> <code>settings.pushover.enable</code> <code>PUSHOVER_API_TOKEN</code> <code>settings.pushover.apiToken</code> <code>PUSHOVER_USER_KEY</code> <code>settings.pushover.userKey</code> <code>PUSHOVER_DEVICE</code> <code>settings.pushover.device</code> <code>PUSHOVER_PRIORITY</code> <code>settings.pushover.priority</code> <code>ENABLE_UPTIMEROBOT</code> <code>settings.uptimerobot.enable</code> <code>UPTIMEROBOT_API_KEY</code> <code>settings.uptimerobot.apiKey</code> <code>CAN_CHANNELS</code> <code>settings.canbus.channels</code> (comma-separated) <code>CAN_BUSTYPE</code> <code>settings.canbus.bustype</code> <code>CAN_BITRATE</code> <code>settings.canbus.bitrate</code> <code>RVC2API_HOST</code> <code>settings.host</code> <code>RVC2API_PORT</code> <code>settings.port</code> <code>LOG_LEVEL</code> <code>settings.logLevel</code> <code>CONTROLLER_SOURCE_ADDR</code> <code>settings.controllerSourceAddr</code> <code>GITHUB_UPDATE_REPO</code> <code>settings.githubUpdateRepo</code> <code>CAN_MODEL_SELECTOR</code> <code>settings.modelSelector</code> <code>CAN_SPEC_PATH</code> <code>settings.rvcSpecPath</code> <code>CAN_MAP_PATH</code> Complex logic based on <code>deviceMappingPath</code> and <code>modelSelector</code> <code>RVC2API_USER_COACH_INFO_PATH</code> <code>settings.userCoachInfoPath</code>"},{"location":"nixos-module/#advanced-configuration","title":"Advanced Configuration","text":"<p>For advanced use cases, you might want to override the package to use a custom version:</p> <pre><code>rvc2api = {\n  enable = true;\n  package = pkgs.callPackage ./path/to/custom-rvc2api.nix {};\n  # ...other settings\n};\n</code></pre> <p>Or use inputs from a flake for package references:</p> <pre><code>rvc2api = {\n  enable = true;\n  package = inputs.rvc2api.packages.${pkgs.system}.rvc2api;\n  # ...other settings\n};\n</code></pre>"},{"location":"pdf-processing-guide-new/","title":"PDF Processing Guide for Vector Search","text":"<p>This guide explains how to process PDF files through the enhanced document processor to generate embeddings for the FAISS index in the RVC2API project. The tool supports multiple chunking strategies and can automatically detect the most appropriate strategy for your document.</p>"},{"location":"pdf-processing-guide-new/#workflow-overview","title":"Workflow Overview","text":"<p>The process of adding a new PDF document to the searchable FAISS index involves these steps:</p> <ol> <li>Prepare the PDF document - Place in resources directory</li> <li>Process the PDF into chunks - Generate text chunks with appropriate strategy</li> <li>Create embeddings and update the index - Convert chunks to vectors and add to FAISS</li> <li>Verify and test the search - Ensure the new content is searchable</li> </ol>"},{"location":"pdf-processing-guide-new/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+ with proper type annotations</li> <li>OpenAI API key set in your environment (<code>export OPENAI_API_KEY=your-api-key</code>)</li> <li>Poetry dependencies installed with <code>poetry install --with devtools</code></li> <li>PDF document(s) you want to add to the search index</li> </ul>"},{"location":"pdf-processing-guide-new/#step-1-prepare-your-pdf-document","title":"Step 1: Prepare Your PDF Document","text":"<ol> <li>Place your PDF file in the <code>resources/</code> directory</li> <li>Recommended: Use a consistent naming convention that describes content and version    <pre><code>resources/your-document-name-2023.pdf\n</code></pre></li> </ol>"},{"location":"pdf-processing-guide-new/#step-2-choose-a-chunking-strategy","title":"Step 2: Choose a Chunking Strategy","text":"<p>Select the appropriate chunking strategy based on your document's structure:</p> Document Type Recommended Strategy Use Case RV-C Specification <code>SECTION_OVERLAP</code> Technical specifications with section numbers Equipment Manuals <code>PARAGRAPH</code> User manuals with natural paragraphs Generic PDFs <code>SLIDING_WINDOW</code> General text with no clear structure Technical Docs <code>TOKEN</code> Fixed-size token-based chunks"},{"location":"pdf-processing-guide-new/#step-3-process-your-pdf-with-the-enhanced-document-processor","title":"Step 3: Process Your PDF with the Enhanced Document Processor","text":"<p>Use the enhanced document processor (<code>enhanced_document_processor.py</code>) which supports multiple chunking strategies and can automatically detect the most appropriate strategy for your document.</p>"},{"location":"pdf-processing-guide-new/#basic-usage-auto-detect","title":"Basic Usage (Auto-Detect)","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py --pdf resources/your-document-name-2023.pdf\n</code></pre> <p>This will:</p> <ol> <li>Auto-detect the best chunking strategy based on document structure</li> <li>Process the document with the selected strategy</li> <li>Save chunks to <code>resources/your-document-name-2023_chunks.json</code></li> </ol>"},{"location":"pdf-processing-guide-new/#specify-chunking-strategy","title":"Specify Chunking Strategy","text":"<p>You can specify a chunking strategy if you know what works best for your document:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --chunking section_overlap\n</code></pre> <p>Available chunking strategies:</p> <ul> <li><code>section_overlap</code>: For technical specifications with clear section numbering</li> <li><code>paragraph</code>: For manuals and documents with natural paragraph breaks</li> <li><code>sliding_window</code>: For generic documents with no clear structure</li> <li><code>token</code>: For fixed-size token-based chunking</li> </ul>"},{"location":"pdf-processing-guide-new/#process-and-add-to-faiss-index-in-one-step","title":"Process and Add to FAISS Index in One Step","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --add-to-index resources/vector_store/rvc_spec_index\n</code></pre> <p>This processes the PDF and adds it to an existing FAISS index in one operation.</p>"},{"location":"pdf-processing-guide-new/#create-a-new-faiss-index","title":"Create a New FAISS Index","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --add-to-index resources/vector_store/new_index \\\n  --create-new-index\n</code></pre> <p>This processes the PDF and creates a new FAISS index.</p>"},{"location":"pdf-processing-guide-new/#chunking-strategy-options","title":"Chunking Strategy Options","text":""},{"location":"pdf-processing-guide-new/#section-based-chunking","title":"Section-Based Chunking","text":"<p>Best for technical specifications with clear section numbering:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --chunking section_overlap \\\n  --section-pattern \"^(\\d+\\.\\d+(\\.\\d+)?)(\\s+)(.+)\" \\\n  --overlap 5\n</code></pre>"},{"location":"pdf-processing-guide-new/#paragraph-based-chunking","title":"Paragraph-Based Chunking","text":"<p>Best for manuals and documents with natural paragraph breaks:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --chunking paragraph\n</code></pre>"},{"location":"pdf-processing-guide-new/#sliding-window-chunking","title":"Sliding Window Chunking","text":"<p>Best for generic documents with no clear structure:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --chunking sliding_window \\\n  --window-size 10 \\\n  --overlap 3\n</code></pre>"},{"location":"pdf-processing-guide-new/#token-based-chunking","title":"Token-Based Chunking","text":"<p>Best for fixed-size chunks:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --chunking token \\\n  --chunk-size 512 \\\n  --overlap 50\n</code></pre>"},{"location":"pdf-processing-guide-new/#advanced-options","title":"Advanced Options","text":""},{"location":"pdf-processing-guide-new/#custom-output-path","title":"Custom Output Path","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --output resources/custom_output_name.json\n</code></pre>"},{"location":"pdf-processing-guide-new/#specify-embedding-model","title":"Specify Embedding Model","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --add-to-index resources/vector_store/rvc_spec_index \\\n  --model text-embedding-3-small\n</code></pre>"},{"location":"pdf-processing-guide-new/#step-4-test-your-index","title":"Step 4: Test Your Index","text":"<p>Verify that your document is properly indexed and searchable:</p> <pre><code># Test searching in the index\npoetry run python dev_tools/query_faiss.py \"your search query\" --source \"your-document-name-2023.pdf\"\n</code></pre>"},{"location":"pdf-processing-guide-new/#examples-by-document-type","title":"Examples by Document Type","text":""},{"location":"pdf-processing-guide-new/#technical-specification","title":"Technical Specification","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/rvc-spec-2023-11.pdf \\\n  --chunking section_overlap \\\n  --add-to-index resources/vector_store/rvc_spec_index\n</code></pre>"},{"location":"pdf-processing-guide-new/#user-manual","title":"User Manual","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/victron-multiplus-manual.pdf \\\n  --chunking paragraph \\\n  --add-to-index resources/vector_store/manuals_index\n</code></pre>"},{"location":"pdf-processing-guide-new/#generic-pdf","title":"Generic PDF","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/misc-document.pdf \\\n  --chunking sliding_window \\\n  --add-to-index resources/vector_store/misc_index\n</code></pre>"},{"location":"pdf-processing-guide-new/#troubleshooting","title":"Troubleshooting","text":""},{"location":"pdf-processing-guide-new/#common-issues","title":"Common Issues","text":"<ul> <li>Missing API key: Set <code>export OPENAI_API_KEY=your-api-key</code></li> <li>PDF extraction errors: Use PyMuPDF debugging tools and check PDF encoding</li> <li>Chunks too large: Adjust chunking strategy for shorter text segments</li> <li>Inconsistent metadata: Ensure document_loader is used for all sources</li> </ul>"},{"location":"pdf-processing-guide-new/#testing-document-loader","title":"Testing Document Loader","text":"<p>Use the test_document_loader.py script to verify your chunks are correctly processed:</p> <pre><code>poetry run python dev_tools/test_document_loader.py\n</code></pre>"},{"location":"pdf-processing-guide-new/#references","title":"References","text":"<ul> <li>LangChain FAISS Integration</li> <li>PyMuPDF Documentation</li> <li>OpenAI Embeddings Documentation</li> </ul>"},{"location":"pdf-processing-guide/","title":"PDF Processing Guide for Vector Search","text":"<p>This guide explains how to process PDF files through the enhanced document processor to generate embeddings for the FAISS index in the RVC2API project. The tool supports multiple chunking strategies and can automatically detect the most appropriate strategy for your document.</p>"},{"location":"pdf-processing-guide/#workflow-overview","title":"Workflow Overview","text":"<p>The process of adding a new PDF document to the searchable FAISS index involves these steps:</p> <ol> <li>Prepare the PDF document - Place in resources directory</li> <li>Process the PDF into chunks - Generate text chunks with appropriate strategy</li> <li>Create embeddings and update the index - Convert chunks to vectors and add to FAISS</li> <li>Verify and test the search - Ensure the new content is searchable</li> </ol>"},{"location":"pdf-processing-guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+ with proper type annotations</li> <li>OpenAI API key set in your environment (<code>export OPENAI_API_KEY=your-api-key</code>)</li> <li>Poetry dependencies installed with <code>poetry install --with devtools</code></li> <li>PDF document(s) you want to add to the search index</li> </ul>"},{"location":"pdf-processing-guide/#step-1-prepare-your-pdf-document","title":"Step 1: Prepare Your PDF Document","text":"<ol> <li>Place your PDF file in the <code>resources/</code> directory</li> <li>Recommended: Use a consistent naming convention that describes content and version    <pre><code>resources/your-document-name-2023.pdf\n</code></pre></li> </ol>"},{"location":"pdf-processing-guide/#step-2-process-your-pdf-with-the-enhanced-document-processor","title":"Step 2: Process Your PDF with the Enhanced Document Processor","text":"<p>The enhanced document processor (<code>enhanced_document_processor.py</code>) supports multiple chunking strategies and can automatically detect the most appropriate strategy for your document.</p>"},{"location":"pdf-processing-guide/#basic-usage-auto-detect","title":"Basic Usage (Auto-Detect)","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py --pdf resources/your-document-name-2023.pdf\n</code></pre> <p>This will:</p> <ol> <li>Auto-detect the best chunking strategy based on document structure</li> <li>Process the document with the selected strategy</li> <li>Save chunks to <code>resources/your-document-name-2023_chunks.json</code></li> </ol>"},{"location":"pdf-processing-guide/#specify-chunking-strategy","title":"Specify Chunking Strategy","text":"<p>You can specify a chunking strategy if you know what works best for your document:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --chunking section_overlap\n</code></pre> <p>Available chunking strategies:</p> <ul> <li><code>section_overlap</code>: For technical specifications with clear section numbering</li> <li><code>paragraph</code>: For manuals and documents with natural paragraph breaks</li> <li><code>sliding_window</code>: For generic documents with no clear structure</li> <li><code>token</code>: For fixed-size token-based chunking</li> </ul>"},{"location":"pdf-processing-guide/#process-and-add-to-faiss-index-in-one-step","title":"Process and Add to FAISS Index in One Step","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --add-to-index resources/vector_store/rvc_spec_index\n</code></pre> <p>This processes the PDF and adds it to an existing FAISS index in one operation.</p>"},{"location":"pdf-processing-guide/#create-a-new-faiss-index","title":"Create a New FAISS Index","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --add-to-index resources/vector_store/new_index \\\n  --create-new-index\n</code></pre> <p>This processes the PDF and creates a new FAISS index.</p>"},{"location":"pdf-processing-guide/#chunking-strategy-options","title":"Chunking Strategy Options","text":""},{"location":"pdf-processing-guide/#section-based-chunking","title":"Section-Based Chunking","text":"<p>Best for technical specifications with clear section numbering:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --chunking section_overlap \\\n  --section-pattern \"^(\\d+\\.\\d+(\\.\\d+)?)(\\s+)(.+)\" \\\n  --overlap 5\n</code></pre>"},{"location":"pdf-processing-guide/#paragraph-based-chunking","title":"Paragraph-Based Chunking","text":"<p>Best for manuals and documents with natural paragraph breaks:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --chunking paragraph\n</code></pre>"},{"location":"pdf-processing-guide/#sliding-window-chunking","title":"Sliding Window Chunking","text":"<p>Best for generic documents with no clear structure:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --chunking sliding_window \\\n  --window-size 10 \\\n  --overlap 3\n</code></pre>"},{"location":"pdf-processing-guide/#token-based-chunking","title":"Token-Based Chunking","text":"<p>Best for fixed-size chunks:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --chunking token \\\n  --chunk-size 512 \\\n  --overlap 50\n</code></pre>"},{"location":"pdf-processing-guide/#advanced-options","title":"Advanced Options","text":""},{"location":"pdf-processing-guide/#custom-output-path","title":"Custom Output Path","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --output resources/custom_output_name.json\n</code></pre>"},{"location":"pdf-processing-guide/#specify-embedding-model","title":"Specify Embedding Model","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --add-to-index resources/vector_store/rvc_spec_index \\\n  --model text-embedding-3-small\n</code></pre>"},{"location":"pdf-processing-guide/#custom-source-tag","title":"Custom Source Tag","text":"<p>Override the source tag in the metadata when you want to use a standardized name:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/rvc-spec-2023-11-local-copy.pdf \\\n  --add-to-index resources/vector_store/rvc_spec_index \\\n  --source-tag \"rvc-spec-2023-11.pdf\"\n</code></pre>"},{"location":"pdf-processing-guide/#skip-initial-pages","title":"Skip Initial Pages","text":"<p>Skip cover pages, table of contents, or other front matter pages that might contain section-like patterns but aren't actual content:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --skip-pages 5 \\\n  --chunking section_overlap\n</code></pre> <p>This is particularly useful when processing technical PDFs where the table of contents might match section patterns but shouldn't be included in the chunks.</p>"},{"location":"pdf-processing-guide/#dry-run-mode","title":"Dry Run Mode","text":"<p>Process a document without saving the output or modifying the index:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --dry-run\n</code></pre> <p>This is useful for testing chunking strategies on new document types.</p>"},{"location":"pdf-processing-guide/#step-3-test-your-index","title":"Step 3: Test Your Index","text":"<p>Verify that your document is properly indexed and searchable:</p> <pre><code># Test searching in the index\npoetry run python dev_tools/query_faiss.py \"your search query\" --source \"your-document-name-2023.pdf\"\n</code></pre>"},{"location":"pdf-processing-guide/#examples-by-document-type","title":"Examples by Document Type","text":""},{"location":"pdf-processing-guide/#technical-specification","title":"Technical Specification","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/rvc-spec-2023-11.pdf \\\n  --chunking section_overlap \\\n  --skip-pages 5 \\\n  --add-to-index resources/vector_store/rvc_spec_index\n</code></pre>"},{"location":"pdf-processing-guide/#user-manual","title":"User Manual","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/victron-multiplus-manual.pdf \\\n  --chunking paragraph \\\n  --add-to-index resources/vector_store/manuals_index\n</code></pre>"},{"location":"pdf-processing-guide/#generic-pdf","title":"Generic PDF","text":"<pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/misc-document.pdf \\\n  --chunking sliding_window \\\n  --add-to-index resources/vector_store/misc_index\n</code></pre>"},{"location":"pdf-processing-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"pdf-processing-guide/#common-issues","title":"Common Issues","text":"<ul> <li>Missing API key: Set <code>export OPENAI_API_KEY=your-api-key</code></li> <li>PDF extraction errors: Use PyMuPDF debugging tools and check PDF encoding</li> <li>Table of contents being chunked: Use <code>--skip-pages</code> to skip TOC/front matter</li> <li>Chunks too large: Adjust chunking strategy for shorter text segments</li> <li>Inconsistent metadata: Ensure document_loader is used for all sources</li> <li>Source tag conflicts: Use <code>--source-tag</code> to ensure consistent naming</li> <li>Processing errors: Check the detailed error messages in the summary report</li> <li>Index confusion: Use <code>--dry-run</code> to test processing without modifying files</li> </ul>"},{"location":"pdf-processing-guide/#testing-document-loader","title":"Testing Document Loader","text":"<p>Use the test_document_loader.py script to verify your chunks are correctly processed:</p> <pre><code>poetry run python dev_tools/test_document_loader.py\n</code></pre>"},{"location":"pdf-processing-guide/#viewing-processing-summary","title":"Viewing Processing Summary","text":"<p>The enhanced document processor now provides a detailed summary at the end of processing:</p> <pre><code>========================================================\nDOCUMENT PROCESSING SUMMARY\n========================================================\nDocument: resources/your-document-name-2023.pdf\nChunking method: section_overlap\nChunks generated: 42\nProcessing time: 3.25 seconds\nStatus: SUCCESS\nOutput chunks: resources/your-document-name-2023_chunks.json\nAdded to index: resources/vector_store/rvc_spec_index\n========================================================\n</code></pre> <p>This summary helps identify any issues in the processing workflow.</p>"},{"location":"pdf-processing-guide/#using-alternative-openai-api-endpoints","title":"Using Alternative OpenAI API Endpoints","text":"<p>The enhanced document processor now supports Azure OpenAI and other OpenAI-compatible endpoints.</p>"},{"location":"pdf-processing-guide/#azure-openai","title":"Azure OpenAI","text":"<p>To use Azure OpenAI for embeddings, set the required environment variables:</p> <pre><code>export OPENAI_API_KEY=\"your-azure-api-key\"\nexport OPENAI_API_BASE=\"https://your-resource-name.openai.azure.com/\"\nexport OPENAI_API_VERSION=\"2023-05-15\"\nexport OPENAI_API_TYPE=\"azure\"\nexport OPENAI_DEPLOYMENT_NAME=\"your-deployment-id\"\n</code></pre> <p>Then run the document processor normally:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --add-to-index resources/vector_store/your_index\n</code></pre> <p>Alternatively, you can specify API details via command-line arguments:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --add-to-index resources/vector_store/your_index \\\n  --api-type azure \\\n  --api-base \"https://your-resource-name.openai.azure.com/\" \\\n  --api-version \"2023-05-15\" \\\n  --deployment-name \"your-deployment-id\"\n</code></pre> <p>Note: For Azure OpenAI, <code>deployment-name</code> is used instead of <code>model</code>, but you should still set the <code>--model</code> parameter for fallback purposes.</p>"},{"location":"pdf-processing-guide/#custom-openai-compatible-endpoints","title":"Custom OpenAI-Compatible Endpoints","text":"<p>You can also use other OpenAI-compatible endpoints, such as local servers, proxies, or alternative providers:</p> <pre><code>export OPENAI_API_KEY=\"your-api-key\"\nexport OPENAI_API_BASE=\"http://localhost:8000/v1\"\n</code></pre> <p>Or via command-line:</p> <pre><code>poetry run python dev_tools/enhanced_document_processor.py \\\n  --pdf resources/your-document-name-2023.pdf \\\n  --add-to-index resources/vector_store/your_index \\\n  --api-type custom \\\n  --api-base \"http://localhost:8000/v1\"\n</code></pre> <p>This allows you to use services like: - vLLM in OpenAI-compatible mode - LM Studio local servers - Other OpenAI-compatible API providers</p>"},{"location":"pdf-processing-guide/#references","title":"References","text":"<ul> <li>LangChain FAISS Integration</li> <li>PyMuPDF Documentation</li> <li>OpenAI Embeddings Documentation</li> <li>Azure OpenAI Service Documentation</li> </ul>"},{"location":"poetry2nix-integration/","title":"Poetry2nix Integration for rvc2api","text":"<p>This document provides recommendations for integrating poetry2nix with your existing flake.nix configuration to improve dependency management between Poetry and Nix.</p>"},{"location":"poetry2nix-integration/#overview","title":"Overview","text":"<p>poetry2nix is a tool that allows for automatically converting Poetry projects to Nix derivations. It reads your <code>pyproject.toml</code> and <code>poetry.lock</code> files to create reproducible Nix builds.</p>"},{"location":"poetry2nix-integration/#benefits-of-integration","title":"Benefits of Integration","text":"<ol> <li>Single Source of Truth: Manage all dependencies in <code>pyproject.toml</code> without duplicating them in Nix</li> <li>Better Reproducibility: Ensure Nix builds use exactly the same dependency versions as Poetry</li> <li>Simplified Maintenance: Update dependencies with Poetry and have Nix automatically respect those changes</li> <li>Improved Dev Experience: Better integration between dev environments and production builds</li> </ol>"},{"location":"poetry2nix-integration/#implementation-plan","title":"Implementation Plan","text":""},{"location":"poetry2nix-integration/#1-update-flakenix-inputs","title":"1. Update flake.nix Inputs","text":"<pre><code>inputs = {\n  nixpkgs.url     = \"github:NixOS/nixpkgs/nixpkgs-unstable\";\n  flake-utils.url = \"github:numtide/flake-utils\";\n  poetry2nix.url = \"github:nix-community/poetry2nix\";  # Add this line\n};\n</code></pre>"},{"location":"poetry2nix-integration/#2-update-the-outputs-section","title":"2. Update the Outputs Section","text":"<pre><code>outputs = { self, nixpkgs, flake-utils, poetry2nix, ... }:\n  flake-utils.lib.eachDefaultSystem (system:\n    let\n      pkgs = import nixpkgs {\n        inherit system;\n        overlays = [ poetry2nix.overlay ];  # Add this line\n      };\n      python = pkgs.python312;\n\n      # Read version from file\n      version = builtins.replaceStrings [\"\\n\"] [\"\"] (builtins.readFile ./VERSION);\n\n      # Define poetry2nix application\n      rvc2apiPackage = pkgs.poetry2nix.mkPoetryApplication {\n        projectDir = self;\n        inherit version;\n\n        # Optional but often helpful overrides\n        overrides = pkgs.poetry2nix.overrides.withDefaults (final: prev: {\n          # Add overrides for any packages that need special handling\n          # For example:\n          # python-can = prev.python-can.overridePythonAttrs (old: {\n          #   buildInputs = (old.buildInputs or []) ++ [ final.setuptools ];\n          # });\n        });\n\n        # For Linux-specific dependencies\n        checkInputs = with pkgs.python312Packages; [ pytest ];\n      };\n\n      # For development environment\n      devEnv = pkgs.poetry2nix.mkPoetryEnv {\n        projectDir = self;\n        preferWheels = true;\n        python = python;\n\n        # Same overrides as for the package\n        overrides = pkgs.poetry2nix.overrides.withDefaults (final: prev: {\n          # Same overrides as above\n        });\n\n        # For extra development tools not in pyproject.toml\n        extraPackages = ps: with ps; [\n          ruff\n          ruff\n          # Using Pyright as the standardized type checker (see pyrightconfig.json)\n          pytest\n        ];\n      };\n    in {\n      # Keep existing outputs but replace rvc2apiPackage\n      packages.default = rvc2apiPackage;\n      packages.rvc2api = rvc2apiPackage;\n\n      # Update or add the development shell\n      devShells.default = pkgs.mkShell {\n        buildInputs = [\n          devEnv\n          pkgs.poetry\n          # Add any other tools needed for development\n          pkgs.nodejs_20  # For frontend development\n          pkgs.nodePackages.npm\n        ];\n\n        shellHook = ''\n          # Any commands to run when entering the shell\n          echo \"rvc2api development environment activated\"\n          # Configure the project version if needed\n          export RVC2API_VERSION=\"${version}\"\n        '';\n      };\n\n      # Keep other outputs (checks, apps, etc.)\n      ...\n    }\n  );\n</code></pre>"},{"location":"poetry2nix-integration/#3-testing-the-integration","title":"3. Testing the Integration","text":"<p>After implementing these changes:</p> <ol> <li>Run <code>nix flake check</code> to validate the flake</li> <li>Run <code>nix develop</code> to test the development environment</li> <li>Run <code>nix build</code> to test package building</li> </ol>"},{"location":"poetry2nix-integration/#4-common-issues-and-solutions","title":"4. Common Issues and Solutions","text":"<ol> <li>Native Dependencies: If packages have native dependencies, use <code>overrides</code> to add them</li> <li>Special Python Packages: Some packages need special handling (e.g., pytest plugins)</li> <li>Platform-Specific Dependencies: Handle with conditionals as already done in your flake</li> </ol>"},{"location":"poetry2nix-integration/#vs-code-integration","title":"VS Code Integration","text":"<p>With the tasks.json file now available, you can:</p> <ol> <li>Press <code>Ctrl+Shift+P</code> and select \"Tasks: Run Task\"</li> <li>Choose \"Enter Nix Development Shell\" to activate the environment</li> <li>Use other tasks for common development workflows</li> </ol>"},{"location":"poetry2nix-integration/#next-steps","title":"Next Steps","text":"<ol> <li>Gradually refine the poetry2nix overrides as needed</li> <li>Consider moving more development tools into the devEnv</li> <li>Set up CI to test both Poetry and Nix builds</li> </ol>"},{"location":"poetry2nix-integration/#resources","title":"Resources","text":"<ul> <li>poetry2nix Documentation</li> <li>poetry2nix Project Templates</li> <li>Blog: Nix Packaging for Python Projects</li> </ul>"},{"location":"pre-commit-and-actions/","title":"Pre-commit and GitHub Actions Configuration","text":"<p>This document describes the enhanced pre-commit and GitHub Actions configuration for the <code>rvc2api</code> project.</p>"},{"location":"pre-commit-and-actions/#pre-commit-configuration","title":"Pre-commit Configuration","text":"<p>The project uses pre-commit to enforce code quality standards before commits. This ensures consistent code formatting and catches common issues early.</p>"},{"location":"pre-commit-and-actions/#installed-hooks","title":"Installed Hooks","text":"<p>The pre-commit configuration includes:</p> <ol> <li> <p>Core file checks:</p> </li> <li> <p>Trailing whitespace removal</p> </li> <li>End-of-file fixer</li> <li>YAML/JSON/TOML validation</li> <li>Merge conflict detection</li> <li>Debug statement detection</li> <li>Line ending normalization</li> <li> <p>Large file checks</p> </li> <li> <p>Python code quality:</p> </li> <li> <p>Ruff Format: Code formatting</p> </li> <li>Ruff: Modern Python linting (replaces Flake8)</li> <li> <p>Pyright: Type checking (see <code>pyrightconfig.json</code> and <code>pyproject.toml</code>)</p> </li> <li> <p>Frontend code quality:</p> </li> <li> <p>ESLint: JavaScript/TypeScript linting</p> </li> <li> <p>djLint: HTML template linting</p> </li> <li> <p>Project integrity:</p> </li> <li>Poetry lock file validation</li> </ol>"},{"location":"pre-commit-and-actions/#using-pre-commit","title":"Using Pre-commit","text":"<pre><code># Install pre-commit hooks\npoetry run pre-commit install\n\n# Run against all files\npoetry run pre-commit run --all-files\n\n# Run a specific hook\npoetry run pre-commit run ruff-format --all-files\n</code></pre>"},{"location":"pre-commit-and-actions/#github-actions-configuration","title":"GitHub Actions Configuration","text":"<p>The project uses GitHub Actions to automate CI/CD processes.</p>"},{"location":"pre-commit-and-actions/#available-workflows","title":"Available Workflows","text":"<ol> <li> <p>Nix-based CI (<code>nix-ci.yml</code>):</p> </li> <li> <p>Runs all pre-commit checks</p> </li> <li>Executes all tests</li> <li>Validates Poetry lock file</li> <li> <p>Builds the project with Nix</p> </li> <li> <p>Frontend CI (<code>frontend.yml</code>):</p> </li> <li> <p>Triggered by changes to the <code>web_ui</code> directory</p> </li> <li>Runs linting and type checking</li> <li>Builds the frontend</li> <li> <p>Uploads build artifacts</p> </li> <li> <p>Dependency Validation (<code>nixpkgs-version-check.yml</code>):</p> </li> <li> <p>Checks that Python dependencies are available in Nixpkgs</p> </li> <li> <p>Triggered by changes to Poetry configuration</p> </li> <li> <p>Release Management (<code>release-please.yml</code>):</p> </li> <li>Automates version bumping and release notes</li> <li>Creates release pull requests</li> </ol>"},{"location":"pre-commit-and-actions/#local-development","title":"Local Development","text":"<p>For day-to-day development, you can use VS Code tasks to run common operations:</p> <ul> <li>Start Backend Server: Run the FastAPI server</li> <li>Start Frontend Dev Server: Run the Vite development server</li> <li>Run Tests: Execute pytest</li> <li>Format Code: Run Black formatter</li> <li>Lint (Ruff): Run Ruff linter</li> <li>Build Frontend: Create production frontend build</li> </ul>"},{"location":"pre-commit-and-actions/#adding-new-checks","title":"Adding New Checks","text":"<p>To add new checks to the pre-commit configuration:</p> <ol> <li>Add the hook to <code>.pre-commit-config.yaml</code></li> <li>Update the Ruff configuration in <code>pyproject.toml</code> if needed</li> <li>Update GitHub Actions workflows if additional CI steps are needed</li> </ol>"},{"location":"pyright-type-checking/","title":"Pyright Type Checking Guide","text":"<p>This document provides guidance on working with Pyright, our standardized Python type checker.</p>"},{"location":"pyright-type-checking/#basic-usage","title":"Basic Usage","text":"<p>Run type checking across the entire codebase:</p> <pre><code>npx pyright src\n</code></pre>"},{"location":"pyright-type-checking/#configuration","title":"Configuration","text":"<p>Pyright is configured in two places:</p> <ol> <li>pyrightconfig.json: Primary configuration file at the project root</li> <li>pyproject.toml: Contains additional Pyright settings under the <code>[tool.pyright]</code> section</li> </ol>"},{"location":"pyright-type-checking/#key-configuration-settings","title":"Key Configuration Settings","text":"<ul> <li><code>typeCheckingMode</code>: Set to \"basic\" for reasonable type checking without being overly strict</li> <li><code>reportMissingImports</code>: Flags imports that can't be resolved</li> <li><code>reportMissingTypeStubs</code>: Disabled to avoid noise from third-party packages without type stubs</li> <li><code>pythonVersion</code>: Set to match our minimum supported Python version</li> <li><code>stubPath</code>: Points to our custom type stubs directory</li> </ul>"},{"location":"pyright-type-checking/#custom-type-stubs","title":"Custom Type Stubs","text":"<p>For third-party libraries with missing or incomplete type information, we maintain custom type stubs in the <code>typings/</code> directory:</p> <ul> <li>FastAPI stubs: Enhanced WebSocket type definitions</li> <li>httpx stubs: Additional typing for HTTP client functions</li> </ul>"},{"location":"pyright-type-checking/#common-type-issues-and-solutions","title":"Common Type Issues and Solutions","text":""},{"location":"pyright-type-checking/#union-types","title":"Union Types","text":"<p>Use Python's built-in <code>|</code> operator for union types (Python 3.10+):</p> <pre><code># Preferred\ndef process_input(value: str | int | None) -&gt; str:\n    ...\n\n# Instead of\nfrom typing import Union\ndef process_input(value: Union[str, int, None]) -&gt; str:\n    ...\n</code></pre>"},{"location":"pyright-type-checking/#typeddict-for-dictionary-structure","title":"TypedDict for Dictionary Structure","text":"<p>Use TypedDict for dictionaries with specific key/value structures:</p> <pre><code>from typing import TypedDict\n\nclass UserData(TypedDict):\n    name: str\n    age: int\n    active: bool\n\ndef process_user(user: UserData) -&gt; None:\n    ...\n</code></pre>"},{"location":"pyright-type-checking/#protocol-for-duck-typing","title":"Protocol for Duck Typing","text":"<p>Use Protocol for structural subtyping (duck typing):</p> <pre><code>from typing import Protocol\n\nclass CanProcess(Protocol):\n    def process(self, data: bytes) -&gt; None: ...\n\ndef run_processor(processor: CanProcess, data: bytes) -&gt; None:\n    processor.process(data)\n</code></pre>"},{"location":"pyright-type-checking/#type-narrowing","title":"Type Narrowing","text":"<p>Use type guards for narrowing types:</p> <pre><code>def is_string_dict(obj: dict[str, object]) -&gt; bool:\n    return all(isinstance(v, str) for v in obj.values())\n\ndata: dict[str, object] = {\"a\": \"1\", \"b\": 2}\nif is_string_dict(data):  # Pyright understands this narrows the type\n    process_strings(data)  # Error avoided\n</code></pre>"},{"location":"pyright-type-checking/#literal-types","title":"Literal Types","text":"<p>Use Literal for constraining string/number values:</p> <pre><code>from typing import Literal\n\ndef set_log_level(level: Literal[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"]) -&gt; None:\n    ...\n</code></pre>"},{"location":"pyright-type-checking/#working-with-fastapi-and-pydantic","title":"Working with FastAPI and Pydantic","text":""},{"location":"pyright-type-checking/#pydantic-models","title":"Pydantic Models","text":"<p>Pyright works well with Pydantic v2 models:</p> <pre><code>from pydantic import BaseModel, Field\n\nclass Item(BaseModel):\n    name: str\n    price: float = Field(gt=0)\n    is_offer: bool = False\n</code></pre>"},{"location":"pyright-type-checking/#fastapi-route-parameters","title":"FastAPI Route Parameters","text":"<p>Type annotations for FastAPI routes should use the appropriate types:</p> <pre><code>from fastapi import FastAPI, Path, Query\n\napp = FastAPI()\n\n@app.get(\"/items/{item_id}\")\nasync def read_item(\n    item_id: int = Path(..., gt=0),\n    q: str | None = Query(None, max_length=50),\n):\n    ...\n</code></pre>"},{"location":"pyright-type-checking/#vs-code-integration","title":"VS Code Integration","text":"<p>For the best experience in VS Code:</p> <ol> <li>Install the Pylance extension</li> <li>Set the default Python type checker to Pyright in settings.json:</li> </ol> <pre><code>{\n  \"python.analysis.typeCheckingMode\": \"basic\",\n  \"python.analysis.diagnosticMode\": \"workspace\"\n}\n</code></pre>"},{"location":"pyright-type-checking/#ci-integration","title":"CI Integration","text":"<p>In CI pipelines, we run Pyright to check types:</p> <pre><code>npx pyright src\n</code></pre> <p>This ensures all PRs maintain type safety throughout the codebase.</p>"},{"location":"react-deployment/","title":"React Deployment with Caddy","text":"<p>This document describes the deployment setup for the rvc2api React frontend after the refactoring from a FastAPI-served template-based UI to a standalone React application.</p> <p>For information on developing the frontend, see Frontend Development Guide.</p>"},{"location":"react-deployment/#architecture","title":"Architecture","text":"<p>The architecture consists of:</p> <ol> <li>FastAPI Backend: Provides API endpoints at <code>/api/*</code> and WebSocket connections at <code>/ws/*</code></li> <li>React Frontend: Standalone SPA served directly by Caddy</li> <li>Caddy: HTTP server that:</li> <li>Serves the React frontend static files</li> <li>Reverse proxies API requests to the FastAPI backend</li> <li>Handles TLS termination and certificate management</li> </ol> <pre><code>  +--------+                +-------+                +-----------+\n  | Browser | &lt;--HTTPS----&gt; | Caddy | &lt;--HTTP/WS---&gt; | FastAPI   |\n  +--------+                +-------+                +-----------+\n                               |\n                         +----------+\n                         | React    |\n                         | Frontend |\n                         | (static) |\n                         +----------+\n</code></pre>"},{"location":"react-deployment/#caddy-configuration","title":"Caddy Configuration","text":"<p>The Caddy configuration is defined in the NixOS module at <code>modules/caddy.nix</code>. Key features:</p> <ul> <li>Serves the React frontend from <code>/var/lib/rvc2api-web-ui/dist</code></li> <li>Proxies all <code>/api/*</code> requests to the FastAPI backend</li> <li>Proxies all <code>/ws/*</code> WebSocket connections to the backend</li> <li>Uses Cloudflare DNS verification for HTTPS certificates</li> <li>Falls back to serving <code>index.html</code> for any non-file paths (for SPA routing)</li> </ul>"},{"location":"react-deployment/#deployment-process","title":"Deployment Process","text":"<ol> <li> <p>Build the React frontend:    <pre><code>cd web_ui\nnpm install\nnpm run build\n</code></pre></p> </li> <li> <p>Copy the built files to the server:    <pre><code>rsync -avz dist/ nixpi:/var/lib/rvc2api-web-ui/dist/\n</code></pre></p> </li> </ol>"},{"location":"react-deployment/#static-files-for-api-documentation","title":"Static Files for API Documentation","text":"<p>The FastAPI backend still serves static files for API documentation at the <code>/static</code> route. These files are no longer related to the web UI, which is now a standalone React application. The static files are:</p> <ol> <li>Located in the <code>src/core_daemon/static/</code> directory</li> <li>Automatically created if the directory doesn't exist</li> <li>Used only for API documentation and Swagger UI customization</li> <li>Not related to the React frontend</li> </ol> <p>When deploying updates:</p> <ol> <li>API documentation static files are included in the Python package</li> <li>No manual action is needed for these files during deployment</li> <li>The React frontend is built and deployed separately as described above</li> </ol>"},{"location":"react-deployment/#code-changes-from-refactoring","title":"Code Changes from Refactoring","text":"<ol> <li>Modified <code>config.py</code> to only handle static files for API documentation</li> <li>Removed web UI template-related code from the FastAPI application</li> <li>Updated <code>main.py</code> to mount only the API documentation static files</li> <li>Created a dedicated <code>static</code> directory in <code>src/core_daemon/</code> separate from web UI</li> <li> <p>Removed frontend router imports from the FastAPI application</p> </li> <li> <p>Ensure the Caddy service is running:    <pre><code>systemctl status caddy\n</code></pre></p> </li> </ol>"},{"location":"react-deployment/#development-workflow","title":"Development Workflow","text":"<p>During development:</p> <ol> <li> <p>Run the FastAPI backend:    <pre><code>poetry run python src/core_daemon/main.py\n</code></pre></p> </li> <li> <p>Run the React dev server:    <pre><code>cd web_ui\nnpm run dev\n</code></pre></p> </li> </ol> <p>The Vite dev server is configured to proxy API requests to the FastAPI backend.</p>"},{"location":"react-migration-summary/","title":"Web UI Migration to React","text":"<p>This document summarizes the migration process from the original Jinja2/FastAPI-served UI to the new standalone React application.</p>"},{"location":"react-migration-summary/#migration-overview","title":"Migration Overview","text":"<p>The UI has been successfully migrated from a server-side rendered Jinja2 template system to a modern React application with the following improvements:</p> <ol> <li> <p>Decoupled Architecture</p> </li> <li> <p>Frontend is now completely separate from the backend</p> </li> <li>Independent development cycles for UI and API</li> <li> <p>Can be deployed and hosted separately</p> </li> <li> <p>Modern Technology Stack</p> </li> <li> <p>React 19 with hooks and functional components</p> </li> <li>TypeScript for type safety</li> <li>Vite for fast development and optimized builds</li> <li> <p>TailwindCSS for modern styling</p> </li> <li> <p>Improved Developer Experience</p> </li> <li> <p>Hot module replacement for instant feedback</p> </li> <li>Type checking with TypeScript</li> <li>ESLint for code quality</li> <li>Jest for testing</li> <li> <p>Modern dev tools integration</p> </li> <li> <p>Better User Experience</p> </li> <li>More responsive UI with client-side rendering</li> <li>Modern animations and transitions</li> <li>Improved accessibility</li> <li>Mobile-friendly responsive design</li> </ol>"},{"location":"react-migration-summary/#implemented-features","title":"Implemented Features","text":"<p>The new UI includes all features from the original interface:</p> <ul> <li>Dashboard with system status</li> <li>Light control interface</li> <li>CAN message sniffer</li> <li>Device mapping</li> <li>Network visualization</li> <li>RVC specification viewer</li> <li>Unmapped entries and unknown PGNs</li> </ul>"},{"location":"react-migration-summary/#api-integration","title":"API Integration","text":"<p>The React frontend communicates with the backend through:</p> <ul> <li>REST API endpoints for data fetching and commands</li> <li>WebSocket for real-time updates</li> </ul>"},{"location":"react-migration-summary/#deployment","title":"Deployment","text":"<p>The new frontend can be served in two ways:</p> <ol> <li>Development Mode</li> </ol> <pre><code>cd web_ui\nnpm run dev\n</code></pre> <ol> <li>Production Mode</li> </ol> <pre><code>cd web_ui\nnpm run build\n</code></pre> <p>The built files (in <code>dist/</code>) can be served by Caddy or another web server.</p>"},{"location":"react-migration-summary/#testing","title":"Testing","text":"<p>The React UI includes a Jest testing setup:</p> <ul> <li>Component tests with React Testing Library</li> <li>Basic test coverage reporting</li> <li>Integration with the development workflow</li> </ul>"},{"location":"react-migration-summary/#future-enhancements","title":"Future Enhancements","text":"<p>Planned improvements for the React UI:</p> <ol> <li>More comprehensive test coverage</li> <li>Additional data visualization components</li> <li>Improved mobile responsiveness</li> <li>Dark/light theme switching</li> <li>Enhanced accessibility features</li> </ol>"},{"location":"react-migration-summary/#references","title":"References","text":"<ul> <li>React Documentation</li> <li>Vite Documentation</li> <li>React Testing Library</li> </ul>"},{"location":"rv-c-documentation-search/","title":"RV-C Documentation Search","text":"<p>This guide explains how to set up and use the RV-C documentation search functionality in the rvc2api project.</p>"},{"location":"rv-c-documentation-search/#overview","title":"Overview","text":"<p>The rvc2api project includes a semantic search feature that allows users to query RV-C specification and other technical documentation using natural language. This feature is powered by:</p> <ol> <li>FAISS vector database for efficient similarity search</li> <li>OpenAI embeddings for converting text to vectors</li> <li>Mixed chunking strategies to support multiple document formats</li> <li>FastAPI endpoints for accessing the search functionality</li> </ol>"},{"location":"rv-c-documentation-search/#setup-instructions","title":"Setup Instructions","text":""},{"location":"rv-c-documentation-search/#1-prepare-the-documentation-pdfs","title":"1. Prepare the Documentation PDFs","text":"<p>Place the RV-C specification PDF in the resources directory with a standardized name:</p> <pre><code>cp /path/to/your/rv-c-spec.pdf resources/rvc-spec-2023-11.pdf\n</code></pre> <p>You can also add additional documentation sources:</p> <pre><code># Add equipment manuals\ncp /path/to/victron/manual.pdf resources/victron-multiplus-manual.pdf\ncp /path/to/firefly/manual.pdf resources/firefly-g31-manual.pdf\n</code></pre>"},{"location":"rv-c-documentation-search/#2-set-up-openai-api-key","title":"2. Set up OpenAI API Key","text":"<p>The embedding generation requires an OpenAI API key. Set it in your environment:</p> <pre><code># For bash/zsh shells:\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For fish shell:\nset -x OPENAI_API_KEY \"your-openai-api-key\"\n</code></pre> <p>You can obtain an API key from https://platform.openai.com/api-keys</p>"},{"location":"rv-c-documentation-search/#3-using-the-helper-script-recommended","title":"3. Using the Helper Script (Recommended)","text":"<p>The easiest way to set up the documentation search is to use our helper script:</p> <pre><code># Check the current setup status\npoetry run python scripts/setup_faiss.py\n\n# Run the complete setup process\npoetry run python scripts/setup_faiss.py --setup\n</code></pre>"},{"location":"rv-c-documentation-search/#4-manual-setup-alternative","title":"4. Manual Setup (Alternative)","text":"<p>If you prefer to set up each component manually:</p> <p>First, generate text chunks from the PDFs:</p> <pre><code># For RV-C spec with section-based chunking\npoetry run python dev_tools/generate_embeddings.py\n\n# You can create custom chunking scripts for other document types\n# Example: For paragraph-based chunking of equipment manuals\npoetry run python dev_tools/chunk_paragraphs.py resources/victron-multiplus-manual.pdf\n</code></pre> <p>This will:</p> <ul> <li>Process the PDFs into text chunks with metadata</li> <li>Apply appropriate chunking strategies based on document type</li> <li>Save the chunks to JSON files (e.g., <code>resources/rvc_spec_chunks_with_overlap.json</code>)</li> </ul> <p>Then, generate the FAISS vector index:</p> <pre><code># Generate index from RV-C spec chunks\npoetry run python dev_tools/generate_faiss_index.py\n</code></pre> <p>This will:</p> <ul> <li>Convert the text chunks to document objects with standardized metadata</li> <li>Add source and chunking strategy information to enable filtering</li> <li>Generate embeddings using OpenAI's model</li> <li>Generate embeddings using the OpenAI API</li> <li>Create and save a FAISS index to <code>resources/vector_store/rvc_spec_index</code></li> </ul>"},{"location":"rv-c-documentation-search/#5-startrestart-the-server","title":"5. Start/Restart the Server","text":"<p>Start or restart the FastAPI server to load the new index:</p> <pre><code>poetry run python src/core_daemon/main.py\n</code></pre>"},{"location":"rv-c-documentation-search/#using-the-documentation-search","title":"Using the Documentation Search","text":""},{"location":"rv-c-documentation-search/#command-line-usage-new","title":"Command Line Usage (New!)","text":"<p>You can query the documentation directly from the command line:</p> <pre><code># Basic search\npoetry run python dev_tools/query_faiss.py \"how to calculate battery state of charge\"\n\n# Filter by document source\npoetry run python dev_tools/query_faiss.py \"battery monitoring\" --source rvc-spec-2023-11.pdf\n\n# Filter by chunking strategy\npoetry run python dev_tools/query_faiss.py \"battery monitoring\" --chunking section_overlap\n\n# Limit number of results\npoetry run python dev_tools/query_faiss.py \"battery monitoring\" --count 5\n</code></pre>"},{"location":"rv-c-documentation-search/#via-web-interface","title":"Via Web Interface","text":"<p>The easiest way to use the search in the application is through the web interface:</p> <ol> <li>Open the web UI in your browser (typically at http://localhost:8000 or http://localhost:5173 for development)</li> <li>Navigate to the \"Documentation\" page from the navigation menu</li> <li>Use the search box to enter your query</li> </ol>"},{"location":"rv-c-documentation-search/#via-api-endpoint","title":"Via API Endpoint","text":"<p>You can query the documentation search through the API endpoint:</p> <pre><code>curl \"http://localhost:8000/api/docs/search?query=battery%20charging%20parameters&amp;k=3\"\n</code></pre> <p>Parameters:</p> <ul> <li><code>query</code>: (Required) Your natural language search query</li> <li><code>k</code>: (Optional, default=3) Number of results to return (1-10)</li> </ul>"},{"location":"rv-c-documentation-search/#adding-multiple-document-sources","title":"Adding Multiple Document Sources","text":"<p>You can now mix different document types in the search index:</p>"},{"location":"rv-c-documentation-search/#adding-new-documents","title":"Adding New Documents","text":"<ol> <li>Process your document with an appropriate chunking strategy</li> <li>Generate embeddings for these chunks</li> <li>Add to the existing index with source and chunking metadata</li> </ol> <p>For a complete step-by-step guide on processing new PDF files and adding them to the FAISS index, refer to the PDF Processing Guide.</p> <p>Example code:</p> <pre><code>from pathlib import Path\nfrom document_loader import ChunkingStrategy, load_chunk_with_metadata\nfrom langchain_community.embeddings import OpenAIEmbeddings\nfrom langchain_community.vectorstores import FAISS\n\n# Process your document with appropriate chunking (See PDF Processing Guide for details)\n# This would create your_chunks with appropriate text and metadata\n\n# Load chunks with standard metadata\nnew_docs = load_chunk_with_metadata(\n    chunks_data=your_chunks,\n    source_path=Path(\"resources/your-document.pdf\"),\n    chunking_strategy=ChunkingStrategy.PARAGRAPH\n)\n\n# Load existing index\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\nvectorstore = FAISS.load_local(\"resources/vector_store/rvc_spec_index\", embeddings)\n\n# Add new documents to index\nvectorstore.add_documents(new_docs)\n\n# Save updated index\nvectorstore.save_local(\"resources/vector_store/rvc_spec_index\")\n</code></pre>"},{"location":"rv-c-documentation-search/#supported-chunking-strategies","title":"Supported Chunking Strategies","text":"<p>The <code>document_loader</code> module provides several chunking strategies for different document types:</p> Strategy Description Best For <code>SECTION_OVERLAP</code> Based on document sections with overlap Technical specifications with clear sections <code>PARAGRAPH</code> Based on natural paragraphs Prose-heavy manuals and guides <code>TOKEN</code> Fixed token size chunks Consistent embeddings for mixed content <code>SLIDING_WINDOW</code> Window with configurable overlap Code or dense technical content"},{"location":"rv-c-documentation-search/#filtering-results-by-source","title":"Filtering Results By Source","text":"<p>When querying, you can filter by document source to focus on specific documentation:</p> <pre><code>from document_loader import filter_results_by_source\n\n# Get initial results\nresults = vectorstore.similarity_search(query, k=10)\n\n# Filter to specific sources\nrvc_results = filter_results_by_source(results, source=\"rvc-spec-2023-11.pdf\", limit=3)\nvictron_results = filter_results_by_source(results, source=\"victron-multiplus-manual.pdf\", limit=3)\n</code></pre>"},{"location":"rv-c-documentation-search/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues with the documentation search:</p>"},{"location":"rv-c-documentation-search/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Search Not Available Error: This typically means either:</p> </li> <li> <p>The FAISS index hasn't been created yet</p> </li> <li>The OpenAI API key is missing or invalid</li> <li> <p>The server can't find the vector store files</p> </li> <li> <p>Missing PDF: If you're missing the RV-C specification PDF:</p> </li> <li> <p>Check your RV manufacturer's resources</p> </li> <li> <p>Contact RVIA for access to the specification</p> </li> <li> <p>OpenAI API Issues:</p> </li> <li>Verify your API key is valid and has sufficient quota</li> <li>Check your billing status on the OpenAI dashboard</li> <li>Try using a different API key if available</li> </ol>"},{"location":"rv-c-documentation-search/#diagnostic-steps","title":"Diagnostic Steps","text":"<ol> <li>Run the status check to identify issues:</li> </ol> <pre><code>poetry run python scripts/setup_faiss.py --check\n</code></pre> <ol> <li> <p>Verify file paths:</p> </li> <li> <p>PDF: <code>resources/rv-c-spec.pdf</code></p> </li> <li>Chunks file: <code>resources/rvc_spec_chunks_with_overlap.json</code></li> <li> <p>FAISS index: <code>resources/vector_store/rvc_spec_index/</code></p> </li> <li> <p>Check server logs for specific error messages:</p> </li> </ol> <pre><code># On most systems\njournalctl -u rvc2api.service -f\n\n# When running manually, check the terminal output\n</code></pre> <ol> <li>Test the search endpoint directly:</li> </ol> <pre><code>curl -v \"http://localhost:8000/api/docs/search?query=test\"\n</code></pre>"},{"location":"rv-c-documentation-search/#advanced-troubleshooting","title":"Advanced Troubleshooting","text":"<p>If the above steps don't resolve your issue:</p> <ol> <li>Regenerate the chunks and index:</li> </ol> <pre><code>rm resources/rvc_spec_chunks_with_overlap.json\nrm -rf resources/vector_store/rvc_spec_index\npoetry run python scripts/setup_faiss.py --setup\n</code></pre> <ol> <li>Check for Python package issues:</li> </ol> <pre><code>poetry install\n</code></pre> <ol> <li>Verify the HTTP status from the API endpoint (503 means service unavailable)</li> </ol> <p>For more detailed help, see the project documentation or create an issue on GitHub.</p>"},{"location":"test-mermaid/","title":"Testing Mermaid Diagrams","text":"<p>This file is for testing that mermaid diagrams render correctly with the updated YAML configuration.</p>"},{"location":"test-mermaid/#sample-diagram","title":"Sample Diagram","text":"<p>Here's a diagram showing the main components of our application:</p> <pre><code>graph TD\n    A[FastAPI Backend] --&gt; B[WebSocket Connection]\n    A --&gt; C[REST API]\n    B --&gt; D[RV-C Decoder]\n    C --&gt; D\n    D --&gt; E[CANbus Interface]\n\n    classDef backend fill:#009688,stroke:#00796B,color:#FFFFFF;\n    classDef api fill:#FF5722,stroke:#E64A19,color:#FFFFFF;\n    classDef decoder fill:#3F51B5,stroke:#303F9F,color:#FFFFFF;\n    classDef interface fill:#FFC107,stroke:#FFA000,color:#000000;\n\n    class A backend;\n    class B,C api;\n    class D decoder;\n    class E interface;</code></pre>"},{"location":"test-mermaid/#simple-flowchart","title":"Simple Flowchart","text":"<p>A simple process flowchart:</p> <pre><code>graph LR\n    Start([Start]) --&gt; Process[Process Data]\n    Process --&gt; Decision{Decision}\n    Decision --&gt;|Yes| End([End])\n    Decision --&gt;|No| Process\n\n    style Start fill:#C8E6C9,stroke:#4CAF50\n    style Process fill:#BBDEFB,stroke:#2196F3\n    style Decision fill:#FFECB3,stroke:#FFC107\n    style End fill:#FFCDD2,stroke:#F44336</code></pre>"},{"location":"test-mermaid/#sequence-diagram","title":"Sequence Diagram","text":"<p>A sample interaction sequence:</p> <pre><code>sequenceDiagram\n    participant User\n    participant API\n    participant Database\n\n    User-&gt;&gt;API: Request data\n    API-&gt;&gt;Database: Query\n    Database--&gt;&gt;API: Results\n    API--&gt;&gt;User: Response\n\n    Note over User,API: Authentication required</code></pre> <p>This should render as proper diagrams if the configuration is correct.</p>"},{"location":"vcan-setup-changes/","title":"vCAN Setup for DevContainer Changes","text":"<p>This document summarizes the changes made to improve vCAN setup in the rvc2api DevContainer environment.</p>"},{"location":"vcan-setup-changes/#changes-made","title":"Changes Made","text":"<ol> <li> <p>Enhanced Colima setup process:</p> </li> <li> <p>Integrated vcan setup into <code>.devcontainer/setup-colima.sh</code> for a streamlined experience</p> </li> <li> <p>Created standalone scripts for flexibility and troubleshooting:</p> <ul> <li><code>scripts/setup_colima_vcan.sh</code>: Sets up vcan kernel modules, interfaces and systemd services in the Colima VM</li> <li><code>scripts/ensure_vcan_interfaces.sh</code>: Helper script to verify and create vcan interfaces inside the container</li> <li><code>.devcontainer/diagnose-vcan.sh</code>: Diagnostic script for vcan interface issues</li> </ul> </li> <li> <p>Updated DevContainer configuration:</p> </li> <li> <p>Added vcan interface setup to container startup script (<code>.devcontainer/startup.sh</code>)</p> </li> <li>Set proper file permissions in <code>devcontainer.json</code> for vcan scripts</li> <li>Added vcan diagnostics to diagnose toolkit</li> <li> <p>Updated documentation references</p> </li> <li> <p>Added VS Code tasks for vCAN management:</p> </li> <li> <p>\"System: Setup Colima vcan\": Runs the standalone setup script on the host</p> </li> <li> <p>\"System: Ensure vcan Interfaces\": Verifies interfaces in the container</p> </li> <li> <p>Updated documentation:</p> </li> <li>Expanded <code>devcontainer-vcan-guide.md</code> with more detailed setup and troubleshooting steps</li> <li>Updated <code>.devcontainer/README.md</code> to reference the new scripts</li> </ol>"},{"location":"vcan-setup-changes/#how-it-works","title":"How It Works","text":""},{"location":"vcan-setup-changes/#automated-setup","title":"Automated Setup","text":"<ol> <li>The user runs <code>.devcontainer/setup-colima.sh</code> on their macOS host to configure both Colima and vcan</li> <li>When the devcontainer starts, <code>ensure_vcan_interfaces.sh</code> is automatically called by <code>startup.sh</code></li> <li>If any issues occur, the user can run <code>.devcontainer/diagnose-vcan.sh</code> to troubleshoot</li> </ol>"},{"location":"vcan-setup-changes/#manual-setup-if-needed","title":"Manual Setup (if needed)","text":"<ol> <li>The user can also run <code>./scripts/setup_colima_vcan.sh</code> separately if just the vcan setup is needed</li> <li>Inside the container, the \"System: Ensure vcan Interfaces\" task can be used to verify/repair the interfaces</li> </ol>"},{"location":"vcan-setup-changes/#testing-vcan","title":"Testing vCAN","text":"<ol> <li>The user can verify vCAN functionality using the <code>dev_tools/test_vcan_setup.py</code> script</li> <li>This script uses python-can to send and receive a test message on vcan0</li> <li>A VS Code task \"System: Test vCAN Setup\" is available for easy testing</li> </ol>"},{"location":"vcan-setup-changes/#testing-procedure","title":"Testing Procedure","text":"<p>To verify the changes:</p> <ol> <li>Stop any running Colima instance: <code>colima stop</code></li> <li>Run <code>.devcontainer/setup-colima.sh</code> to configure Colima with vcan support</li> <li>Open the folder in a DevContainer in VSCode</li> <li>Check if vcan interfaces are available in the container: <code>ip link show vcan0</code></li> <li>If issues persist, run the \"System: Ensure vcan Interfaces\" task in VSCode</li> </ol>"},{"location":"vcan-setup-changes/#notes","title":"Notes","text":"<ul> <li>These scripts include comprehensive error handling and user feedback</li> <li>The setup is designed to be non-destructive, able to run multiple times without issues</li> <li>Can-utils is automatically installed for testing if missing</li> <li>A systemd service is created in the Colima VM to ensure vcan interfaces persist across VM restarts</li> </ul>"},{"location":"verifying-versioned-documentation/","title":"Verifying Documentation Versioning","text":"<p>This document provides instructions for verifying that the documentation versioning system is working correctly.</p>"},{"location":"verifying-versioned-documentation/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure you have:</p> <ol> <li>Set up the repository according to the development environment guidelines</li> <li>Installed all the required dependencies with <code>poetry install</code></li> <li>Configured git for the repository</li> </ol>"},{"location":"verifying-versioned-documentation/#initial-setup-verification","title":"Initial Setup Verification","text":"<p>To verify that the initial setup for versioned documentation is complete:</p> <pre><code># List all currently deployed versions\npoetry run mike list\n</code></pre> <p>You should see at least:</p> <ul> <li><code>dev</code> - The development version</li> <li>The current version number (e.g., <code>0.1.0</code>)</li> <li><code>latest</code> - An alias to the current version</li> </ul> <p>If these versions are not present, you can set them up:</p> <pre><code># Using the setup script (fish shell)\n./scripts/setup_versioned_docs.fish\n\n# Alternatively, using VS Code tasks\n# Run the \"Docs: Setup Initial Versioned Documentation\" task\n</code></pre>"},{"location":"verifying-versioned-documentation/#testing-local-versioned-documentation","title":"Testing Local Versioned Documentation","text":"<p>To test that versioned documentation works locally:</p> <pre><code># Start the versioned documentation server\npoetry run mike serve\n</code></pre> <p>Visit http://localhost:8000/ and verify:</p> <ol> <li>The version selector shows the available versions</li> <li>You can switch between versions</li> <li>The content matches the expected version</li> </ol>"},{"location":"verifying-versioned-documentation/#testing-version-deployment","title":"Testing Version Deployment","text":"<p>To test deploying a specific version:</p> <pre><code># Deploy the current version\npoetry run mike deploy $(cat VERSION | tr -d '\\n')\n\n# Or for fish shell\nset current_version (cat VERSION | string trim); and poetry run mike deploy $current_version\n</code></pre> <p>Verify that the version is correctly listed:</p> <pre><code>poetry run mike list\n</code></pre>"},{"location":"verifying-versioned-documentation/#integration-with-release-please","title":"Integration with Release-Please","text":"<p>To verify that the integration with release-please is working:</p> <ol> <li>Make a commit with a conventional commit message (e.g., <code>feat: add new feature</code>)</li> <li>Push to the main branch</li> <li>Check that the release-please workflow creates a pull request for version bump</li> <li>Once merged, verify that the new version is deployed to the documentation site</li> </ol>"},{"location":"verifying-versioned-documentation/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"verifying-versioned-documentation/#missing-version-in-dropdown","title":"Missing Version in Dropdown","text":"<p>If a version is not appearing in the dropdown:</p> <pre><code># Check if the version exists\npoetry run mike list\n\n# If missing, deploy it\npoetry run mike deploy &lt;version&gt; --push\n</code></pre>"},{"location":"verifying-versioned-documentation/#wrong-default-version","title":"Wrong Default Version","text":"<p>If the wrong version is set as default:</p> <pre><code># Set the correct default version\npoetry run mike set-default &lt;version&gt; --push\n</code></pre>"},{"location":"verifying-versioned-documentation/#build-failures","title":"Build Failures","text":"<p>If the documentation build fails:</p> <ol> <li>Check the GitHub Actions logs for errors</li> <li>Verify that the OpenAPI schema generation works locally</li> <li>Ensure all dependencies are correctly installed</li> </ol>"},{"location":"verifying-versioned-documentation/#maintaining-documentation-versions","title":"Maintaining Documentation Versions","text":"<p>As a best practice:</p> <ol> <li>Always test documentation changes locally before pushing</li> <li>Use the <code>dev</code> version for ongoing work</li> <li>Only deploy specific versions when a release is created</li> <li>Use the GitHub Actions workflows for production deployments</li> </ol>"},{"location":"version-management/","title":"Version Management","text":"<p>This document explains how version management works in the rvc2api project.</p>"},{"location":"version-management/#single-source-of-truth","title":"Single Source of Truth","text":"<p>The project uses a single source of truth for version information:</p> <ul> <li>VERSION: The root-level <code>VERSION</code> file contains the canonical version number.</li> </ul> <p>This approach simplifies version management by centralizing the version information in one place.</p>"},{"location":"version-management/#version-updates","title":"Version Updates","text":"<p>The project uses release-please to manage version updates:</p> <ol> <li>Automated Updates: When PRs are merged with conventional commits, release-please automatically:</li> <li>Determines the appropriate version bump (major, minor, patch)</li> <li>Updates the version in pyproject.toml</li> <li> <p>Creates a release PR with a changelog</p> </li> <li> <p>Version Extraction: Various tools and scripts extract the version from the VERSION file when needed:</p> </li> <li><code>flake.nix</code> gets the version directly from the VERSION file for building packages</li> <li>The <code>pyproject.toml</code> file is updated to match the VERSION file during builds</li> <li>Documentation versioning scripts read the version from the VERSION file</li> <li>The Python code uses <code>importlib.metadata.version(\"rvc2api\")</code> to access the version at runtime</li> </ol>"},{"location":"version-management/#version-propagation","title":"Version Propagation","text":"<p>The version from the VERSION file propagates through the system:</p> <ol> <li>At Build Time: The version is included in the Python package metadata</li> <li>At Runtime: The version is available via <code>importlib.metadata</code> or the <code>_version.py</code> module</li> <li>In Documentation: MkDocs versioning uses the version for documentation releases</li> </ol>"},{"location":"version-management/#benefits","title":"Benefits","text":"<p>This approach provides several benefits:</p> <ul> <li>Simplicity: Only one place to update the version</li> <li>Consistency: All components share the same version information</li> <li>Automation: Release-please manages version changes according to semantic versioning</li> <li>Integration: Works well with Poetry, Nix, and documentation tools</li> </ul>"},{"location":"version-management/#previous-approach","title":"Previous Approach","text":"<p>Before this change, the project used both pyproject.toml and a separate VERSION file. This dual-source approach was eliminated to simplify version management and remove the risk of version inconsistencies.</p>"},{"location":"versioning-with-release-please/","title":"Guide to MkDocs Versioning with Release-Please","text":"<p>This guide explains how to use the integrated MkDocs versioning system that works with release-please.</p>"},{"location":"versioning-with-release-please/#integration-summary","title":"Integration Summary","text":"<p>We have successfully integrated:</p> <ol> <li>MkDocs with the mike plugin: For versioned documentation management</li> <li>release-please: For automated version management and version updates in pyproject.toml</li> <li>GitHub Actions workflows: For automated documentation deployment</li> <li>VS Code tasks: For local development and testing</li> </ol>"},{"location":"versioning-with-release-please/#key-components","title":"Key Components","text":"<ul> <li><code>pyproject.toml</code>: Source of truth for the current version of the project</li> <li><code>mike</code> plugin: Manages documentation versions</li> <li><code>deploy-versioned-docs.yml</code>: Workflow for versioned documentation releases</li> <li><code>deploy-docs.yml</code>: Workflow for development documentation updates</li> <li><code>release-please.yml</code>: Workflow for automated version management</li> </ul>"},{"location":"versioning-with-release-please/#how-to-use-the-versioning-system","title":"How to Use the Versioning System","text":""},{"location":"versioning-with-release-please/#local-development","title":"Local Development","text":"<ol> <li>View the current documentation:</li> </ol> <pre><code>poetry run mkdocs serve\n</code></pre> <ol> <li>View versioned documentation:</li> </ol> <pre><code># Using the VS Code task\n# \"Docs: Serve Versioned Documentation\"\n\n# Or manually\n./scripts/docs_version.sh serve\n</code></pre> <ol> <li>Deploy a specific version:</li> </ol> <pre><code># Using the VS Code task\n# \"Docs: Deploy Current Version\"\n\n# Or manually\n./scripts/docs_version.sh deploy\n\n# This automatically reads the version from pyproject.toml\n</code></pre> <ol> <li>Set the default version:</li> </ol> <pre><code># Using the VS Code task\n# \"Docs: Set Default Version\"\n\n# Or manually\n./scripts/docs_version.sh set-default\n\n# This automatically reads the version from pyproject.toml\n</code></pre>"},{"location":"versioning-with-release-please/#automated-deployment","title":"Automated Deployment","text":"<ol> <li> <p>Development updates:</p> </li> <li> <p>Push changes to documentation files on the <code>main</code> branch</p> </li> <li> <p>The <code>deploy-docs.yml</code> workflow will deploy the changes to the <code>dev</code> version</p> </li> <li> <p>Version releases:</p> </li> <li>Use conventional commit messages (e.g., <code>feat: add new feature</code>)</li> <li>When release-please creates a new version tag</li> <li>The <code>deploy-versioned-docs.yml</code> workflow will deploy the documentation for that version</li> </ol>"},{"location":"versioning-with-release-please/#testing-the-integration","title":"Testing the Integration","text":"<p>To verify that the integration is working correctly:</p> <ol> <li> <p>Check that versioned documentation is available:</p> </li> <li> <p>Run <code>poetry run mike list</code> to see all deployed versions</p> </li> <li> <p>If no versions are available, run <code>./scripts/setup_versioned_docs.fish</code></p> </li> <li> <p>Test a documentation update:</p> </li> <li> <p>Make a small change to a documentation file</p> </li> <li>Push to the <code>main</code> branch</li> <li> <p>Verify that the change appears in the <code>dev</code> version</p> </li> <li> <p>Test a version release:</p> </li> <li>Make a commit with a conventional commit message</li> <li>Push to the <code>main</code> branch</li> <li>When release-please creates a new version</li> <li>Verify that the new version is available in the version selector</li> </ol>"},{"location":"versioning-with-release-please/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues with the versioning system:</p> <ol> <li> <p>Check that the version in pyproject.toml is correct:</p> </li> <li> <p>The version should be in the format <code>version = \"x.y.z\"</code> under <code>[tool.poetry]</code></p> </li> <li> <p>release-please should update this automatically on releases</p> </li> <li> <p>Check permissions on bash scripts:</p> </li> <li> <p>Make sure the scripts are executable: <code>chmod +x scripts/*.sh</code></p> </li> <li> <p>If not, make them executable and try again</p> </li> <li> <p>Check that the gh-pages branch exists:</p> </li> <li> <p>If not, create it with the setup script: <code>./scripts/setup_versioned_docs.sh</code></p> </li> <li> <p>Check the GitHub Actions logs:</p> </li> <li>Look for errors in the workflows</li> <li>Fix any issues and rerun the workflows</li> </ol> <p>For detailed troubleshooting, see Verifying Versioned Documentation.</p>"},{"location":"vscode-extensions/","title":"VS Code Extensions for rvc2api Development","text":"<p>This document provides details about the recommended VS Code extensions for developing the rvc2api project. These extensions are tailored to support the project's technology stack and improve the development experience.</p>"},{"location":"vscode-extensions/#installing-the-extensions","title":"Installing the Extensions","text":"<p>To install the recommended extensions:</p> <ol> <li>Open VS Code with the rvc2api project</li> <li>Press <code>Cmd+Shift+P</code> (macOS) or <code>Ctrl+Shift+P</code> (Windows/Linux)</li> <li>Type and select \"Extensions: Show Recommended Extensions\"</li> <li>Install the extensions from the recommendations list</li> </ol> <p>Alternatively, you can install them one by one using the VS Code Extensions view (<code>Cmd+Shift+X</code> or <code>Ctrl+Shift+X</code>).</p>"},{"location":"vscode-extensions/#python-development-extensions","title":"Python Development Extensions","text":""},{"location":"vscode-extensions/#core-python-support","title":"Core Python Support","text":"<ul> <li>Python (ms-python.python): Essential Python language support with IntelliSense, linting, and debugging</li> <li>Pylance (ms-python.vscode-pylance): Fast type checking and IntelliSense for Python</li> <li>Configured to work with our custom type stubs in the <code>typings/</code> directory</li> <li>See <code>typings/fastapi/README.md</code> for information about our FastAPI type stub organization</li> </ul>"},{"location":"vscode-extensions/#code-quality-tools","title":"Code Quality Tools","text":"<ul> <li>Ruff (charliermarsh.ruff): Fast Python linter and formatter integrated into VS Code</li> <li>isort (ms-python.isort): Import sorting for Python files (mostly handled by Ruff now)</li> </ul>"},{"location":"vscode-extensions/#python-workflow","title":"Python Workflow","text":"<ul> <li>Poetry (njpwerner.poetry): Poetry commands and environment management</li> <li>Python Test Explorer (tht13.python): Discover and run Python tests</li> </ul>"},{"location":"vscode-extensions/#fastapi-development","title":"FastAPI Development","text":"<ul> <li>FastAPI Snippets (LikhithD.fastapi-snippets-extension): Code snippets for FastAPI development</li> </ul>"},{"location":"vscode-extensions/#nix-development-extensions","title":"Nix Development Extensions","text":"<ul> <li>Nix IDE (jnoortheen.nix-ide): Language support, formatting, and linting for Nix files</li> <li>Nix Environment Selector (arrterian.nix-env-selector): Manage and select Nix environments</li> <li>Nix (bbenoist.Nix): Syntax highlighting for Nix files</li> <li>direnv (mkhl.direnv): Integrates direnv for automatic environment activation</li> </ul>"},{"location":"vscode-extensions/#frontend-development-extensions","title":"Frontend Development Extensions","text":""},{"location":"vscode-extensions/#react-typescript","title":"React &amp; TypeScript","text":"<ul> <li>ESLint (dbaeumer.vscode-eslint): JavaScript and TypeScript linting</li> <li>Prettier (esbenp.prettier-vscode): Code formatting for JavaScript, TypeScript, and CSS</li> <li>ES7+ React/Redux/React-Native snippets (dsznajder.es7-react-js-snippets): Code snippets for React development</li> </ul>"},{"location":"vscode-extensions/#ui-development","title":"UI Development","text":"<ul> <li>Tailwind CSS IntelliSense (bradlc.vscode-tailwindcss): IntelliSense for Tailwind CSS classes</li> <li>Headless UI Snippets (dylanwatson.headlessui-snippets): Code snippets for Headless UI components</li> </ul>"},{"location":"vscode-extensions/#build-tools","title":"Build Tools","text":"<ul> <li>Vite (antfu.vite): Enhanced support for Vite projects</li> </ul>"},{"location":"vscode-extensions/#general-development-tools","title":"General Development Tools","text":"<ul> <li>JSON5 (mrmlnc.vscode-json5): Advanced JSON support with comments</li> <li>YAML (redhat.vscode-yaml): YAML language support and validation</li> </ul>"},{"location":"vscode-extensions/#ai-assistance","title":"AI Assistance","text":"<ul> <li>GitHub Copilot (GitHub.copilot): AI-powered code completion</li> <li>GitHub Copilot Chat (GitHub.copilot-chat): Conversational AI assistance with MCP tools integration</li> </ul>"},{"location":"vscode-extensions/#using-extensions-with-tasks","title":"Using Extensions with Tasks","text":"<p>Many of these extensions work well with the VS Code tasks defined in <code>tasks.json</code>:</p> <ol> <li>Press <code>Cmd+Shift+P</code> (macOS) or <code>Ctrl+Shift+P</code> (Windows/Linux)</li> <li>Type and select \"Tasks: Run Task\"</li> <li>Choose a task like \"Start Backend Server\" or \"Format Code (Ruff)\"</li> </ol> <p>See the VS Code Tasks documentation for more information on using tasks.</p>"},{"location":"vscode-extensions/#mcp-tools-integration","title":"MCP Tools Integration","text":"<p>The GitHub Copilot Chat extension integrates with Model Context Protocol (MCP) tools like @context7, @perplexity, and @github. See <code>docs/mcp-tools-setup.md</code> for detailed information on using these tools.</p>"},{"location":"vscode-extensions/#extension-configuration","title":"Extension Configuration","text":"<p>Most extensions are pre-configured in <code>.vscode/settings.json</code>, but you may want to customize them further. Refer to each extension's documentation for configuration options.</p> <p>For project-specific settings, update <code>.vscode/settings.json</code> to ensure consistency across the development team.</p>"},{"location":"api/","title":"API Documentation","text":"<p>Welcome to the rvc2api API documentation. This documentation provides comprehensive information about the API endpoints, request/response formats, and data models.</p>"},{"location":"api/#api-overview","title":"API Overview","text":"<p>The rvc2api server provides a RESTful API for interacting with RV-C devices and systems. The API is organized into the following categories:</p> <ul> <li>Entity API: Endpoints for managing and controlling entities (devices like lights, temperature sensors, etc.)</li> <li>CAN Bus API: Endpoints for interacting directly with the CAN bus</li> <li>Configuration API: Endpoints for retrieving and modifying system configuration</li> <li>WebSocket API: Real-time communication endpoints</li> </ul>"},{"location":"api/#api-specification","title":"API Specification","text":"<p>The API is fully documented using the OpenAPI specification. You can:</p> <ul> <li>Browse the OpenAPI Specification for details on how to use the API</li> <li>Access interactive API documentation at http://localhost:8000/docs when the server is running</li> <li>Use the raw OpenAPI schema to generate API clients for various programming languages</li> </ul>"},{"location":"api/#frontend-integration","title":"Frontend Integration","text":"<p>The rvc2api project includes a React frontend that consumes the API. For information about how the frontend integrates with the API, see the Frontend API Integration page.</p>"},{"location":"api/can/","title":"CAN API Reference","text":"<p>The CAN API provides access to the CAN bus interface and message history. This allows you to directly interact with the RV-C network.</p>"},{"location":"api/can/#can-status","title":"CAN Status","text":"<pre><code>GET /api/can/status\n</code></pre> <p>Returns the current status of the CAN bus interface.</p>"},{"location":"api/can/#response","title":"Response","text":"<pre><code>{\n  \"can0\": {\n    \"state\": \"active\",\n    \"bitrate\": \"250000\",\n    \"message_count\": 15293,\n    \"error_count\": 0,\n    \"last_message_timestamp\": \"2023-05-18T15:30:45\"\n  }\n}\n</code></pre>"},{"location":"api/can/#can-sniffer","title":"CAN Sniffer","text":"<pre><code>GET /api/can/sniffer\n</code></pre> <p>Returns recent CAN messages that have been captured on the bus.</p>"},{"location":"api/can/#query-parameters","title":"Query Parameters","text":"Parameter Type Description limit integer Optional. Maximum number of messages to return (default 100) since string Optional. Only return messages after this timestamp pgn string Optional. Filter by PGN (Parameter Group Number) source string Optional. Filter by source address include_raw boolean Optional. Include raw message data in the response"},{"location":"api/can/#example","title":"Example","text":"<p>Get the last 10 messages:</p> <pre><code>GET /api/can/sniffer?limit=10\n</code></pre> <p>Get messages with a specific PGN:</p> <pre><code>GET /api/can/sniffer?pgn=FEF1\n</code></pre>"},{"location":"api/can/#response_1","title":"Response","text":"<pre><code>[\n  {\n    \"timestamp\": \"2023-05-18T15:30:45\",\n    \"arbitration_id\": \"18FEF121\",\n    \"data\": \"FFFF0000FFFF0000\",\n    \"interface\": \"can0\",\n    \"pgn\": \"FEF1\",\n    \"source_addr\": \"21\",\n    \"priority\": \"6\",\n    \"dgn_hex\": \"FEF1\",\n    \"name\": \"DC Dimmer Command\",\n    \"decoded\": {\n      \"instance\": 1,\n      \"command\": \"On\",\n      \"level\": 100\n    },\n    \"direction\": \"rx\"\n  },\n  {\n    \"timestamp\": \"2023-05-18T15:30:40\",\n    \"arbitration_id\": \"18EAFF00\",\n    \"data\": \"FF000000FF000000\",\n    \"interface\": \"can0\",\n    \"pgn\": \"EAFF\",\n    \"source_addr\": \"00\",\n    \"priority\": \"6\",\n    \"dgn_hex\": \"EAFF\",\n    \"name\": \"Address Claimed\",\n    \"decoded\": {\n      \"industry_group\": \"RV\",\n      \"device_instance\": 0,\n      \"device_function\": \"Bridge\",\n      \"device_class\": \"System\"\n    },\n    \"direction\": \"rx\"\n  }\n]\n</code></pre>"},{"location":"api/can/#send-can-message","title":"Send CAN Message","text":"<pre><code>POST /api/can/send\n</code></pre> <p>Sends a raw CAN message to the bus.</p>"},{"location":"api/can/#request-body","title":"Request Body","text":"Field Type Description arbitration_id string Arbitration ID in hex format data string Data bytes in hex format interface string Optional. Interface to send on (default: can0)"},{"location":"api/can/#example_1","title":"Example","text":"<pre><code>{\n  \"arbitration_id\": \"18FEF121\",\n  \"data\": \"FFFF0000FFFF0000\",\n  \"interface\": \"can0\"\n}\n</code></pre>"},{"location":"api/can/#response_2","title":"Response","text":"<pre><code>{\n  \"success\": true,\n  \"message\": \"Message sent successfully\",\n  \"timestamp\": \"2023-05-18T15:31:00\"\n}\n</code></pre>"},{"location":"api/can/#unknown-pgns","title":"Unknown PGNs","text":"<pre><code>GET /api/can/unknown_pgns\n</code></pre> <p>Returns a list of Parameter Group Numbers (PGNs) that have been seen on the bus but are not recognized by the system.</p>"},{"location":"api/can/#response_3","title":"Response","text":"<pre><code>[\n  {\n    \"pgn\": \"FD01\",\n    \"count\": 127,\n    \"last_seen\": \"2023-05-18T15:30:45\",\n    \"data_samples\": [\"FFFF0000FFFF0000\", \"00FF0000FF000000\"]\n  },\n  {\n    \"pgn\": \"FDA1\",\n    \"count\": 43,\n    \"last_seen\": \"2023-05-18T15:29:10\",\n    \"data_samples\": [\"FFFFFFFFFF000000\"]\n  }\n]\n</code></pre>"},{"location":"api/can/#unmapped-entries","title":"Unmapped Entries","text":"<pre><code>GET /api/can/unmapped\n</code></pre> <p>Returns a list of DGN/instance pairs that have been seen on the bus but are not mapped to entities in the system.</p>"},{"location":"api/can/#response_4","title":"Response","text":"<pre><code>[\n  {\n    \"dgn\": \"1FEFF\",\n    \"dgn_hex\": \"1FEFF\",\n    \"instance\": 3,\n    \"count\": 15,\n    \"last_seen\": \"2023-05-18T15:30:30\",\n    \"name\": \"Generic Sensor\",\n    \"decoded_sample\": {\n      \"instance\": 3,\n      \"value\": 75.5,\n      \"unit\": \"Percent\"\n    }\n  },\n  {\n    \"dgn\": \"1FEF6\",\n    \"dgn_hex\": \"1FEF6\",\n    \"instance\": 2,\n    \"count\": 8,\n    \"last_seen\": \"2023-05-18T15:29:45\",\n    \"name\": \"DC Source Status\",\n    \"decoded_sample\": {\n      \"instance\": 2,\n      \"voltage\": 12.87,\n      \"current\": 1.5\n    }\n  }\n]\n</code></pre>"},{"location":"api/entities/","title":"Entity API Reference","text":"<p>Entities represent the devices and systems in your RV, such as lights, tanks, and temperature sensors. The Entity API allows you to interact with these devices.</p>"},{"location":"api/entities/#entity-model","title":"Entity Model","text":"<p>Each entity has the following structure:</p> <pre><code>{\n  \"id\": \"light_1\",\n  \"name\": \"Living Room Light\",\n  \"device_type\": \"light\",\n  \"suggested_area\": \"living_room\",\n  \"state\": \"on\",\n  \"raw\": {\n    \"operating_status\": 100\n  },\n  \"capabilities\": [\"toggle\", \"brightness\"],\n  \"last_updated\": \"2023-05-18T15:30:45\",\n  \"source_type\": \"rv-c\"\n}\n</code></pre>"},{"location":"api/entities/#list-entities","title":"List Entities","text":"<pre><code>GET /api/entities\n</code></pre> <p>Returns all entities, with optional filtering by device type or area.</p>"},{"location":"api/entities/#query-parameters","title":"Query Parameters","text":"Parameter Type Description device_type string Optional. Filter by device type (e.g., \"light\") area string Optional. Filter by area (e.g., \"living_room\")"},{"location":"api/entities/#example","title":"Example","text":"<p>Get all lights:</p> <pre><code>GET /api/entities?device_type=light\n</code></pre> <p>Get all entities in the bedroom:</p> <pre><code>GET /api/entities?area=bedroom\n</code></pre>"},{"location":"api/entities/#response","title":"Response","text":"<pre><code>{\n  \"light_1\": {\n    \"id\": \"light_1\",\n    \"name\": \"Living Room Light\",\n    \"device_type\": \"light\",\n    \"suggested_area\": \"living_room\",\n    \"state\": \"on\",\n    \"raw\": {\n      \"operating_status\": 100\n    },\n    \"capabilities\": [\"toggle\", \"brightness\"],\n    \"last_updated\": \"2023-05-18T15:30:45\",\n    \"source_type\": \"rv-c\"\n  },\n  \"light_2\": {\n    \"id\": \"light_2\",\n    \"name\": \"Bedroom Light\",\n    \"device_type\": \"light\",\n    \"suggested_area\": \"bedroom\",\n    \"state\": \"off\",\n    \"raw\": {\n      \"operating_status\": 0\n    },\n    \"capabilities\": [\"toggle\", \"brightness\"],\n    \"last_updated\": \"2023-05-18T15:25:30\",\n    \"source_type\": \"rv-c\"\n  }\n}\n</code></pre>"},{"location":"api/entities/#get-entity-by-id","title":"Get Entity by ID","text":"<pre><code>GET /api/entities/{entity_id}\n</code></pre> <p>Returns a specific entity by ID.</p>"},{"location":"api/entities/#path-parameters","title":"Path Parameters","text":"Parameter Type Description entity_id string The ID of the entity to get"},{"location":"api/entities/#response_1","title":"Response","text":"<pre><code>{\n  \"id\": \"light_1\",\n  \"name\": \"Living Room Light\",\n  \"device_type\": \"light\",\n  \"suggested_area\": \"living_room\",\n  \"state\": \"on\",\n  \"raw\": {\n    \"operating_status\": 100\n  },\n  \"capabilities\": [\"toggle\", \"brightness\"],\n  \"last_updated\": \"2023-05-18T15:30:45\",\n  \"source_type\": \"rv-c\"\n}\n</code></pre>"},{"location":"api/entities/#control-entity","title":"Control Entity","text":"<pre><code>POST /api/entities/{entity_id}/control\n</code></pre> <p>Controls an entity by sending commands.</p>"},{"location":"api/entities/#path-parameters_1","title":"Path Parameters","text":"Parameter Type Description entity_id string The ID of the entity to control"},{"location":"api/entities/#request-body","title":"Request Body","text":"<p>The request body contains a command object with the following structure:</p> Field Type Description command string The command to execute: \"set\", \"toggle\", \"brightness_up\", \"brightness_down\" state string Optional. The desired state: \"on\" or \"off\" (used with \"set\" command) brightness integer Optional. The desired brightness: 0-100 (used with \"set\" command)"},{"location":"api/entities/#command-examples","title":"Command Examples","text":"<p>Turn a light on:</p> <pre><code>{\n  \"command\": \"set\",\n  \"state\": \"on\"\n}\n</code></pre> <p>Turn a light off:</p> <pre><code>{\n  \"command\": \"set\",\n  \"state\": \"off\"\n}\n</code></pre> <p>Set brightness to 75%:</p> <pre><code>{\n  \"command\": \"set\",\n  \"state\": \"on\",\n  \"brightness\": 75\n}\n</code></pre> <p>Toggle a light:</p> <pre><code>{\n  \"command\": \"toggle\"\n}\n</code></pre> <p>Increase brightness by 10%:</p> <pre><code>{\n  \"command\": \"brightness_up\"\n}\n</code></pre> <p>Decrease brightness by 10%:</p> <pre><code>{\n  \"command\": \"brightness_down\"\n}\n</code></pre>"},{"location":"api/entities/#response_2","title":"Response","text":"<pre><code>{\n  \"command\": \"set\",\n  \"state\": \"on\",\n  \"brightness\": 75,\n  \"description\": \"Light turned on and set to 75% brightness\"\n}\n</code></pre>"},{"location":"api/entities/#get-entity-history","title":"Get Entity History","text":"<pre><code>GET /api/entities/{entity_id}/history\n</code></pre> <p>Returns the history of an entity's state changes.</p>"},{"location":"api/entities/#path-parameters_2","title":"Path Parameters","text":"Parameter Type Description entity_id string The ID of the entity to get history for"},{"location":"api/entities/#response_3","title":"Response","text":"<pre><code>[\n  {\n    \"timestamp\": \"2023-05-18T15:30:45\",\n    \"state\": \"on\",\n    \"raw\": {\n      \"operating_status\": 100\n    }\n  },\n  {\n    \"timestamp\": \"2023-05-18T15:25:30\",\n    \"state\": \"off\",\n    \"raw\": {\n      \"operating_status\": 0\n    }\n  }\n]\n</code></pre>"},{"location":"api/frontend-integration/","title":"Frontend API Integration","text":"<p>This page describes how the React frontend integrates with the rvc2api backend API.</p>"},{"location":"api/frontend-integration/#integration-architecture","title":"Integration Architecture","text":"<pre><code>sequenceDiagram\n    participant UI as React Components\n    participant Hooks as Custom Hooks\n    participant API as API Client\n    participant Backend as Backend Server\n    participant WS as WebSocket\n\n    UI-&gt;&gt;Hooks: Render component with data needs\n    Hooks-&gt;&gt;API: Call API function\n    API-&gt;&gt;Backend: HTTP Request (GET/POST/PUT)\n    Backend--&gt;&gt;API: Response (JSON)\n    API--&gt;&gt;Hooks: Processed data\n    Hooks--&gt;&gt;UI: Updated state\n\n    Note over UI,Hooks: Initial data load completed\n\n    WS-&gt;&gt;Backend: Connect WebSocket\n    Backend--&gt;&gt;WS: Connection established\n\n    loop Real-time updates\n        Backend-&gt;&gt;WS: Entity state change\n        WS-&gt;&gt;Hooks: Update event\n        Hooks-&gt;&gt;UI: Re-render with new data\n    end\n\n    UI-&gt;&gt;Hooks: User interaction\n    Hooks-&gt;&gt;API: Send command\n    API-&gt;&gt;Backend: HTTP Request (POST)\n    Backend--&gt;&gt;API: Command result\n    API--&gt;&gt;Hooks: Updated state\n    Hooks--&gt;&gt;UI: Re-render with result</code></pre>"},{"location":"api/frontend-integration/#api-client-structure","title":"API Client Structure","text":"<p>The frontend uses a structured approach for API communication:</p> <ol> <li>API Types (<code>src/api/types.ts</code>): TypeScript interfaces matching the API response models</li> <li>API Endpoints (<code>src/api/endpoints.ts</code>): Functions to call specific API endpoints</li> <li>API Utilities (<code>src/api/index.ts</code>): Helper functions for error handling and response parsing</li> </ol>"},{"location":"api/frontend-integration/#base-api-configuration","title":"Base API Configuration","text":"<p>The API base URL and common fetch options are defined in <code>endpoints.ts</code>:</p> <pre><code>/** Base URL for API requests */\nconst API_BASE = \"/api\";\n\n// Common fetch options\nconst defaultOptions: RequestInit = {\n  headers: {\n    \"Content-Type\": \"application/json\",\n  },\n};\n</code></pre>"},{"location":"api/frontend-integration/#entity-api-integration","title":"Entity API Integration","text":""},{"location":"api/frontend-integration/#fetching-entities","title":"Fetching Entities","text":"<p>Entities are fetched using the standardized <code>/api/entities</code> endpoint:</p> <pre><code>export async function fetchLights(): Promise&lt;LightStatus[]&gt; {\n  const response = await fetch(\n    `${API_BASE}/entities?device_type=light`,\n    defaultOptions\n  );\n  return handleApiResponse&lt;LightStatus[]&gt;(response);\n}\n</code></pre>"},{"location":"api/frontend-integration/#controlling-entities","title":"Controlling Entities","text":"<p>Entity control commands follow the standardized command format:</p> <pre><code>export async function setLightState(\n  id: string,\n  state: boolean\n): Promise&lt;LightControlResponse&gt; {\n  const command = {\n    command: \"set\",\n    state: state ? \"on\" : \"off\",\n  };\n\n  const response = await fetch(`${API_BASE}/entities/${id}/control`, {\n    ...defaultOptions,\n    method: \"POST\",\n    body: JSON.stringify(command),\n  });\n\n  return handleApiResponse&lt;LightControlResponse&gt;(response);\n}\n</code></pre>"},{"location":"api/frontend-integration/#setting-brightness","title":"Setting Brightness","text":"<pre><code>export async function setLightBrightness(\n  id: string,\n  brightness: number\n): Promise&lt;LightControlResponse&gt; {\n  const command = {\n    command: \"set\",\n    state: \"on\",\n    brightness: Math.min(Math.max(0, Math.round(brightness)), 100),\n  };\n\n  const response = await fetch(`${API_BASE}/entities/${id}/control`, {\n    ...defaultOptions,\n    method: \"POST\",\n    body: JSON.stringify(command),\n  });\n\n  return handleApiResponse&lt;LightControlResponse&gt;(response);\n}\n</code></pre>"},{"location":"api/frontend-integration/#websocket-integration","title":"WebSocket Integration","text":"<p>The frontend connects to the WebSocket API for real-time updates:</p> <pre><code>export function setupWebSocket(\n  onMessage: (data: any) =&gt; void,\n  onConnect: () =&gt; void,\n  onDisconnect: () =&gt; void\n): WebSocket {\n  const wsProtocol = window.location.protocol === \"https:\" ? \"wss:\" : \"ws:\";\n  const wsUrl = `${wsProtocol}//${window.location.host}/api/ws`;\n\n  const socket = new WebSocket(wsUrl);\n\n  socket.onopen = () =&gt; {\n    console.log(\"WebSocket connected\");\n    onConnect();\n  };\n\n  socket.onmessage = (event) =&gt; {\n    try {\n      const data = JSON.parse(event.data);\n      onMessage(data);\n    } catch (error) {\n      console.error(\"Error parsing WebSocket message:\", error);\n    }\n  };\n\n  socket.onclose = () =&gt; {\n    console.log(\"WebSocket disconnected\");\n    onDisconnect();\n  };\n\n  return socket;\n}\n</code></pre>"},{"location":"api/frontend-integration/#error-handling","title":"Error Handling","text":"<p>The frontend uses a consistent error handling approach for API responses:</p> <pre><code>export async function handleApiResponse&lt;T&gt;(response: Response): Promise&lt;T&gt; {\n  if (!response.ok) {\n    let errorMessage = `API Error: ${response.status}`;\n    try {\n      const errorData = await response.json();\n      errorMessage = errorData.detail || errorMessage;\n    } catch (e) {\n      // Use default error message if we can't parse the response\n    }\n    throw new Error(errorMessage);\n  }\n\n  return response.json() as Promise&lt;T&gt;;\n}\n</code></pre>"},{"location":"api/frontend-integration/#type-safety","title":"Type Safety","text":"<p>The frontend uses TypeScript interfaces to ensure type safety when working with API responses:</p> <pre><code>// Example entity interface\ninterface Entity {\n  id: string;\n  name: string;\n  device_type: string;\n  suggested_area: string;\n  state: string;\n  raw: Record&lt;string, any&gt;;\n  capabilities: string[];\n  last_updated: string;\n}\n\n// Light-specific interface\ninterface LightStatus extends Entity {\n  brightness?: number;\n}\n</code></pre> <p>This ensures that API data is properly validated at compile-time.</p>"},{"location":"api/openapi/","title":"OpenAPI Specification","text":"<p>The rvc2api service provides a comprehensive OpenAPI specification that documents all available API endpoints, request parameters, response formats, and data models.</p>"},{"location":"api/openapi/#what-is-openapi","title":"What is OpenAPI?","text":"<p>OpenAPI (formerly known as Swagger) is a specification for machine-readable interface files for describing, producing, consuming, and visualizing RESTful web services. The OpenAPI specification defines a standard, language-agnostic interface to RESTful APIs.</p>"},{"location":"api/openapi/#how-to-access-the-openapi-specification","title":"How to Access the OpenAPI Specification","text":""},{"location":"api/openapi/#interactive-documentation","title":"Interactive Documentation","text":"<p>The FastAPI framework automatically generates interactive API documentation based on the OpenAPI specification. You can access it directly in your browser while the server is running:</p> <ul> <li>Swagger UI: http://localhost:8000/docs</li> <li>ReDoc: http://localhost:8000/redoc</li> </ul>"},{"location":"api/openapi/#raw-openapi-schema","title":"Raw OpenAPI Schema","text":"<p>You can also access the raw OpenAPI schema in JSON format:</p> <ul> <li>JSON: http://localhost:8000/openapi.json</li> </ul> <p>For convenience, the OpenAPI schema is also exported to files in the <code>docs/api</code> directory:</p> <ul> <li><code>openapi.json</code> - JSON format</li> <li><code>openapi.yaml</code> - YAML format</li> </ul>"},{"location":"api/openapi/#generating-api-clients","title":"Generating API Clients","text":"<p>You can use the OpenAPI schema to generate client libraries for various programming languages using tools like:</p> <ul> <li>openapi-generator</li> <li>Swagger Codegen</li> </ul>"},{"location":"api/openapi/#example-generating-a-typescript-client","title":"Example: Generating a TypeScript Client","text":"<pre><code># Install OpenAPI Generator\nnpm install @openapitools/openapi-generator-cli -g\n\n# Generate a TypeScript client\nopenapi-generator-cli generate -i docs/api/openapi.json -g typescript-fetch -o web_ui/src/api/generated\n</code></pre>"},{"location":"api/openapi/#example-generating-a-python-client","title":"Example: Generating a Python Client","text":"<pre><code># Install OpenAPI Generator\npip install openapi-generator-cli\n\n# Generate a Python client\nopenapi-generator-cli generate -i docs/api/openapi.json -g python -o clients/python\n</code></pre>"},{"location":"api/openapi/#using-the-openapi-schema-for-documentation","title":"Using the OpenAPI Schema for Documentation","text":"<p>The OpenAPI schema is integrated with this documentation site. You can find the complete API reference in the API section of this documentation.</p> <p>You can also import the OpenAPI schema into tools like:</p> <ul> <li>Postman</li> <li>Insomnia</li> <li>Stoplight Studio</li> </ul> <p>This allows you to explore and test the API without writing any code.</p>"},{"location":"api/openapi/#keeping-the-openapi-schema-up-to-date","title":"Keeping the OpenAPI Schema Up-to-Date","text":"<p>The OpenAPI schema is automatically generated from the API code. To manually update the exported files, run:</p> <pre><code>cd /Users/ryan/src/rvc2api\npoetry run python scripts/export_openapi.py\n</code></pre> <p>This will regenerate the <code>docs/api/openapi.json</code> and <code>docs/api/openapi.yaml</code> files.</p>"},{"location":"api/overview/","title":"API Overview","text":"<p>The rvc2api server provides a RESTful API for interacting with RV-C devices and systems. This page provides an overview of the API structure and common patterns.</p>"},{"location":"api/overview/#api-base-url","title":"API Base URL","text":"<p>All API endpoints are located under <code>/api</code>.</p>"},{"location":"api/overview/#authentication","title":"Authentication","text":"<p>Currently, the API doesn't require authentication. This may change in future versions.</p>"},{"location":"api/overview/#response-format","title":"Response Format","text":"<p>Most API endpoints return JSON responses with the following general structure:</p> <pre><code>{\n  \"key1\": \"value1\",\n  \"key2\": \"value2\",\n  ...\n}\n</code></pre> <p>List endpoints typically return an array of objects:</p> <pre><code>[\n  { \"id\": \"light_1\", ... },\n  { \"id\": \"light_2\", ... },\n  ...\n]\n</code></pre>"},{"location":"api/overview/#error-handling","title":"Error Handling","text":"<p>The API uses standard HTTP status codes to indicate the success or failure of requests:</p> <ul> <li><code>200 OK</code>: The request was successful</li> <li><code>400 Bad Request</code>: The request was invalid or cannot be served</li> <li><code>404 Not Found</code>: The requested resource was not found</li> <li><code>500 Internal Server Error</code>: An error occurred on the server</li> </ul> <p>Error responses include a JSON body with details about the error:</p> <pre><code>{\n  \"detail\": \"Error message\"\n}\n</code></pre>"},{"location":"api/overview/#api-categories","title":"API Categories","text":"<p>The API is organized into the following categories:</p>"},{"location":"api/overview/#entity-api","title":"Entity API","text":"<p>Endpoints for managing and controlling entities (devices like lights, temperature sensors, etc.) in the RV.</p> <ul> <li><code>GET /api/entities</code> - List all entities with optional filtering by device type and area</li> <li><code>GET /api/entities/{id}</code> - Get details for a specific entity</li> <li><code>POST /api/entities/{id}/control</code> - Control an entity (e.g., turn a light on/off)</li> </ul>"},{"location":"api/overview/#can-bus-api","title":"CAN Bus API","text":"<p>Endpoints for interacting with the CAN bus directly.</p> <ul> <li><code>GET /api/can/status</code> - Get status of the CAN bus interface</li> <li><code>GET /api/can/sniffer</code> - Get recent CAN messages</li> </ul>"},{"location":"api/overview/#configuration-api","title":"Configuration API","text":"<p>Endpoints for retrieving and modifying system configuration.</p> <ul> <li><code>GET /api/config</code> - Get current configuration</li> </ul>"},{"location":"api/overview/#websocket-api","title":"WebSocket API","text":"<p>The server also provides WebSocket endpoints for real-time updates.</p> <ul> <li><code>WS /api/ws</code> - WebSocket connection for entity state updates</li> </ul>"},{"location":"api/websocket/","title":"WebSocket API Reference","text":"<p>The WebSocket API allows you to receive real-time updates about entity state changes and system events.</p>"},{"location":"api/websocket/#websocket-communication-flow","title":"WebSocket Communication Flow","text":"<p>The following diagram illustrates how WebSocket communication flows through the system:</p> <pre><code>sequenceDiagram\n    participant Client as React Frontend\n    participant WS as WebSocket Server\n    participant State as App State\n    participant CANBus as CAN Bus Interface\n\n    Client-&gt;&gt;WS: Connect to /api/ws\n    WS-&gt;&gt;Client: Connection Established\n\n    loop Real-time Updates\n        CANBus-&gt;&gt;State: New CAN message\n        State-&gt;&gt;State: Update entity states\n        State-&gt;&gt;WS: Notify of state change\n        WS-&gt;&gt;Client: Send entity_update message\n    end\n\n    Client-&gt;&gt;WS: Send command\n    WS-&gt;&gt;State: Process command\n    State-&gt;&gt;CANBus: Send to CAN bus\n    CANBus--&gt;&gt;State: Acknowledgement\n    State--&gt;&gt;WS: Command result\n    WS--&gt;&gt;Client: Command response</code></pre>"},{"location":"api/websocket/#connection","title":"Connection","text":"<p>Connect to the WebSocket endpoint at:</p> <pre><code>ws://[server-address]/api/ws\n</code></pre>"},{"location":"api/websocket/#message-format","title":"Message Format","text":""},{"location":"api/websocket/#entity-updates","title":"Entity Updates","text":"<p>When an entity's state changes, a message with the following format is sent:</p> <pre><code>{\n  \"type\": \"entity_update\",\n  \"data\": {\n    \"id\": \"light_1\",\n    \"name\": \"Living Room Light\",\n    \"device_type\": \"light\",\n    \"suggested_area\": \"living_room\",\n    \"state\": \"on\",\n    \"raw\": {\n      \"operating_status\": 100\n    },\n    \"capabilities\": [\"toggle\", \"brightness\"],\n    \"last_updated\": \"2023-05-18T15:30:45\",\n    \"source_type\": \"rv-c\"\n  }\n}\n</code></pre>"},{"location":"api/websocket/#can-bus-messages","title":"CAN Bus Messages","text":"<p>When a CAN message is received, it is broadcasted to WebSocket clients:</p> <pre><code>{\n  \"type\": \"can_message\",\n  \"data\": {\n    \"timestamp\": \"2023-05-18T15:30:45\",\n    \"arbitration_id\": \"18FEF121\",\n    \"data\": \"FFFF0000FFFF0000\",\n    \"decoded\": {\n      \"dgn\": \"FEF1\",\n      \"name\": \"DC Dimmer Command\"\n    }\n  }\n}\n</code></pre>"},{"location":"api/websocket/#log-messages","title":"Log Messages","text":"<p>Log messages from the server are also sent via WebSocket:</p> <pre><code>{\n  \"type\": \"log\",\n  \"level\": \"info\",\n  \"message\": \"Light state changed: light_1 turned on\"\n}\n</code></pre>"},{"location":"api/websocket/#usage-in-javascript","title":"Usage in JavaScript","text":"<p>Here's an example of how to connect to and use the WebSocket API from JavaScript:</p> <pre><code>// Connect to the WebSocket\nconst socket = new WebSocket(`ws://${window.location.host}/api/ws`);\n\n// Handle connection open\nsocket.onopen = () =&gt; {\n  console.log(\"WebSocket connection established\");\n};\n\n// Handle incoming messages\nsocket.onmessage = (event) =&gt; {\n  const data = JSON.parse(event.data);\n\n  switch (data.type) {\n    case \"entity_update\":\n      console.log(\"Entity update received:\", data.data);\n      // Update UI with new entity state\n      break;\n\n    case \"can_message\":\n      console.log(\"CAN message received:\", data.data);\n      // Process CAN message if needed\n      break;\n\n    case \"log\":\n      console.log(`Server log [${data.level}]: ${data.message}`);\n      // Display log message if needed\n      break;\n\n    default:\n      console.log(\"Unknown message type:\", data);\n  }\n};\n\n// Handle errors\nsocket.onerror = (error) =&gt; {\n  console.error(\"WebSocket error:\", error);\n};\n\n// Handle connection close\nsocket.onclose = (event) =&gt; {\n  console.log(\"WebSocket connection closed:\", event.code, event.reason);\n  // Reconnect logic could go here\n};\n</code></pre>"},{"location":"architecture/backend/","title":"Backend Architecture","text":"<p>This page provides an overview of the rvc2api backend architecture, focusing on how the API components are structured.</p>"},{"location":"architecture/backend/#core-components","title":"Core Components","text":""},{"location":"architecture/backend/#component-structure","title":"Component Structure","text":"<p>The backend consists of several key components:</p> <pre><code>src/\n\u251c\u2500\u2500 common/               # Shared models and utilities\n\u251c\u2500\u2500 core_daemon/          # FastAPI application\n\u2502   \u251c\u2500\u2500 api_routers/      # API route handlers\n\u2502   \u251c\u2500\u2500 services/         # Business logic services\n\u2502   \u251c\u2500\u2500 models.py         # Pydantic models for API\n\u2502   \u251c\u2500\u2500 app_state.py      # Shared application state\n\u2502   \u251c\u2500\u2500 can_manager.py    # CAN bus integration\n\u2502   \u251c\u2500\u2500 config.py         # Configuration handling\n\u2502   \u251c\u2500\u2500 websocket.py      # WebSocket handlers\n\u2502   \u2514\u2500\u2500 main.py           # Main entry point\n\u2514\u2500\u2500 rvc_decoder/          # RV-C protocol decoder\n</code></pre>"},{"location":"architecture/backend/#component-flow","title":"Component Flow","text":"<pre><code>flowchart TD\n    Client[Client] &lt;--&gt; FastAPI[FastAPI App]\n\n    subgraph Backend\n        FastAPI --&gt; APIRouters[API Routers]\n        FastAPI --&gt; WSHandler[WebSocket Handler]\n\n        APIRouters --&gt; Services[Services]\n        WSHandler --&gt; Services\n\n        Services --&gt; AppState[App State]\n        Services --&gt; RVCDecoder[RV-C Decoder]\n\n        RVCDecoder --&gt; CANInterface[CAN Interface]\n        AppState --&gt; EntityManager[Entity Manager]\n    end\n\n    CANInterface &lt;--&gt; CANBus[CAN Bus Hardware]\n\n    classDef client fill:#E1F5FE,stroke:#0288D1\n    classDef api fill:#E8F5E9,stroke:#4CAF50\n    classDef services fill:#FFF3E0,stroke:#FF9800\n    classDef hardware fill:#FFEBEE,stroke:#F44336\n\n    class Client client\n    class FastAPI,APIRouters,WSHandler api\n    class Services,AppState,EntityManager,RVCDecoder services\n    class CANInterface,CANBus hardware</code></pre>"},{"location":"architecture/backend/#api-architecture","title":"API Architecture","text":""},{"location":"architecture/backend/#fastapi-application","title":"FastAPI Application","text":"<p>The main FastAPI application is created in <code>main.py</code>. It configures:</p> <ul> <li>API metadata and documentation settings</li> <li>Middleware for metrics and logging</li> <li>API routers for different functional areas</li> <li>WebSocket connections for real-time updates</li> <li>Startup and shutdown event handlers</li> </ul>"},{"location":"architecture/backend/#api-routers","title":"API Routers","text":"<p>API routes are organized by functional area in separate modules:</p> <ul> <li><code>api_routers/entities.py</code>: Entity management and control</li> <li><code>api_routers/can.py</code>: CAN bus interaction</li> <li><code>api_routers/config_and_ws.py</code>: Configuration and WebSocket endpoints</li> <li><code>api_routers/docs.py</code>: Documentation-related endpoints</li> </ul> <p>Each router file contains route handlers for a specific area of functionality, keeping the codebase modular and maintainable.</p>"},{"location":"architecture/backend/#data-models","title":"Data Models","text":"<p>Data models are defined using Pydantic, ensuring:</p> <ul> <li>Schema validation for request and response data</li> <li>Automatic documentation generation</li> <li>Type safety throughout the application</li> </ul> <p>Key models include:</p> <ul> <li><code>Entity</code>: Represents a device in the RV (light, tank, etc.)</li> <li><code>ControlCommand</code>: Standardized command format for controlling entities</li> <li><code>ControlEntityResponse</code>: Response format for control operations</li> </ul>"},{"location":"architecture/backend/#state-management","title":"State Management","text":"<p>The application maintains shared state in <code>app_state.py</code>:</p> <ul> <li>Current entity states</li> <li>Entity history</li> <li>Entity mappings (DGN to entity ID)</li> <li>CAN bus configuration</li> </ul> <p>This centralized state management allows different components to access the same data without tight coupling.</p>"},{"location":"architecture/backend/#real-time-communication","title":"Real-time Communication","text":"<p>The application provides real-time updates through WebSockets:</p> <ul> <li>Entity state changes</li> <li>CAN bus messages</li> <li>System log events</li> </ul> <p>WebSocket connections are managed in <code>websocket.py</code>, which handles:</p> <ul> <li>Client connection management</li> <li>Message broadcasting</li> <li>Connection authentication (when enabled)</li> </ul>"},{"location":"architecture/backend/#can-bus-integration","title":"CAN Bus Integration","text":"<p>The application integrates with the RV-C CAN bus through:</p> <ul> <li><code>can_manager.py</code>: Handles CAN bus connections and message processing</li> <li><code>rvc_decoder/</code>: Decodes raw CAN messages into structured data</li> </ul> <p>When a message is received from the CAN bus:</p> <ol> <li>It's decoded using the RV-C specification</li> <li>The decoded data updates entity state in <code>app_state.py</code></li> <li>The updated entity is broadcast to WebSocket clients</li> <li>The entity state history is updated</li> </ol>"},{"location":"architecture/backend/#future-architecture","title":"Future Architecture","text":"<p>The planned future architecture will reorganize the codebase into:</p> <pre><code>backend/\n\u251c\u2500\u2500 api/               # API routes and controllers\n\u251c\u2500\u2500 integrations/      # External system integrations\n\u2502   \u2514\u2500\u2500 rvc/           # RV-C specific code\n\u251c\u2500\u2500 middleware/        # HTTP and WebSocket middleware\n\u251c\u2500\u2500 models/            # Application data models\n\u251c\u2500\u2500 services/          # Business logic services\n\u2514\u2500\u2500 settings/          # Configuration handling\n</code></pre> <p>This reorganization will:</p> <ul> <li>Improve separation of concerns</li> <li>Make the codebase more maintainable</li> <li>Prepare for additional integrations beyond RV-C</li> </ul>"},{"location":"architecture/feature-flags/","title":"Feature Flag System","text":""},{"location":"architecture/feature-flags/#overview","title":"Overview","text":"<p>The rvc2api backend uses a robust, production-ready feature flag system to manage optional and experimental features. This system is designed for maintainability, extensibility, and runtime configurability.</p>"},{"location":"architecture/feature-flags/#how-feature-flags-work","title":"How Feature Flags Work","text":"<ul> <li>Definition: All available (registerable) features are defined in <code>backend/services/feature_flags.yaml</code>. This YAML file specifies:</li> <li>The feature name</li> <li>Default enabled/disabled state</li> <li>Whether the feature is core/required</li> <li> <p>Any dependencies on other features</p> </li> <li> <p>Registration: At startup, the backend loads all features from <code>feature_flags.yaml</code> and registers them with the <code>FeatureManager</code>.</p> </li> <li> <p>Runtime State: The actual enabled/disabled state of each feature is determined at runtime by environment variables, Pydantic settings, or other config sources. This allows you to override the YAML defaults without editing the file.</p> </li> <li> <p>For example, setting <code>ENABLE_CANBUS=false</code> in your environment or config will disable the <code>canbus</code> feature, even if it is enabled by default in YAML.</p> </li> <li> <p>Dependencies: Feature dependencies are resolved automatically. If a feature depends on another, it will only be enabled if all its dependencies are enabled.</p> </li> <li> <p>Extensibility: The system supports future integration with external feature flag providers (e.g., LaunchDarkly, Unleash) and can be extended to support toggling via a database or admin UI.</p> </li> </ul>"},{"location":"architecture/feature-flags/#example-feature_flagsyaml","title":"Example: feature_flags.yaml","text":"<pre><code>canbus:\n  enabled: true\n  core: true\n  depends_on: []\n\nweb_ui:\n  enabled: true\n  core: true\n  depends_on: []\n\n# Add additional features below as needed\n</code></pre>"},{"location":"architecture/feature-flags/#best-practices","title":"Best Practices","text":"<ul> <li>Add new features by editing <code>feature_flags.yaml</code>.</li> <li>Enable/disable features at runtime using environment variables or config files, not by editing YAML in production.</li> <li>Document feature purpose and dependencies in the YAML file and/or codebase.</li> <li>Reload features at runtime if your config changes (see <code>FeatureManager.reload_features_from_config</code>).</li> </ul>"},{"location":"architecture/feature-flags/#see-also","title":"See Also","text":"<ul> <li>backend/services/feature_manager.py</li> <li>backend/services/feature_flags.yaml</li> <li>Configuration and Environment Variables</li> </ul>"},{"location":"architecture/frontend/","title":"Frontend Architecture","text":"<p>This page provides an overview of the rvc2api frontend architecture, focusing on how it integrates with the API.</p>"},{"location":"architecture/frontend/#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TD\n    Client[Browser Client] --&gt; ReactApp[React Application]\n\n    subgraph \"Frontend Architecture\"\n        ReactApp --&gt; Router[React Router]\n        Router --&gt; Pages[Page Components]\n        Pages --&gt; SharedComponents[Shared Components]\n        Pages --&gt; Hooks[Custom Hooks]\n\n        SharedComponents --&gt; UIComponents[UI Components]\n        SharedComponents --&gt; EntityComponents[Entity Components]\n\n        Hooks --&gt; APIHooks[API Integration Hooks]\n        Hooks --&gt; UtilityHooks[Utility Hooks]\n\n        APIHooks --&gt; WebSocketClient[WebSocket Client]\n        APIHooks --&gt; RESTClient[REST API Client]\n\n        WebSocketClient --&gt; WSContext[WebSocket Context]\n        RESTClient --&gt; DataContext[Data Context]\n    end\n\n    WSContext --&gt; BackendWS[Backend WebSocket]\n    DataContext --&gt; BackendREST[Backend REST API]\n\n    classDef client fill:#f9f9f9,stroke:#333,stroke-width:1px;\n    classDef frontend fill:#bbdefb,stroke:#1976d2,stroke-width:1px;\n    classDef api fill:#c8e6c9,stroke:#388e3c,stroke-width:1px;\n    classDef backend fill:#ffecb3,stroke:#ffa000,stroke-width:1px;\n\n    class Client client;\n    class ReactApp,Router,Pages,SharedComponents,UIComponents,EntityComponents,Hooks,APIHooks,UtilityHooks frontend;\n    class WebSocketClient,RESTClient,WSContext,DataContext api;\n    class BackendWS,BackendREST backend;</code></pre>"},{"location":"architecture/frontend/#core-components","title":"Core Components","text":"<p>The frontend is built using React, TypeScript, and Vite, with the following structure:</p> <pre><code>web_ui/\n\u251c\u2500\u2500 public/            # Static assets\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 api/           # API integration\n\u2502   \u251c\u2500\u2500 components/    # React components\n\u2502   \u251c\u2500\u2500 context/       # React context providers\n\u2502   \u251c\u2500\u2500 hooks/         # Custom React hooks\n\u2502   \u251c\u2500\u2500 pages/         # Page components\n\u2502   \u251c\u2500\u2500 store/         # State management\n\u2502   \u251c\u2500\u2500 styles/        # CSS and styling\n\u2502   \u2514\u2500\u2500 utils/         # Utility functions\n\u2514\u2500\u2500 docs/              # Frontend-specific documentation\n</code></pre>"},{"location":"architecture/frontend/#api-integration","title":"API Integration","text":""},{"location":"architecture/frontend/#api-module-structure","title":"API Module Structure","text":"<p>The API integration is organized in the <code>src/api</code> directory:</p> <pre><code>src/api/\n\u251c\u2500\u2500 index.ts          # Main API exports &amp; utilities\n\u251c\u2500\u2500 endpoints.ts      # API endpoint functions\n\u2514\u2500\u2500 types.ts          # TypeScript interfaces for API models\n</code></pre> <p>This structure separates concerns and allows for better type safety and maintainability.</p>"},{"location":"architecture/frontend/#api-endpoints","title":"API Endpoints","text":"<p>API endpoints are defined in <code>endpoints.ts</code> as functions that:</p> <ol> <li>Construct the appropriate URL</li> <li>Set up request options</li> <li>Make the fetch request</li> <li>Handle errors and parse responses</li> </ol> <p>Example:</p> <pre><code>export async function fetchLights(): Promise&lt;LightStatus[]&gt; {\n  const response = await fetch(\n    `${API_BASE}/entities?device_type=light`,\n    defaultOptions\n  );\n  return handleApiResponse&lt;LightStatus[]&gt;(response);\n}\n</code></pre>"},{"location":"architecture/frontend/#api-types","title":"API Types","text":"<p>API types in <code>types.ts</code> define the structure of request and response data using TypeScript interfaces:</p> <pre><code>export interface Entity {\n  id: string;\n  name: string;\n  device_type: string;\n  suggested_area: string;\n  state: string;\n  raw: Record&lt;string, any&gt;;\n  capabilities: string[];\n  last_updated: string;\n}\n\nexport interface LightStatus extends Entity {\n  brightness?: number;\n}\n</code></pre>"},{"location":"architecture/frontend/#state-management","title":"State Management","text":"<p>The frontend uses React's Context API for state management, with custom hooks to interact with the API:</p> <pre><code>// Example of a custom hook for lights\nexport function useLights() {\n  const [lights, setLights] = useState&lt;LightStatus[]&gt;([]);\n  const [loading, setLoading] = useState(true);\n  const [error, setError] = useState&lt;Error | null&gt;(null);\n\n  useEffect(() =&gt; {\n    async function loadLights() {\n      try {\n        setLoading(true);\n        const data = await fetchLights();\n        setLights(data);\n        setError(null);\n      } catch (err) {\n        setError(err as Error);\n      } finally {\n        setLoading(false);\n      }\n    }\n\n    loadLights();\n  }, []);\n\n  return { lights, loading, error };\n}\n</code></pre>"},{"location":"architecture/frontend/#websocket-integration","title":"WebSocket Integration","text":"<p>The frontend connects to the WebSocket API for real-time updates through a custom hook:</p> <pre><code>export function useWebSocket() {\n  const [isConnected, setIsConnected] = useState(false);\n  const [lastMessage, setLastMessage] = useState&lt;any&gt;(null);\n  const socketRef = useRef&lt;WebSocket | null&gt;(null);\n\n  useEffect(() =&gt; {\n    const wsProtocol = window.location.protocol === \"https:\" ? \"wss:\" : \"ws:\";\n    const wsUrl = `${wsProtocol}//${window.location.host}/api/ws`;\n\n    const socket = new WebSocket(wsUrl);\n    socketRef.current = socket;\n\n    socket.onopen = () =&gt; {\n      setIsConnected(true);\n    };\n\n    socket.onmessage = (event) =&gt; {\n      try {\n        const data = JSON.parse(event.data);\n        setLastMessage(data);\n      } catch (e) {\n        console.error(\"Failed to parse WebSocket message:\", e);\n      }\n    };\n\n    socket.onclose = () =&gt; {\n      setIsConnected(false);\n    };\n\n    return () =&gt; {\n      socket.close();\n    };\n  }, []);\n\n  return { isConnected, lastMessage };\n}\n</code></pre>"},{"location":"architecture/frontend/#component-structure","title":"Component Structure","text":"<p>Components are organized by feature, with each feature typically including:</p> <ul> <li>A container component that handles API calls and state</li> <li>Presentational components that render UI based on props</li> <li>Custom hooks for logic reuse</li> </ul>"},{"location":"architecture/frontend/#typescript-integration","title":"TypeScript Integration","text":"<p>TypeScript is used throughout the application to ensure type safety, with:</p> <ul> <li>API types matching backend models</li> <li>Props interfaces for components</li> <li>Strong typing for hooks and utility functions</li> </ul>"},{"location":"architecture/overview/","title":"Project Overview","text":"<p>The rvc2api project provides a modern API and WebSocket service for RV-C (Recreational Vehicle Controller Area Network) systems, allowing you to monitor and control various devices in your RV.</p>"},{"location":"architecture/overview/#system-architecture","title":"System Architecture","text":"<p>The system consists of several major components with clear separation of concerns:</p> <pre><code>graph TD\n    User[User] --&gt; WebUI[Web UI]\n    User --&gt; MobileApp[Mobile Apps]\n\n    subgraph \"Frontend Layer\"\n        WebUI --&gt; REST[REST API Client]\n        WebUI --&gt; WS[WebSocket Client]\n        MobileApp --&gt; REST\n        MobileApp --&gt; WS\n    end\n\n    subgraph \"API Layer\"\n        REST --&gt; FastAPI[FastAPI Server]\n        WS --&gt; WSServer[WebSocket Server]\n        FastAPI --&gt; AppState[Application State]\n        WSServer --&gt; AppState\n    end\n\n    subgraph \"Business Logic\"\n        AppState --&gt; EntityManager[Entity Manager]\n        AppState --&gt; HistoryManager[History Manager]\n        EntityManager --&gt; Decoder[RV-C Decoder]\n        HistoryManager --&gt; Storage[State Storage]\n    end\n\n    subgraph \"Device Layer\"\n        Decoder --&gt; CanManager[CAN Manager]\n        CanManager --&gt; CanInterface[CAN Bus Interface]\n        CanInterface --&gt; RVCBus[RV-C CAN Bus]\n    end\n\n    classDef user fill:#f5f5f5,stroke:#bdbdbd,color:#212121;\n    classDef frontend fill:#bbdefb,stroke:#1976d2,color:#212121;\n    classDef api fill:#c8e6c9,stroke:#388e3c,color:#212121;\n    classDef logic fill:#fff9c4,stroke:#fbc02d,color:#212121;\n    classDef device fill:#ffccbc,stroke:#e64a19,color:#212121;\n\n    class User user;\n    class WebUI,MobileApp,REST,WS frontend;\n    class FastAPI,WSServer,AppState api;\n    class EntityManager,HistoryManager,Decoder,Storage logic;\n    class CanManager,CanInterface,RVCBus device;</code></pre>"},{"location":"architecture/overview/#backend-components","title":"Backend Components","text":"<p>The backend is built with Python and FastAPI:</p> <ul> <li>FastAPI Application: Provides RESTful API and WebSocket endpoints</li> <li>RV-C Decoder: Translates CAN messages to/from human-readable formats</li> <li>State Management: Maintains entity states and histories</li> <li>WebSocket Server: Provides real-time updates to clients</li> </ul>"},{"location":"architecture/overview/#frontend-components","title":"Frontend Components","text":"<p>The frontend is built with React, TypeScript, and Vite:</p> <ul> <li>React Application: Single-page application with modern UI</li> <li>TypeScript: Provides type safety and better developer experience</li> <li>API Client: Communicates with the backend API</li> <li>WebSocket Client: Receives real-time updates</li> </ul>"},{"location":"architecture/overview/#directory-structure","title":"Directory Structure","text":"<p>The project follows a monorepo structure:</p> <pre><code>rvc2api/\n\u251c\u2500\u2500 src/                  # Python backend code\n\u2502   \u251c\u2500\u2500 common/           # Shared models and utilities\n\u2502   \u251c\u2500\u2500 core_daemon/      # FastAPI application\n\u2502   \u2514\u2500\u2500 rvc_decoder/      # RV-C protocol decoder\n\u251c\u2500\u2500 web_ui/               # React frontend\n\u2502   \u251c\u2500\u2500 src/              # Frontend source code\n\u2502   \u2514\u2500\u2500 docs/             # Frontend-specific documentation\n\u251c\u2500\u2500 docs/                 # Project documentation\n\u2514\u2500\u2500 scripts/              # Utility scripts\n</code></pre>"},{"location":"architecture/overview/#key-features","title":"Key Features","text":"<ul> <li>Entity Management: Monitor and control RV entities like lights, tanks, thermostats</li> <li>Real-time Updates: WebSocket for instant updates on entity state changes</li> <li>Unified API: Consistent endpoint structure for all entity types</li> <li>Type Safety: Strong typing in both backend and frontend</li> <li>Interactive Documentation: Auto-generated API docs via OpenAPI/Swagger</li> </ul>"},{"location":"architecture/overview/#development-and-deployment","title":"Development and Deployment","text":""},{"location":"architecture/overview/#development","title":"Development","text":"<p>Development workflows are streamlined with:</p> <ul> <li>Poetry: Python dependency management</li> <li>npm: JavaScript dependency management</li> <li>VS Code Tasks: Common tasks for building, testing, and running</li> <li>Pre-commit Hooks: Code quality checks</li> </ul>"},{"location":"architecture/overview/#deployment","title":"Deployment","text":"<p>The system can be deployed in various ways:</p> <ul> <li>Docker: Containerized deployment</li> <li>NixOS: Native integration with NixOS</li> <li>Direct Installation: On compatible Linux systems</li> </ul>"},{"location":"architecture/overview/#api-design-decision","title":"API Design Decision","text":"<p>All light-related API operations are consolidated under <code>/api/entities</code> endpoints (e.g., <code>/api/entities?device_type=light</code>). The legacy <code>/api/lights</code> endpoint is not used. This ensures a unified, type-safe, and extensible API surface for all entity types.</p>"},{"location":"architecture/overview/#entity-control-command-structure","title":"Entity Control Command Structure","text":"<p>When controlling entities via the <code>/api/entities/{id}/control</code> endpoint, the request body must use the standardized command format:</p> <pre><code>// Turn light on\n{ \"command\": \"set\", \"state\": \"on\" }\n\n// Set light brightness\n{ \"command\": \"set\", \"state\": \"on\", \"brightness\": 75 }\n\n// Toggle light state\n{ \"command\": \"toggle\" }\n\n// Adjust brightness\n{ \"command\": \"brightness_up\" }\n{ \"command\": \"brightness_down\" }\n</code></pre> <ul> <li>Feature Flags: Feature flag system, configuration, and runtime overrides</li> </ul>"},{"location":"contributing/documentation/","title":"Contributing to Documentation","text":"<p>This guide explains how to contribute to the rvc2api documentation.</p>"},{"location":"contributing/documentation/#documentation-structure","title":"Documentation Structure","text":"<p>The documentation is built using MkDocs with the Material theme.</p> <p>The documentation files are located in the following directories:</p> <ul> <li><code>/docs/</code>: Main project documentation (markdown files)</li> <li><code>/web_ui/docs/</code>: Frontend-specific documentation</li> </ul>"},{"location":"contributing/documentation/#setting-up-the-documentation-environment","title":"Setting Up the Documentation Environment","text":"<p>To work on the documentation, you'll need to have the project dependencies installed:</p> <pre><code>poetry install\n</code></pre> <p>This will install MkDocs and all required plugins.</p>"},{"location":"contributing/documentation/#previewing-the-documentation-locally","title":"Previewing the Documentation Locally","text":"<p>To preview the documentation while you're working on it:</p> <pre><code>cd docs\nmkdocs serve\n</code></pre> <p>This will start a local web server at http://localhost:8000/ that automatically updates when you save changes to the markdown files.</p> <p>You can also use the VS Code task \"Server: Serve Documentation\" to launch the docs server.</p>"},{"location":"contributing/documentation/#directory-organization","title":"Directory Organization","text":"<p>The documentation is organized into several sections:</p> <ul> <li>API Reference: Documentation for the REST and WebSocket APIs</li> <li>Architecture: System design and component organization</li> <li>Development Guides: How to set up and develop the project</li> <li>Contributing: Guidelines for contributing to the project</li> </ul>"},{"location":"contributing/documentation/#adding-new-documentation","title":"Adding New Documentation","text":"<p>To add new documentation:</p> <ol> <li>Create a new markdown file in the appropriate directory</li> <li>Add a reference to it in <code>docs/mkdocs.yml</code> under the <code>nav</code> section</li> <li>Follow the existing style and formatting</li> </ol>"},{"location":"contributing/documentation/#documentation-standards","title":"Documentation Standards","text":""},{"location":"contributing/documentation/#formatting","title":"Formatting","text":"<ul> <li>Use ATX-style headers (<code>#</code>, <code>##</code>, <code>###</code>, etc.)</li> <li>Use fenced code blocks with language specifiers</li> <li>Use relative links to other pages within the documentation</li> <li>Include alt text for images</li> </ul>"},{"location":"contributing/documentation/#code-examples","title":"Code Examples","text":"<ul> <li>Include language specifiers for code blocks (e.g., ```python)</li> <li>Use meaningful variable names in examples</li> <li>Add comments to explain complex code</li> <li>Ensure code examples are tested and working</li> </ul>"},{"location":"contributing/documentation/#api-documentation","title":"API Documentation","text":"<ul> <li>Document all parameters and return values</li> <li>Include example requests and responses</li> <li>Specify required permissions or authentication</li> <li>Note any limitations or restrictions</li> </ul>"},{"location":"contributing/documentation/#generating-api-documentation","title":"Generating API Documentation","text":"<p>The API documentation is partially generated from the OpenAPI schema produced by FastAPI. To update the OpenAPI schema:</p> <pre><code>poetry run python scripts/export_openapi.py\n</code></pre> <p>This will generate <code>docs/api/openapi.json</code> and <code>docs/api/openapi.yaml</code>.</p> <p>You can also use the VS Code task \"API: Export OpenAPI Schema\" to generate the schema.</p>"},{"location":"contributing/documentation/#building-the-documentation-for-production","title":"Building the Documentation for Production","text":"<p>To build the documentation for production:</p> <pre><code>cd docs\nmkdocs build\n</code></pre> <p>This will generate a static site in the <code>site</code> directory that can be deployed to a web server.</p> <p>You can also use the VS Code task \"Build: Documentation\" to build the documentation.</p>"},{"location":"contributing/documentation/#extending-the-documentation","title":"Extending the Documentation","text":""},{"location":"contributing/documentation/#adding-new-sections","title":"Adding New Sections","text":"<p>To add a new section to the documentation:</p> <ol> <li>Create a new directory in <code>/docs/</code></li> <li>Add markdown files to the directory</li> <li>Update <code>docs/mkdocs.yml</code> to include the new section and files</li> </ol>"},{"location":"contributing/documentation/#adding-plugins","title":"Adding plugins","text":"<p>To add a new plugin to the documentation:</p> <ol> <li>Add the plugin to <code>pyproject.toml</code> in the <code>[tool.poetry.dev-dependencies]</code> section</li> <li>Run <code>poetry install</code> to install the plugin</li> <li>Update <code>docs/mkdocs.yml</code> to configure the plugin</li> </ol>"},{"location":"contributing/openapi/","title":"Using OpenAPI in Development","text":"<p>This guide explains how to use the OpenAPI schema in your development workflow for both frontend and backend development.</p>"},{"location":"contributing/openapi/#what-is-openapi","title":"What is OpenAPI?","text":"<p>OpenAPI is a specification for describing RESTful APIs. It provides a standardized way to document API endpoints, request parameters, response formats, and data models.</p> <p>FastAPI automatically generates an OpenAPI schema based on your route definitions, type hints, and docstrings. This schema can be used to:</p> <ol> <li>Generate interactive API documentation</li> <li>Create API client libraries</li> <li>Validate API requests and responses</li> <li>Generate mock data for testing</li> </ol>"},{"location":"contributing/openapi/#accessing-the-openapi-schema","title":"Accessing the OpenAPI Schema","text":""},{"location":"contributing/openapi/#interactive-documentation","title":"Interactive Documentation","text":"<p>When the rvc2api server is running, you can access the interactive API documentation at:</p> <ul> <li>Swagger UI: http://localhost:8000/docs</li> <li>ReDoc: http://localhost:8000/redoc</li> </ul>"},{"location":"contributing/openapi/#raw-schema","title":"Raw Schema","text":"<p>You can also access the raw OpenAPI schema in JSON format:</p> <ul> <li>JSON: http://localhost:8000/openapi.json</li> </ul>"},{"location":"contributing/openapi/#exported-schema-files","title":"Exported Schema Files","text":"<p>The OpenAPI schema is also exported to files in the <code>docs/api</code> directory:</p> <ul> <li><code>openapi.json</code> - JSON format</li> <li><code>openapi.yaml</code> - YAML format</li> </ul> <p>To update these files, run:</p> <pre><code>poetry run python scripts/export_openapi.py\n</code></pre> <p>Or use the VS Code task \"API: Export OpenAPI Schema\".</p>"},{"location":"contributing/openapi/#frontend-development-with-openapi","title":"Frontend Development with OpenAPI","text":""},{"location":"contributing/openapi/#generating-typescript-types","title":"Generating TypeScript Types","text":"<p>You can generate TypeScript types from the OpenAPI schema using tools like <code>openapi-typescript</code>:</p> <pre><code># Install the tool\nnpm install --save-dev openapi-typescript\n\n# Generate types\nnpx openapi-typescript docs/api/openapi.json --output web_ui/src/api/generated/types.ts\n</code></pre> <p>This ensures that your frontend code uses types that are consistent with the backend API.</p>"},{"location":"contributing/openapi/#generating-api-clients","title":"Generating API Clients","text":"<p>You can also generate a full TypeScript client for the API:</p> <pre><code># Install OpenAPI Generator\nnpm install @openapitools/openapi-generator-cli -g\n\n# Generate a TypeScript client\nopenapi-generator-cli generate -i docs/api/openapi.json -g typescript-fetch -o web_ui/src/api/generated\n</code></pre> <p>This client provides type-safe methods for all API endpoints.</p>"},{"location":"contributing/openapi/#backend-development-with-openapi","title":"Backend Development with OpenAPI","text":""},{"location":"contributing/openapi/#documenting-endpoints","title":"Documenting Endpoints","text":"<p>To ensure that your API endpoints are properly documented in the OpenAPI schema, follow these practices:</p>"},{"location":"contributing/openapi/#route-decorators","title":"Route Decorators","text":"<p>Use the full range of FastAPI route decorators:</p> <pre><code>@router.get(\n    \"/entities\",\n    response_model=dict[str, Entity],\n    summary=\"List all entities\",\n    description=\"Retrieve all entities with optional filtering by device type or area.\",\n    response_description=\"A dictionary of entities matching the filter criteria.\",\n    tags=[\"entities\"]\n)\n</code></pre>"},{"location":"contributing/openapi/#parameter-documentation","title":"Parameter Documentation","text":"<p>Document all parameters:</p> <pre><code>async def list_entities(\n    device_type: str | None = Query(\n        None,\n        description=\"Filter entities by device type (e.g., 'light', 'tank', 'temperature')\"\n    ),\n    area: str | None = Query(\n        None,\n        description=\"Filter entities by suggested area (e.g., 'living', 'bedroom', 'bathroom')\"\n    ),\n):\n    \"\"\"\n    Return all entities, optionally filtered by device_type and/or area.\n    ...\n    \"\"\"\n</code></pre>"},{"location":"contributing/openapi/#response-examples","title":"Response Examples","text":"<p>Provide examples for requests and responses using FastAPI's example system:</p> <pre><code>@router.post(\n    \"/entities/{entity_id}/control\",\n    response_model=ControlEntityResponse,\n)\nasync def control_entity(\n    entity_id: str,\n    cmd: Annotated[\n        ControlCommand,\n        Body(\n            examples={\n                \"turn_on\": {\"summary\": \"Turn light on\", \"value\": {\"command\": \"set\", \"state\": \"on\"}},\n                \"turn_off\": {\"summary\": \"Turn light off\", \"value\": {\"command\": \"set\", \"state\": \"off\"}},\n            }\n        ),\n    ],\n):\n    \"\"\"Control a light entity based on the provided command.\"\"\"\n</code></pre>"},{"location":"contributing/openapi/#testing-against-the-schema","title":"Testing Against the Schema","text":"<p>You can validate your API implementation against the OpenAPI schema using tools like <code>openapi-python-client</code>:</p> <pre><code>pip install openapi-python-client\n\n# Generate a client\nopenapi-python-client generate --url http://localhost:8000/openapi.json --output api_client\n\n# Use the client in tests\n</code></pre>"},{"location":"contributing/openapi/#openapi-integration-tools","title":"OpenAPI Integration Tools","text":""},{"location":"contributing/openapi/#vs-code-extensions","title":"VS Code Extensions","text":"<ul> <li>OpenAPI (Swagger) Editor: Provides syntax highlighting and validation for OpenAPI files</li> <li>Swagger Viewer: Preview OpenAPI schemas in VS Code</li> </ul>"},{"location":"contributing/openapi/#postman-integration","title":"Postman Integration","text":"<p>You can import the OpenAPI schema into Postman:</p> <ol> <li>In Postman, click \"Import\"</li> <li>Select \"OpenAPI\"</li> <li>Choose the <code>openapi.json</code> file or enter the URL <code>http://localhost:8000/openapi.json</code></li> </ol> <p>This will create a collection with all API endpoints, making it easy to test and explore the API.</p>"},{"location":"contributing/openapi/#continuous-integration","title":"Continuous Integration","text":"<p>To ensure that your OpenAPI schema stays up-to-date with your code, add the following steps to your CI pipeline:</p> <ol> <li>Generate the OpenAPI schema</li> <li>Compare it with the committed version</li> <li>Fail if there are differences</li> </ol> <p>This ensures that your documentation always matches your implementation.</p>"},{"location":"contributing/pull-requests/","title":"Pull Request Guidelines","text":"<p>This document provides guidelines for creating and submitting pull requests to the rvc2api project.</p>"},{"location":"contributing/pull-requests/#pull-request-workflow","title":"Pull Request Workflow","text":"<pre><code>flowchart TD\n    Issue[Issue or Feature Request] --&gt; Fork[Fork Repository]\n    Fork --&gt; Branch[Create Feature Branch]\n    Branch --&gt; Develop[Develop Changes]\n    Develop --&gt; QualityChecks{Quality Checks}\n    QualityChecks --&gt;|Pass| CreatePR[Create Pull Request]\n    QualityChecks --&gt;|Fail| Develop\n\n    CreatePR --&gt; CodeReview{Code Review}\n    CodeReview --&gt;|Approved| CIChecks{CI Checks}\n    CodeReview --&gt;|Changes Requested| UpdatePR[Update PR]\n    UpdatePR --&gt; CodeReview\n\n    CIChecks --&gt;|Pass| Merge[Merge PR]\n    CIChecks --&gt;|Fail| FixCI[Fix CI Issues]\n    FixCI --&gt; CIChecks\n\n    Merge --&gt; Release[Include in Release]\n\n    classDef start fill:#e3f2fd,stroke:#1565c0,stroke-width:2px;\n    classDef process fill:#e8f5e9,stroke:#2e7d32,stroke-width:1px;\n    classDef decision fill:#fff8e1,stroke:#f9a825,stroke-width:1px;\n    classDef end fill:#fce4ec,stroke:#c2185b,stroke-width:2px;\n\n    class Issue start;\n    class Fork,Branch,Develop,UpdatePR,FixCI process;\n    class QualityChecks,CodeReview,CIChecks decision;\n    class Merge,Release end;</code></pre>"},{"location":"contributing/pull-requests/#pull-request-expectations","title":"Pull Request Expectations","text":"<p>All pull requests should include:</p> <ul> <li>Tests for new logic and functionality</li> <li>Documentation updates (inline or markdown)</li> <li>Passing code quality checks:</li> <li>Linting: <code>ruff check .</code></li> <li>Type checking: <code>pyright src</code></li> <li>Formatting: <code>ruff format src</code></li> <li>Scoped, focused changes rather than monolithic updates</li> <li>References to design intent or research, if needed</li> </ul>"},{"location":"contributing/pull-requests/#pull-request-structure","title":"Pull Request Structure","text":"<p>When creating a pull request, please include the following sections:</p>"},{"location":"contributing/pull-requests/#problem-statement","title":"Problem Statement","text":"<p>Clearly describe the issue or requirement that the PR addresses. This helps reviewers understand the context and motivation for the changes.</p>"},{"location":"contributing/pull-requests/#solution-overview","title":"Solution Overview","text":"<p>Provide a high-level description of your solution approach. Explain key design decisions and trade-offs considered.</p>"},{"location":"contributing/pull-requests/#testing-strategy","title":"Testing Strategy","text":"<p>Describe how you've tested the changes:</p> <ul> <li>What kinds of tests were added or updated</li> <li>How edge cases are covered</li> <li>Any manual testing that was performed</li> </ul>"},{"location":"contributing/pull-requests/#code-quality-verification","title":"Code Quality Verification","text":"<p>Explain the steps you've taken to ensure code quality:</p> <ul> <li>Confirmation that linting and type checking pass</li> <li>Any type stub additions or modifications that were necessary</li> <li>Formatting and style consistency measures</li> </ul>"},{"location":"contributing/pull-requests/#documentation-updates","title":"Documentation Updates","text":"<p>Outline any documentation changes:</p> <ul> <li>API documentation updates</li> <li>New or updated markdown files</li> <li>Changes to inline documentation</li> </ul>"},{"location":"contributing/pull-requests/#related-issues","title":"Related Issues","text":"<p>Link to any related GitHub issues that this PR addresses or impacts, using the GitHub issue linking syntax (e.g., \"Fixes #123\").</p>"},{"location":"contributing/pull-requests/#pull-request-review-process","title":"Pull Request Review Process","text":"<ol> <li>Pull requests will be reviewed by at least one maintainer</li> <li>Automated checks must pass (CI/CD)</li> <li>All review comments must be addressed</li> <li>Final approval requires passing CI and maintainer approval</li> </ol>"},{"location":"contributing/pull-requests/#tips-for-successful-pull-requests","title":"Tips for Successful Pull Requests","text":"<ul> <li>Keep changes focused: Address one concern per PR</li> <li>Provide context: Help reviewers understand why changes are needed</li> <li>Be responsive: Address review feedback promptly</li> <li>Update tests: Ensure test coverage remains high</li> <li>Document changes: Update relevant documentation</li> </ul> <p>For more detailed information about the project's code style and development practices, refer to:</p> <ul> <li>Python Code Style</li> <li>TypeScript Code Style</li> <li>Pre-Commit Hooks</li> </ul>"},{"location":"specs/faiss-integration-plan/","title":"FAISS Integration Plan for RV-C Documentation","text":""},{"location":"specs/faiss-integration-plan/#overview","title":"Overview","text":"<p>This document outlines the plan to incorporate FAISS vector database integration into the rvc2api project to enhance RV-C protocol interpretation, validation, and discovery. The system will leverage semantic search capabilities through vector embeddings to improve the accuracy and completeness of our RV-C decoder.</p>"},{"location":"specs/faiss-integration-plan/#goals","title":"Goals","text":"<ol> <li>Enhance DGN Validation: Validate that decoded DGN values match the official RV-C specification</li> <li>Identify Missing Mappings: Discover gaps in our current rvc.json mappings</li> <li>Detect Additional Devices: Identify devices in the RV-C specification that aren't currently mapped</li> </ol>"},{"location":"specs/faiss-integration-plan/#architecture","title":"Architecture","text":"<pre><code>graph TD\n    subgraph CI[\"GitHub CI Pipeline\"]\n        PDFs[PDF Sources] --&gt;|Process| Chunks[Text Chunks]\n        Chunks --&gt;|Generate| Embeddings[Vector Embeddings]\n        Embeddings --&gt;|Build| FAISSIndex[FAISS Index]\n        FAISSIndex --&gt;|Release| GitHubRelease[GitHub Release Asset]\n    end\n\n    subgraph Runtime[\"Runtime System\"]\n        GitHubRelease --&gt;|Download during install| AppIndex[Application Index]\n        AppIndex --&gt;|Query| SemanticSearch[Semantic Search Service]\n        DGNDecoder[RV-C DGN Decoder] --&gt;|Validate| SemanticSearch\n        EntityMapper[Entity Mapper] --&gt;|Enhance| SemanticSearch\n        SemanticSearch --&gt;|Update Suggestions| RVCConfig[RV-C Configuration]\n    end\n\n    subgraph Services[\"API Services\"]\n        RVCConfig --&gt;|Provide Enhanced Data| APIEndpoints[API Endpoints]\n        APIEndpoints --&gt;|Serve| Frontend[Frontend UI]\n    end</code></pre>"},{"location":"specs/faiss-integration-plan/#implementation-plan","title":"Implementation Plan","text":""},{"location":"specs/faiss-integration-plan/#1-cicd-process-for-index-generation","title":"1. CI/CD Process for Index Generation","text":"<ol> <li>PDF Document Collection</li> <li>Store official RV-C specification PDFs in version control</li> <li>Add additional manufacturer PDFs for comprehensive coverage</li> <li> <p>Implement versioning strategy for specification updates</p> </li> <li> <p>Document Processing Pipeline</p> </li> <li>Configure GitHub Actions to process PDFs when specifications change</li> <li>Use enhanced_document_processor.py to extract and chunk text content</li> <li>Support multiple chunking strategies for different document types</li> <li> <p>Generate a comprehensive JSON representation of the chunks</p> </li> <li> <p>Embedding Generation</p> </li> <li>Use quality embeddings (e.g., OpenAI embedding API or local model)</li> <li>Normalize embeddings for consistent similarity calculations</li> <li> <p>Consider dimensionality reduction for storage efficiency</p> </li> <li> <p>FAISS Index Creation</p> </li> <li>Select appropriate FAISS index type (likely IndexIVF or IndexHNSW)</li> <li>Configure index parameters for optimal performance/accuracy balance</li> <li>Compress index using quantization for efficient storage</li> <li> <p>Package index metadata for interpretation during runtime</p> </li> <li> <p>GitHub Release Integration</p> </li> <li>Automate GitHub release asset generation containing:<ul> <li>FAISS index file</li> <li>Metadata for interpreting search results</li> <li>Version information and source document details</li> </ul> </li> <li>Create semantic versioning strategy for index updates</li> </ol>"},{"location":"specs/faiss-integration-plan/#2-runtime-integration","title":"2. Runtime Integration","text":"<ol> <li>Index Loading and Management</li> <li>Update Nix flake to download and install the latest index release</li> <li>Implement lazy loading of index to minimize startup impact</li> <li> <p>Add configuration options for index location and version control</p> </li> <li> <p>Index Query Service</p> </li> <li>Create a dedicated service for handling FAISS queries</li> <li>Implement query batching for efficient processing</li> <li>Provide caching mechanism for frequent queries</li> <li> <p>Support filtering by document source and section</p> </li> <li> <p>DGN Validation Integration</p> </li> <li>Extend RV-C decoder to validate DGN interpretations against the index</li> <li>Implement confidence scoring for validations</li> <li>Create mechanism to flag potential decoding errors</li> <li> <p>Log validation results for future analysis</p> </li> <li> <p>Mapping Enhancement</p> </li> <li>Develop periodic scan process to identify missing mappings</li> <li>Create pattern-based parser for interpreting search results</li> <li>Implement suggestion mechanism for new mappings</li> <li> <p>Provide API to access and review suggestions</p> </li> <li> <p>Device Discovery</p> </li> <li>Create detection process for undocumented devices</li> <li>Build parser for device capability extraction</li> <li>Implement confidence scoring for device suggestions</li> <li>Provide feedback mechanism to improve detection accuracy</li> </ol>"},{"location":"specs/faiss-integration-plan/#3-result-parser-implementation","title":"3. Result Parser Implementation","text":"<ol> <li>Semantic Parsing Strategy</li> <li>Implement pattern recognition for different document sections</li> <li> <p>Create specialized parsers for:</p> <ul> <li>DGN specifications (data format, scaling, units)</li> <li>Device capabilities and characteristics</li> <li>Protocol requirements and constraints</li> </ul> </li> <li> <p>Structured Information Extraction</p> </li> <li> <p>Extract key information from embedding search results:</p> <ul> <li>Data field specifications (bit positions, scaling factors)</li> <li>Valid value ranges and enumerations</li> <li>Engineering units and conversion factors</li> <li>Relationships between DGNs and devices</li> </ul> </li> <li> <p>Confidence Scoring</p> </li> <li>Implement scoring algorithm for result reliability</li> <li>Consider context, search score, and result consistency</li> <li> <p>Apply different thresholds for different use cases</p> </li> <li> <p>Integration with Existing Models</p> </li> <li>Connect parser results with Pydantic models</li> <li>Ensure type safety through validation</li> <li>Create adapters for different result formats</li> </ol>"},{"location":"specs/faiss-integration-plan/#4-frontend-integration","title":"4. Frontend Integration","text":"<ol> <li>Configuration Interface</li> <li>Add UI for viewing and managing semantic search results</li> <li>Implement suggestion review and acceptance workflow</li> <li> <p>Provide visualization of missing mappings and potential enhancements</p> </li> <li> <p>Developer Tools</p> </li> <li>Create debugging tools for viewing raw search results</li> <li>Implement testing interface for manual queries</li> <li> <p>Add visualization for understanding embedding relationships</p> </li> <li> <p>Documentation Enhancement</p> </li> <li>Automatically generate enhanced documentation using index data</li> <li>Link API documentation to relevant specification sections</li> <li>Provide searchable specification references</li> </ol>"},{"location":"specs/faiss-integration-plan/#milestones-and-timeline","title":"Milestones and Timeline","text":"<ol> <li>Foundation (Sprint 1)</li> <li>Set up GitHub Actions workflow for processing PDFs</li> <li>Implement basic index generation and release process</li> <li> <p>Create initial index loading mechanism in the application</p> </li> <li> <p>Core Integration (Sprint 2)</p> </li> <li>Implement FAISS query service with basic parsing</li> <li>Create DGN validation integration</li> <li> <p>Develop initial mapping enhancement features</p> </li> <li> <p>Advanced Features (Sprint 3)</p> </li> <li>Implement device discovery capabilities</li> <li>Enhance parser with confidence scoring</li> <li> <p>Add frontend tools for managing results</p> </li> <li> <p>Refinement (Sprint 4)</p> </li> <li>Optimize performance and resource usage</li> <li>Enhance result quality through parser improvements</li> <li>Complete frontend integration</li> </ol>"},{"location":"specs/faiss-integration-plan/#technical-considerations","title":"Technical Considerations","text":""},{"location":"specs/faiss-integration-plan/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Index Compression: Use dimensionality reduction and quantization</li> <li>Query Batching: Batch related queries for efficiency</li> <li>Caching: Implement result caching for frequent lookups</li> <li>Memory Management: Use memory mapping for large indices</li> </ul>"},{"location":"specs/faiss-integration-plan/#reliability","title":"Reliability","text":"<ul> <li>Versioned Indices: Track index versions with source documents</li> <li>Confidence Scoring: Implement robust scoring for result reliability</li> <li>Fallback Mechanisms: Provide graceful degradation if index is unavailable</li> <li>Validation: Compare parser results against known-good examples</li> </ul>"},{"location":"specs/faiss-integration-plan/#extensibility","title":"Extensibility","text":"<ul> <li>Plugin Architecture: Allow custom parsers for different document types</li> <li>Configuration Options: Make behavior configurable for different use cases</li> <li>API Design: Create clean interfaces for future enhancements</li> <li>Documentation: Provide detailed documentation for customization</li> </ul>"},{"location":"specs/faiss-integration-plan/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Interactive Learning: Implement feedback loop to improve parser accuracy</li> <li>Multi-Index Support: Support multiple specialized indices for different purposes</li> <li>Natural Language Queries: Allow querying the index using natural language</li> <li>Cross-Reference Analysis: Identify relationships between different RV-C components</li> <li>Anomaly Detection: Use embeddings to identify unusual device behavior</li> </ul>"},{"location":"specs/faiss-integration-plan/#agentic-interface-and-chatbot-integration","title":"Agentic Interface and Chatbot Integration","text":"<p>Building on the FAISS vector database foundation, a future iteration could implement an agentic interface with conversational capabilities. This would transform the system from a passive validation tool to an interactive assistant that can help users understand and interact with RV-C systems.</p>"},{"location":"specs/faiss-integration-plan/#architecture-for-agentic-integration","title":"Architecture for Agentic Integration","text":"<pre><code>graph TD\n    subgraph VectorLayer[\"Vector Knowledge Layer\"]\n        FAISSIndex[FAISS Index] --&gt; RAG[Retrieval Augmented Generation]\n    end\n\n    subgraph AgentLayer[\"Agentic Layer\"]\n        LLM[Language Model] --&gt; AgentOrchestrator[Agent Orchestrator]\n        RAG --&gt; LLM\n        AgentOrchestrator --&gt; ToolUse[Tool Selection &amp; Execution]\n    end\n\n    subgraph IntegrationLayer[\"Integration Layer\"]\n        ToolUse --&gt; APIConnector[API Connector]\n        ToolUse --&gt; WSConnector[WebSocket Connector]\n        APIConnector --&gt; RVCSystem[RV-C System]\n        WSConnector --&gt; RVCSystem\n    end\n\n    subgraph InterfaceLayer[\"User Interface\"]\n        ChatUI[Chatbot UI] --&gt; AgentOrchestrator\n        AgentOrchestrator --&gt; ChatUI\n        WebUI[Web Dashboard] --&gt; ChatUI\n        MobileUI[Mobile Interface] --&gt; ChatUI\n    end</code></pre>"},{"location":"specs/faiss-integration-plan/#core-components-for-agentic-interface","title":"Core Components for Agentic Interface","text":"<ol> <li>Retrieval Augmented Generation (RAG) System</li> <li>Build on the FAISS vector store to retrieve relevant context</li> <li>Implement prompt engineering for specific RV-C knowledge extraction</li> <li> <p>Create templated responses for common operations and queries</p> </li> <li> <p>Language Model Integration</p> </li> <li>Connect with LLM service (e.g., OpenAI API, local Llama model)</li> <li>Design specialized prompts for RV-C domain understanding</li> <li> <p>Implement context window management for complex conversations</p> </li> <li> <p>Agent Orchestrator</p> </li> <li>Develop intent recognition for user queries</li> <li>Create task planning and decomposition capabilities</li> <li>Implement conversation history tracking and context management</li> <li> <p>Build error recovery and clarification mechanisms</p> </li> <li> <p>Tool Selection and Execution Framework</p> </li> <li>Create tool definitions for common RV-C operations</li> <li>Implement parameter extraction from natural language</li> <li>Build validation layer for safety and security</li> <li> <p>Design feedback mechanisms for tool execution outcomes</p> </li> <li> <p>UI/UX Components</p> </li> <li>Design conversational interface (web-based or embedded)</li> <li>Create visualization components for system state</li> <li>Implement multi-modal interaction (text, voice, graphical)</li> <li>Build accessibility features for diverse users</li> </ol>"},{"location":"specs/faiss-integration-plan/#use-cases-for-agentic-interface","title":"Use Cases for Agentic Interface","text":"<ol> <li>Conversational System Diagnostics</li> <li>\"What's the status of my water heater?\"</li> <li>\"Why isn't my bedroom light turning on?\"</li> <li> <p>\"Show me power usage for the last 24 hours\"</p> </li> <li> <p>Natural Language Control</p> </li> <li>\"Turn on the living room lights at 50% brightness\"</li> <li>\"Set the thermostat to 72 degrees when we're home\"</li> <li> <p>\"Start generator maintenance mode\"</p> </li> <li> <p>Interactive Documentation</p> </li> <li>\"Explain how the tank level sensors work\"</li> <li>\"What DGNs are related to the climate control system?\"</li> <li> <p>\"Show me the protocol for battery charging\"</p> </li> <li> <p>System Configuration</p> </li> <li>\"Set up a new light fixture in the bedroom\"</li> <li>\"Configure the entertainment system to turn on with a single command\"</li> <li>\"Create a power-saving mode for overnight\"</li> </ol>"},{"location":"specs/faiss-integration-plan/#implementation-considerations","title":"Implementation Considerations","text":"<ol> <li>Security and Safety</li> <li>Implement multi-level authorization for system control</li> <li>Create validation guardrails for potentially harmful actions</li> <li>Design confirmation workflows for critical operations</li> <li> <p>Build audit logging for all agent actions</p> </li> <li> <p>Performance Optimization</p> </li> <li>Use stream processing for real-time responses</li> <li>Implement local embedding and inference where possible</li> <li> <p>Create lightweight response modes for bandwidth-constrained environments</p> </li> <li> <p>Integration Requirements</p> </li> <li>Design API abstraction layer for system operations</li> <li>Implement WebSocket handlers for real-time updates</li> <li> <p>Build adapters for different RV-C implementations</p> </li> <li> <p>User Experience</p> </li> <li>Create conversational patterns specific to RV systems</li> <li>Design feedback mechanisms for successful operations</li> <li>Implement progressive disclosure of system capabilities</li> <li>Build user onboarding and help systems</li> </ol>"},{"location":"specs/faiss-integration-plan/#future-research-areas","title":"Future Research Areas","text":"<ul> <li>Multimodal Understanding: Processing images and diagrams of RV systems alongside text queries</li> <li>Predictive Maintenance: Using historical data to predict and prevent system failures</li> <li>Personalization: Learning user preferences and adapting responses accordingly</li> <li>Offline Operation: Enabling core functionality without internet connectivity</li> <li>Multi-agent Collaboration: Specialized agents for different subsystems working together</li> </ul>"},{"location":"specs/faiss-integration-plan/#dependencies-and-requirements","title":"Dependencies and Requirements","text":"<ul> <li>OpenAI API Access: For generating high-quality embeddings (or alternative)</li> <li>GitHub Actions Capacity: Sufficient resources for PDF processing</li> <li>Storage Requirements: Space for index storage (~50-100MB estimated)</li> <li>Memory Requirements: RAM for index loading and query processing</li> </ul>"},{"location":"specs/faiss-integration-plan/#risks-and-mitigations","title":"Risks and Mitigations","text":"Risk Impact Mitigation Embedding quality insufficient for accurate matches High Test with multiple embedding models; implement confidence thresholds PDF processing fails to extract critical information Medium Validate extraction results; manual review process Index size becomes too large for distribution Medium Implement compression; consider serving smaller specialized indices Parser misinterprets specification details High Create comprehensive validation tests; implement confidence scoring Runtime performance impact Medium Profile and optimize; implement caching; consider background processing"},{"location":"specs/faiss-integration-plan/#github-issue-tracking","title":"GitHub Issue Tracking","text":"<p>To implement this plan, we will track progress through a set of GitHub issues organized as follows:</p>"},{"location":"specs/faiss-integration-plan/#epic-faiss-integration-for-rv-c-documentation","title":"Epic: FAISS Integration for RV-C Documentation","text":"<ol> <li>Infrastructure Setup</li> <li>Issue: Set up PDF document repository structure</li> <li>Issue: Create GitHub Action for PDF processing and embedding generation</li> <li>Issue: Implement FAISS index creation and release process</li> <li> <p>Issue: Update Nix flake for index distribution</p> </li> <li> <p>Core System Development</p> </li> <li>Issue: Create semantic search service architecture</li> <li>Issue: Implement index loading and query functionality</li> <li>Issue: Develop result parser framework</li> <li> <p>Issue: Create parsers for DGN specifications</p> </li> <li> <p>Integration Components</p> </li> <li>Issue: Connect DGN decoder with semantic search for validation</li> <li>Issue: Implement mapping enhancement detection</li> <li>Issue: Create device discovery process</li> <li> <p>Issue: Add API endpoints for semantic search features</p> </li> <li> <p>Frontend and Developer Tools</p> </li> <li>Issue: Design UI for search result management</li> <li>Issue: Create developer debugging tools</li> <li>Issue: Implement result visualization</li> <li> <p>Issue: Add documentation integration</p> </li> <li> <p>Testing and Validation</p> </li> <li>Issue: Create comprehensive test suite for parsers</li> <li>Issue: Develop validation framework for embedding quality</li> <li>Issue: Implement performance benchmarks</li> <li> <p>Issue: Design integration tests for the complete system</p> </li> <li> <p>Documentation</p> </li> <li>Issue: Document CI/CD process for index generation</li> <li>Issue: Create integration guide for developers</li> <li>Issue: Write admin documentation for configuration options</li> <li> <p>Issue: Prepare user guide for frontend features</p> </li> <li> <p>Future: Agentic Interface Research</p> </li> <li>Issue: Research language models suitable for RV-C domain</li> <li>Issue: Design agent architecture prototype</li> <li>Issue: Evaluate RAG performance with RV-C documentation</li> <li>Issue: Create proof-of-concept for conversational interface</li> </ol>"},{"location":"specs/faiss-integration-plan/#conclusion","title":"Conclusion","text":"<p>This FAISS integration plan provides a structured approach to incorporating vector search capabilities into the rvc2api project. By leveraging semantic search, we can significantly enhance the accuracy and completeness of our RV-C decoder, ensuring better interoperability with diverse RV-C implementations. The future possibilities for agentic interfaces could transform how users interact with RV systems, making complex protocol details accessible through natural language conversation.</p>"},{"location":"specs/refactor-backend-structure/","title":"Refactor Backend Structure to Modular Architecture","text":""},{"location":"specs/refactor-backend-structure/#1-refactoring-objective","title":"1. Refactoring Objective","text":""},{"location":"specs/refactor-backend-structure/#11-purpose","title":"1.1. Purpose","text":"<ul> <li>Reorganize the backend structure to improve modularity, maintainability, and extensibility</li> <li>Prepare the codebase for new features like coach maintenance tracking</li> <li>Create clear separation of concerns between different functional areas</li> <li>Establish a consistent pattern for future backend development</li> <li>Transition from the current mixed structure to a more standardized FastAPI monorepo organization</li> </ul>"},{"location":"specs/refactor-backend-structure/#12-scope","title":"1.2. Scope","text":"<ul> <li>Affected: <code>src/core_daemon/</code>, <code>src/rvc_decoder/</code>, <code>src/common/</code></li> <li>Unchanged: Business logic and API functionality will remain the same, only the structure changes</li> <li>Boundaries: Focus is on backend reorganization; no changes to frontend integration or overall system behavior</li> </ul>"},{"location":"specs/refactor-backend-structure/#2-current-state-analysis","title":"2. Current State Analysis","text":""},{"location":"specs/refactor-backend-structure/#21-code-structure","title":"2.1. Code Structure","text":"<ul> <li>Backend code is currently split across multiple directories:</li> <li><code>src/common/</code>: Shared models and utilities</li> <li><code>src/core_daemon/</code>: FastAPI application, API routers, state management</li> <li><code>src/rvc_decoder/</code>: DGN decoding, mappings</li> <li>The <code>core_daemon</code> module contains a mix of concerns (API, WebSockets, state management)</li> <li>Future plans already include coach maintenance and other features that would benefit from clearer separation</li> </ul>"},{"location":"specs/refactor-backend-structure/#22-code-quality-concerns","title":"2.2. Code Quality Concerns","text":"<ul> <li>Limited separation between API definition, business logic, and data access</li> <li>Tight coupling between components makes it difficult to add new features without modifying existing code</li> <li>Core daemon has grown to include various responsibilities that could be better separated</li> <li>Limited modularity makes testing more difficult</li> </ul>"},{"location":"specs/refactor-backend-structure/#23-test-coverage","title":"2.3. Test Coverage","text":"<ul> <li>Existing tests need to be updated to reflect the new structure</li> <li>Current testing approach focused on high-level API tests rather than modular unit tests</li> <li>Refactoring provides an opportunity to improve test organization and coverage</li> </ul>"},{"location":"specs/refactor-backend-structure/#3-refactoring-plan","title":"3. Refactoring Plan","text":""},{"location":"specs/refactor-backend-structure/#31-architectural-changes","title":"3.1. Architectural Changes","text":"<ul> <li>Create a new <code>backend/</code> directory at the project root to house all backend code</li> <li>Organize code by functional areas rather than technical layers</li> <li>Separate core application configuration from business logic</li> <li>Create a clear distinction between API definition and service implementation</li> <li>Establish dedicated directories for integrations (RV-C, future integrations like Victron)</li> <li>Prepare for new features like coach maintenance tracking</li> </ul>"},{"location":"specs/refactor-backend-structure/#32-code-structure-changes","title":"3.2. Code Structure Changes","text":"<ul> <li> <p>New structure:   <pre><code>backend/\n\u251c\u2500\u2500 api/                 # API definition and routes\n\u2502   \u251c\u2500\u2500 routers/         # APIRouter modules organized by domain\n\u2502   \u2514\u2500\u2500 endpoints/       # Endpoint implementations\n\u251c\u2500\u2500 core/                # Core application logic\n\u2502   \u251c\u2500\u2500 config.py        # Configuration handling\n\u2502   \u251c\u2500\u2500 app.py           # FastAPI app factory\n\u2502   \u2514\u2500\u2500 state.py         # Application state management\n\u251c\u2500\u2500 integrations/        # External system integrations\n\u2502   \u251c\u2500\u2500 can/             # CAN bus integration\n\u2502   \u2514\u2500\u2500 rvc/             # RV-C decoder (moved from src/rvc_decoder)\n\u251c\u2500\u2500 services/            # Business logic services\n\u2502   \u251c\u2500\u2500 entity_service.py # Entity-related business logic\n\u2502   \u251c\u2500\u2500 can_service.py   # CAN-related business logic\n\u2502   \u2514\u2500\u2500 maintenance/     # New maintenance tracking features\n\u251c\u2500\u2500 models/              # Pydantic models\n\u2502   \u251c\u2500\u2500 common.py        # Shared models (from src/common/models.py)\n\u2502   \u251c\u2500\u2500 entities.py      # Entity-related models\n\u2502   \u2514\u2500\u2500 maintenance.py   # New maintenance-related models\n\u251c\u2500\u2500 middleware/          # HTTP and WebSocket middleware\n\u251c\u2500\u2500 websocket/           # WebSocket handlers\n\u2514\u2500\u2500 main.py              # Entry point\n</code></pre></p> </li> <li> <p>Files to be moved or refactored (with analysis):</p> </li> </ul> <p>### Core Components   - <code>src/core_daemon/app_state.py</code> \u2192 <code>backend/core/state.py</code>     - Purpose: Manages in-memory application state, entity data, history, and client connections     - Analysis: Core application component that other modules depend on     - Dependencies: Imports from config, metrics, models     - Refactoring Notes: Will require careful handling of circular dependencies with websocket.py</p> <ul> <li> <p><code>src/core_daemon/config.py</code> \u2192 <code>backend/core/config.py</code></p> <ul> <li>Purpose: Handles application configuration, logging, path resolution, and environment settings</li> <li>Analysis: Configuration is a core concern, correctly placed in core module</li> <li>Dependencies: Minimal external dependencies</li> <li>Refactoring Notes: Should be one of the first files to migrate to avoid dependency issues</li> </ul> </li> <li> <p><code>src/core_daemon/main.py</code> \u2192 <code>backend/main.py</code></p> <ul> <li>Purpose: Application entry point, initialization, and orchestration</li> <li>Analysis: High-level bootstrap code that ties components together</li> <li>Dependencies: Imports from many modules</li> <li>Refactoring Notes: Should be simplified to delegate more responsibility to service modules</li> </ul> </li> <li> <p><code>src/core_daemon/metrics.py</code> \u2192 <code>backend/core/metrics.py</code> (Missing in original plan)</p> <ul> <li>Purpose: Defines Prometheus metrics for monitoring</li> <li>Analysis: Core infrastructure concern used across multiple components</li> <li>Dependencies: Minimal external dependencies</li> <li>Refactoring Notes: Important to migrate early as it's used by many components</li> </ul> </li> </ul> <p>### API and Routers   - <code>src/core_daemon/api_routers/*.py</code> \u2192 <code>backend/api/routers/*.py</code>     - Purpose: Define API endpoints organized by domain     - Analysis: Properly placed in api/routers, but contain business logic that should be extracted     - Dependencies: Import app_state and models extensively     - Refactoring Notes: Business logic should be extracted to service modules</p> <p>### Integration Components   - <code>src/core_daemon/can_manager.py</code> \u2192 <code>backend/integrations/can/manager.py</code>     - Purpose: Manages CAN bus communication, listeners, and message construction     - Analysis: Hardware integration component, correctly placed in integrations     - Dependencies: Minimal external dependencies     - Refactoring Notes: Clean interfaces between this and business logic should be established</p> <ul> <li> <p><code>src/core_daemon/can_processing.py</code> \u2192 <code>backend/integrations/can/processing.py</code></p> <ul> <li>Purpose: Processes incoming CAN messages, updates application state</li> <li>Analysis: Handles integration between CAN bus and application state</li> <li>Dependencies: Imports app_state, websocket, metrics, models</li> <li>Refactoring Notes: Consider splitting business logic into a separate service</li> </ul> </li> <li> <p><code>src/rvc_decoder/*</code> \u2192 <code>backend/integrations/rvc/*</code></p> <ul> <li>Purpose: Decodes RV-C protocol messages from CAN frames</li> <li>Analysis: Protocol-specific integration, correctly placed in integrations</li> <li>Dependencies: Imports common.models</li> <li>Refactoring Notes: Clean separation from business logic should be maintained</li> </ul> </li> </ul> <p>### WebSocket Handling   - <code>src/core_daemon/websocket.py</code> \u2192 <code>backend/websocket/handlers.py</code>     - Purpose: Manages WebSocket connections, clients, and message broadcasting     - Analysis: Communication layer separate from HTTP API, warrants its own module     - Dependencies: Circular dependency with app_state     - Refactoring Notes: Circular dependency with app_state needs careful handling</p> <p>### Models   - <code>src/common/models.py</code> \u2192 <code>backend/models/common.py</code>     - Purpose: Shared Pydantic models used across modules     - Analysis: Base models that should be accessible to all components     - Dependencies: Minimal (just Pydantic)     - Refactoring Notes: Should be migrated early as other components depend on it</p> <ul> <li><code>src/core_daemon/models.py</code> \u2192 Split into domain-specific models:<ul> <li>Purpose: Contains multiple domain-specific Pydantic models</li> <li>Analysis: Should be split by domain to improve separation of concerns</li> <li>Split Strategy:</li> <li><code>backend/models/entities.py</code>: Entity-related models</li> <li><code>backend/models/can.py</code>: CAN-related models</li> <li><code>backend/models/github.py</code>: GitHub update models</li> <li>Refactoring Notes: Update imports in dependent files after splitting</li> </ul> </li> </ul> <p>### Additional Components (Missing in original plan)   - <code>src/core_daemon/feature_manager.py</code> \u2192 <code>backend/services/feature_manager.py</code>     - Purpose: Manages feature flags and optional components     - Analysis: Business logic that manages application features     - Dependencies: Various application components     - Refactoring Notes: Consider refactoring into a proper service pattern</p> <ul> <li><code>src/core_daemon/middleware.py</code> \u2192 <code>backend/middleware/http.py</code><ul> <li>Purpose: HTTP middleware like CORS and metrics collection</li> <li>Analysis: Web framework infrastructure component</li> <li>Dependencies: Imports metrics</li> <li>Refactoring Notes: Consider expanding to include additional middleware</li> </ul> </li> </ul>"},{"location":"specs/refactor-backend-structure/#33-feature-management-system-modern-approach","title":"3.3. Feature Management System (Modern Approach)","text":""},{"location":"specs/refactor-backend-structure/#overview","title":"Overview","text":"<p>The backend now uses a modern, config-driven, dependency-aware feature management system. This system is designed for extensibility, testability, and clear separation of feature logic. It consists of:</p> <ul> <li>FeatureManager: Central service for feature registration, dependency resolution, lifecycle management, and status reporting. Features are loaded from a YAML config and registered at startup.</li> <li>Feature Base Class: All features inherit from <code>Feature</code> (see <code>backend/services/feature_base.py</code>), which provides lifecycle hooks (<code>startup</code>, <code>shutdown</code>), health reporting, and dependency declaration.</li> <li>YAML Configuration: Features and their dependencies are defined in <code>backend/services/feature_flags.yaml</code>. This file controls which features are enabled, their core/optional status, and their dependencies.</li> </ul>"},{"location":"specs/refactor-backend-structure/#key-patterns","title":"Key Patterns","text":"<ul> <li>Config-Driven: Features are enabled/disabled and configured via YAML, not hardcoded.</li> <li>Dependency-Aware: Features can declare dependencies on other features. The manager resolves and starts them in the correct order.</li> <li>Extensible: New features are added by subclassing <code>Feature</code> and registering with the manager.</li> <li>Service-Oriented: All feature logic and registration must use the new pattern; legacy ad-hoc feature flags are deprecated.</li> </ul>"},{"location":"specs/refactor-backend-structure/#example-yaml","title":"Example YAML","text":"<pre><code>canbus:\n  enabled: true\n  core: true\n  depends_on: []\nweb_ui:\n  enabled: true\n  core: true\n  depends_on: []\nmaintenance_tracking:\n  enabled: false\n  core: false\n  depends_on: [canbus]\n</code></pre>"},{"location":"specs/refactor-backend-structure/#example-feature-class","title":"Example Feature Class","text":"<pre><code>from backend.services.feature_base import Feature\n\nclass MaintenanceTrackingFeature(Feature):\n    async def startup(self):\n        # Custom startup logic\n        pass\n    async def shutdown(self):\n        # Custom shutdown logic\n        pass\n    @property\n    def health(self) -&gt; str:\n        return \"healthy\" if self.enabled else \"disabled\"\n</code></pre>"},{"location":"specs/refactor-backend-structure/#example-featuremanager-usage","title":"Example FeatureManager Usage","text":"<pre><code>from backend.services.feature_manager import FeatureManager\nfrom backend.services.feature_base import Feature\n\nmanager = FeatureManager()\nmanager.register_feature(MaintenanceTrackingFeature(name=\"maintenance_tracking\", enabled=True, core=False))\nmanager.is_enabled(\"maintenance_tracking\")  # True/False\n</code></pre>"},{"location":"specs/refactor-backend-structure/#migration-notes","title":"Migration Notes","text":"<ul> <li>All feature logic and registration must use the new FeatureManager/Feature/YAML pattern.</li> <li>Remove legacy feature flag code and update all imports to use <code>backend/services/feature_manager.py</code> and <code>feature_base.py</code>.</li> <li>Update documentation and OpenAPI specs to reflect feature-conditional endpoints.</li> </ul>"},{"location":"specs/refactor-backend-structure/#34-interface-changes","title":"3.4. Interface Changes","text":"<ul> <li>No changes to public APIs; internal imports will be updated</li> <li>Maintain backward compatibility during transition</li> <li>Code refactoring will preserve API contracts and behavior</li> </ul>"},{"location":"specs/refactor-backend-structure/#35-testing-strategy","title":"3.5. Testing Strategy","text":"<ul> <li>Update existing tests to use the new import paths</li> <li>Add unit tests for newly refactored modules</li> <li>Improve test isolation with the new modular structure</li> <li>Use the refactoring as an opportunity to increase test coverage</li> </ul>"},{"location":"specs/refactor-backend-structure/#4-implementation-strategy","title":"4. Implementation Strategy","text":""},{"location":"specs/refactor-backend-structure/#41-phased-approach","title":"4.1. Phased Approach","text":"<p>The migration will follow a dependency-driven phased approach, starting with the least dependent components and gradually working up to the most integrated ones:</p> <ul> <li>Phase 1: Foundation Setup</li> <li>Set up the new directory structure</li> <li>Create minimal entry points and infrastructure</li> <li>Migrate low-dependency modules first:<ol> <li><code>src/common/models.py</code> \u2192 <code>backend/models/common.py</code></li> <li><code>src/core_daemon/config.py</code> \u2192 <code>backend/core/config.py</code></li> <li><code>src/core_daemon/metrics.py</code> \u2192 <code>backend/core/metrics.py</code></li> <li><code>src/rvc_decoder/*</code> \u2192 <code>backend/integrations/rvc/*</code></li> </ol> </li> <li> <p>Status: Complete. The foundational backend directory structure and initial package files are already in place.</p> </li> <li> <p>Phase 2: Core Services Migration</p> </li> <li>Create initial service layer modules</li> <li>Move key components with carefully managed dependencies:<ol> <li>Split <code>src/core_daemon/models.py</code> into domain-specific model files</li> <li><code>src/core_daemon/middleware.py</code> \u2192 <code>backend/middleware/http.py</code></li> <li><code>src/core_daemon/can_manager.py</code> \u2192 <code>backend/integrations/can/manager.py</code></li> <li>Create skeleton for <code>entity_service.py</code> and <code>can_service.py</code></li> <li>Create enhanced feature management:</li> <li>Create <code>backend/services/feature_base.py</code> with improved Feature base class</li> <li>Create <code>backend/services/feature_manager.py</code> with FeatureManager service class</li> <li>Add <code>backend/services/feature_flags.yaml</code> for config-driven feature definitions</li> <li>Require all feature logic and registration to use the new FeatureManager/Feature/YAML pattern</li> <li>Remove legacy feature flag code and update all imports to use new backend module paths</li> <li>Update documentation and OpenAPI specs to reflect feature-conditional endpoints</li> <li>Add feature dependency resolution logic</li> </ol> </li> <li> <p>Status: Complete. All core service skeletons, feature management, and migration to the new backend structure are done. Proceed to Phase 3 for state, API, and integration migration.</p> </li> <li> <p>Phase 3: State and API Migration</p> </li> <li> <p>Handle the more complex interdependent components:</p> <ol> <li>Refactor <code>src/core_daemon/app_state.py</code> \u2192 <code>backend/core/state.py</code></li> <li>Migrate <code>src/core_daemon/websocket.py</code> \u2192 <code>backend/websocket/handlers.py</code></li> <li>Move API routers to <code>backend/api/routers/</code> with service layer refactoring</li> <li>Refactor <code>src/core_daemon/can_processing.py</code> \u2192 <code>backend/integrations/can/processing.py</code></li> <li>Move <code>src/core_daemon/feature_manager.py</code> \u2192 <code>backend/services/feature_manager.py</code></li> </ol> </li> <li> <p>Phase 4: Entry Point and Final Integration</p> </li> <li> <p>Tie everything together with the main application:</p> <ol> <li>Create a simplified <code>backend/main.py</code></li> <li>Implement dependency injection where appropriate</li> <li>Create a compatibility layer for transition period</li> <li>Add comprehensive test coverage for the new structure</li> </ol> </li> <li> <p>Phase 3: Service Refactoring</p> </li> <li>Split monolithic services into domain-specific modules</li> <li>Create proper separation between API, services, and data access</li> <li> <p>Update imports and references</p> </li> <li> <p>Phase 4: New Features &amp; Cleanup</p> </li> <li>Implement coach maintenance features in the new structure</li> <li>Remove deprecated code paths</li> <li>Update documentation</li> </ul>"},{"location":"specs/refactor-backend-structure/#42-dependency-challenges-and-solutions","title":"4.2. Dependency Challenges and Solutions","text":"<p>During the analysis, several dependency challenges were identified that will require special handling:</p>"},{"location":"specs/refactor-backend-structure/#circular-dependencies","title":"Circular Dependencies","text":"<ul> <li>app_state.py \u2194 websocket.py: These files import from each other, creating a circular dependency</li> <li>Solution: Create a new module <code>backend/core/events.py</code> to handle the event dispatch that both modules need</li> <li>Strategy: Extract the shared functionality to break the circular dependency</li> </ul>"},{"location":"specs/refactor-backend-structure/#heavy-state-dependencies","title":"Heavy State Dependencies","text":"<ul> <li>Many modules directly import from app_state.py, creating tight coupling</li> <li>Solution: Implement a service layer that accesses state rather than having components access state directly</li> <li>Strategy: Create services like <code>entity_service.py</code> that mediate access to application state</li> </ul>"},{"location":"specs/refactor-backend-structure/#business-logic-in-api-routers","title":"Business Logic in API Routers","text":"<ul> <li>API router files contain business logic that should be in service modules</li> <li>Solution: Extract business logic from routers to dedicated service modules</li> <li>Strategy: Routers should only handle HTTP concerns; service modules handle business logic</li> </ul>"},{"location":"specs/refactor-backend-structure/#43-risk-mitigation","title":"4.3. Risk Mitigation","text":"<ul> <li>Maintain comprehensive test coverage throughout the refactoring</li> <li>Implement changes incrementally, testing at each step</li> <li>Create compatibility layers where needed during the transition</li> <li>Document all changes clearly for future reference</li> <li>Create explicit interfaces between modules to reduce coupling</li> <li>Use dependency injection where appropriate to improve testability</li> </ul>"},{"location":"specs/refactor-backend-structure/#44-validation-checkpoints","title":"4.4. Validation Checkpoints","text":"<p>Each phase of migration requires validation to ensure functionality is preserved:</p>"},{"location":"specs/refactor-backend-structure/#phase-1-validation","title":"Phase 1 Validation","text":"<ul> <li>Verify models can be imported and used in existing code</li> <li>Ensure configuration loading works correctly</li> <li>Confirm metrics registration is functioning</li> <li>Test RV-C decoder functionality in isolation</li> </ul>"},{"location":"specs/refactor-backend-structure/#phase-2-validation","title":"Phase 2 Validation","text":"<ul> <li>Verify domain-specific models properly replace the original models module</li> <li>Ensure middleware functions correctly with new imports</li> <li>Test CAN manager initialization and operation</li> <li>Validate initial service layer functionality</li> </ul>"},{"location":"specs/refactor-backend-structure/#phase-3-validation","title":"Phase 3 Validation","text":"<ul> <li>Confirm application state management is fully functional</li> <li>Test WebSocket connections and message broadcasting</li> <li>Verify API endpoints respond correctly with refactored dependencies</li> <li>Ensure CAN message processing updates state correctly</li> <li>Check feature manager functionality</li> </ul>"},{"location":"specs/refactor-backend-structure/#phase-4-validation","title":"Phase 4 Validation","text":"<ul> <li>Run full integration tests with the new main entry point</li> <li>Test API endpoints to verify that external behavior remains consistent</li> <li>Check WebSocket functionality to ensure real-time updates work correctly</li> <li>Verify that CAN bus integration continues to function as expected</li> <li>Ensure backwards compatibility is maintained for existing clients</li> </ul>"},{"location":"specs/refactor-backend-structure/#5-code-migration-guide","title":"5. Code Migration Guide","text":""},{"location":"specs/refactor-backend-structure/#51-old-vs-new-patterns","title":"5.1. Old vs. New Patterns","text":"<ul> <li> <p>BEFORE: Mixed responsibility modules with tight coupling:   <pre><code># Direct import from core_daemon\nfrom core_daemon.app_state import update_entity_state\n</code></pre></p> </li> <li> <p>AFTER: Clear separation of concerns with modular imports:   <pre><code># Service-oriented approach\nfrom backend.services.entity_service import update_entity\n</code></pre></p> </li> </ul>"},{"location":"specs/refactor-backend-structure/#52-deprecation-path","title":"5.2. Deprecation Path","text":"<ul> <li>Keep old modules initially with imports from new locations</li> <li>Gradually migrate callers to use new import paths</li> <li>Remove deprecated code after all callers are updated</li> </ul>"},{"location":"specs/refactor-backend-structure/#6-documentation-updates","title":"6. Documentation Updates","text":""},{"location":"specs/refactor-backend-structure/#61-code-documentation","title":"6.1. Code Documentation","text":"<ul> <li>Update all docstrings to reflect new module locations</li> <li>Update architecture documentation with new structure</li> <li>Create diagrams showing the revised component organization</li> <li>Document patterns for extending the system with new services</li> </ul>"},{"location":"specs/refactor-backend-structure/#62-user-documentation","title":"6.2. User Documentation","text":"<ul> <li>Update API documentation to reflect any path changes or enhancements</li> <li>Document the transition if relevant to users of the system</li> <li>Update developer setup instructions for the new structure</li> </ul>"},{"location":"specs/refactor-backend-structure/#7-execution-checklist","title":"7. Execution Checklist","text":""},{"location":"specs/refactor-backend-structure/#71-preparation","title":"7.1. Preparation","text":"<ul> <li>[ ] Create detailed dependency graph of existing modules</li> <li>[ ] Map all import statements across the codebase</li> <li>[ ] Establish test baseline to verify functionality preservation</li> <li>[ ] Create comprehensive test cases for critical functionality</li> <li>[ ] Draft interface definitions for new service modules</li> <li>[ ] Create new directory structure</li> </ul>"},{"location":"specs/refactor-backend-structure/#72-phase-1-foundation-setup","title":"7.2. Phase 1: Foundation Setup","text":"<ul> <li>[ ] Migrate <code>common/models.py</code> to <code>backend/models/common.py</code></li> <li>[ ] Migrate <code>core_daemon/config.py</code> to <code>backend/core/config.py</code></li> <li>[ ] Migrate <code>core_daemon/metrics.py</code> to <code>backend/core/metrics.py</code></li> <li>[ ] Migrate <code>rvc_decoder/</code> to <code>backend/integrations/rvc/</code></li> <li>[ ] Verify imports still work with compatibility layer</li> <li>[ ] Run tests to verify phase 1 components function correctly</li> </ul>"},{"location":"specs/refactor-backend-structure/#73-core-components-phase-week-2-3","title":"7.3. Core Components Phase (Week 2-3)","text":"<ul> <li>[x] Split domain-specific models:</li> <li>[x] Create <code>backend/models/entities.py</code>, <code>backend/models/can.py</code>, etc.</li> <li>[x] Update imports in dependent files</li> <li>[x] Create compatibility imports</li> <li>[x] Migrate middleware:</li> <li>[x] <code>src/core_daemon/middleware.py</code> \u2192 <code>backend/middleware/http.py</code></li> <li>[x] Migrate CAN integration:</li> <li>[x] <code>src/core_daemon/can_manager.py</code> \u2192 <code>backend/integrations/can/manager.py</code></li> <li>[x] Create <code>backend/integrations/can/interface.py</code> implementing <code>IntegrationInterface</code></li> <li>[x] Create initial service layer:</li> <li>[x] <code>backend/services/entity_service.py</code></li> <li>[x] <code>backend/services/can_service.py</code></li> <li>[x] Create enhanced feature management:</li> <li>[x] Create <code>backend/services/feature_base.py</code> with improved Feature base class</li> <li>[x] Create <code>backend/services/feature_manager.py</code> with FeatureManager service class</li> <li>[x] Add <code>backend/services/feature_flags.yaml</code> for config-driven feature definitions</li> <li>[x] Require all feature logic and registration to use the new FeatureManager/Feature/YAML pattern</li> <li>[x] Remove legacy feature flag code and update all imports to use new backend module paths</li> <li>[x] Update documentation and OpenAPI specs to reflect feature-conditional endpoints</li> <li>[x] Add feature dependency resolution logic</li> <li>[x] Create tests for all migrated components (to be expanded in later phases)</li> </ul> <p>Phase 2 complete: All core service skeletons, feature management, and migration to the new backend structure are done. Proceed to Phase 3 for state, API, and integration migration.</p>"},{"location":"specs/refactor-backend-structure/#74-phase-3-state-and-api-migration","title":"7.4. Phase 3: State and API Migration","text":"<ul> <li>[ ] Refactor <code>core_daemon/app_state.py</code> to <code>backend/core/state.py</code></li> <li>[ ] Migrate <code>core_daemon/websocket.py</code> to <code>backend/websocket/handlers.py</code></li> <li>[ ] Migrate API routers with extracted business logic:</li> <li>[ ] <code>core_daemon/api_routers/entities.py</code> \u2192 <code>backend/api/routers/entities.py</code></li> <li>[ ] <code>core_daemon/api_routers/can.py</code> \u2192 <code>backend/api/routers/can.py</code></li> <li>[ ] Other API router modules</li> <li>[ ] Move business logic to appropriate service modules</li> <li>[ ] Migrate <code>core_daemon/can_processing.py</code> to <code>backend/integrations/can/processing.py</code></li> <li>[ ] Migrate <code>core_daemon/feature_manager.py</code> to <code>backend/services/feature_manager.py</code></li> <li>[ ] Run tests to verify phase 3 components function correctly</li> </ul>"},{"location":"specs/refactor-backend-structure/#75-phase-4-entry-point-and-final-integration","title":"7.5. Phase 4: Entry Point and Final Integration","text":"<ul> <li>[ ] Create simplified <code>backend/main.py</code> with proper service initialization</li> <li>[ ] Implement dependency injection where appropriate</li> <li>[ ] Create compatibility layer for transition period</li> <li>[ ] Add new coach maintenance service structure</li> <li>[ ] Ensure all imports are updated throughout the codebase</li> <li>[ ] Run full integration tests</li> </ul>"},{"location":"specs/refactor-backend-structure/#76-verification","title":"7.6. Verification","text":"<ul> <li>[ ] Run complete test suite</li> <li>[ ] Verify API behavior with automated and manual testing</li> <li>[ ] Test WebSocket functionality thoroughly</li> <li>[ ] Check performance metrics for any regressions</li> <li>[ ] Test CAN bus integration with hardware or simulators</li> <li>[ ] Review code quality with static analysis tools</li> <li>[ ] Verify backward compatibility with existing clients</li> </ul>"},{"location":"specs/refactor-backend-structure/#77-documentation-cleanup","title":"7.7. Documentation &amp; Cleanup","text":"<ul> <li>[ ] Update architecture documentation with new structure</li> <li>[ ] Create sequence diagrams for key workflows</li> <li>[ ] Update API documentation to reflect any changes</li> <li>[ ] Remove deprecated code paths</li> <li>[ ] Update VS Code tasks and development workflows</li> <li>[ ] Update any CI/CD configurations</li> <li>[ ] Document lessons learned during the refactoring</li> </ul>"},{"location":"specs/refactor-backend-structure/#8-references","title":"8. References","text":"<ul> <li>FastAPI Bigger Applications Guide</li> <li>Python Application Layouts</li> <li>Current <code>docs/architecture/backend.md</code> documentation</li> <li>Existing plan in project documentation about future architecture</li> </ul>"},{"location":"specs/refactor-backend-structure/#9-integration-interface-patterns","title":"9. Integration Interface Patterns","text":"<p>One key goal of this refactoring is to prepare for additional device integration types beyond RV-C CAN bus. The new architecture should flexibly support different communication protocols with a common interface pattern.</p>"},{"location":"specs/refactor-backend-structure/#91-common-integration-interface","title":"9.1. Common Integration Interface","text":"<p>The following pattern defines a common interface that all integration types will implement:</p> <pre><code># backend/integrations/interfaces.py\nfrom abc import ABC, abstractmethod\nfrom typing import Any, AsyncIterator, Callable, Dict, List, Optional, Protocol, TypeVar\n\nclass DeviceMessage(Protocol):\n    \"\"\"Protocol for messages from any device integration.\"\"\"\n    source_id: str\n    timestamp: float\n    raw_data: Any\n\nT = TypeVar('T', bound=DeviceMessage)\n\nclass IntegrationInterface(ABC):\n    \"\"\"Common interface for all device integrations.\"\"\"\n\n    @abstractmethod\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize the integration and establish connections.\"\"\"\n        pass\n\n    @abstractmethod\n    async def shutdown(self) -&gt; None:\n        \"\"\"Clean shutdown of the integration.\"\"\"\n        pass\n\n    @abstractmethod\n    async def send_message(self, target_id: str, message_data: Any) -&gt; bool:\n        \"\"\"Send a message to a specific device.\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_message_stream(self) -&gt; AsyncIterator[T]:\n        \"\"\"Return an async iterator yielding device messages.\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_available_devices(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"Return a list of available devices with their metadata.\"\"\"\n        pass\n\n    @abstractmethod\n    def register_message_handler(self, handler: Callable[[T], None]) -&gt; None:\n        \"\"\"Register a handler for incoming messages.\"\"\"\n        pass\n</code></pre>"},{"location":"specs/refactor-backend-structure/#92-concrete-implementations","title":"9.2. Concrete Implementations","text":""},{"location":"specs/refactor-backend-structure/#rv-c-can-implementation","title":"RV-C CAN Implementation","text":"<pre><code># backend/integrations/can/interface.py\nimport asyncio\nfrom typing import Any, AsyncIterator, Callable, Dict, List, Optional\n\nfrom backend.integrations.interfaces import IntegrationInterface\nfrom backend.integrations.can.manager import CANManager\nfrom backend.integrations.can.models import CANMessage\n\nclass CANIntegration(IntegrationInterface):\n    \"\"\"RV-C CAN bus integration implementation.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        self.can_manager = CANManager(config)\n        self.handlers = []\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize CAN bus connection and start listening.\"\"\"\n        await self.can_manager.initialize()\n        asyncio.create_task(self._process_messages())\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Shutdown CAN bus connections.\"\"\"\n        await self.can_manager.shutdown()\n\n    async def send_message(self, target_id: str, message_data: Any) -&gt; bool:\n        \"\"\"Send a message to the CAN bus.\"\"\"\n        return await self.can_manager.send_message(int(target_id, 16), message_data)\n\n    async def get_message_stream(self) -&gt; AsyncIterator[CANMessage]:\n        \"\"\"Return an async iterator yielding CAN messages.\"\"\"\n        queue = asyncio.Queue()\n\n        def _handler(msg: CANMessage):\n            queue.put_nowait(msg)\n\n        self.register_message_handler(_handler)\n\n        while True:\n            yield await queue.get()\n\n    async def get_available_devices(self) -&gt; List&lt;Dict[str, Any]]:\n        \"\"\"Return a list of available CAN nodes.\"\"\"\n        return [\n            {\"id\": hex(node_id), \"type\": \"can_node\", \"last_seen\": timestamp}\n            for node_id, timestamp in self.can_manager.get_active_nodes()\n        ]\n\n    def register_message_handler(self, handler: Callable[[CANMessage], None]) -&gt; None:\n        \"\"\"Register a handler for CAN messages.\"\"\"\n        self.handlers.append(handler)\n\n    async def _process_messages(self):\n        \"\"\"Process incoming messages and notify handlers.\"\"\"\n        async for msg in self.can_manager.listen():\n            for handler in self.handlers:\n                asyncio.create_task(asyncio.to_thread(handler, msg))\n</code></pre>"},{"location":"specs/refactor-backend-structure/#ip-based-device-implementation","title":"IP-Based Device Implementation","text":"<pre><code># backend/integrations/ip/interface.py\nimport asyncio\nimport aiohttp\nfrom typing import Any, AsyncIterator, Callable, Dict, List, Optional\n\nfrom backend.integrations.interfaces import IntegrationInterface\nfrom backend.integrations.ip.models import IPDeviceMessage\n\nclass IPDeviceIntegration(IntegrationInterface):\n    \"\"\"Integration for IP-based devices (e.g., Victron Venus OS).\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        self.devices = []\n        self.config = config\n        self.handlers = []\n        self.session = None\n        self.running = False\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize connections to IP devices.\"\"\"\n        self.session = aiohttp.ClientSession()\n        self.devices = await self._discover_devices()\n        self.running = True\n        asyncio.create_task(self._poll_devices())\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Close connections to IP devices.\"\"\"\n        self.running = False\n        if self.session:\n            await self.session.close()\n\n    async def send_message(self, target_id: str, message_data: Any) -&gt; bool:\n        \"\"\"Send a command to an IP device.\"\"\"\n        device = next((d for d in self.devices if d[\"id\"] == target_id), None)\n        if not device:\n            return False\n\n        try:\n            url = f\"http://{device['address']}/api/v1/setValue\"\n            async with self.session.post(url, json=message_data) as response:\n                return response.status == 200\n        except Exception:\n            return False\n\n    async def get_message_stream(self) -&gt; AsyncIterator[IPDeviceMessage]:\n        \"\"\"Return an async iterator yielding device status updates.\"\"\"\n        queue = asyncio.Queue()\n\n        def _handler(msg: IPDeviceMessage):\n            queue.put_nowait(msg)\n\n        self.register_message_handler(_handler)\n\n        while True:\n            yield await queue.get()\n\n    async def get_available_devices(self) -&gt; List&lt;Dict[str, Any]]:\n        \"\"\"Return a list of available IP devices.\"\"\"\n        return self.devices\n\n    def register_message_handler(self, handler: Callable[[IPDeviceMessage], None]) -&gt; None:\n        \"\"\"Register a handler for device messages.\"\"\"\n        self.handlers.append(handler)\n\n    async def _discover_devices(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"Discover IP devices on the network.\"\"\"\n        # Example: scan network, use mDNS, or predefined list\n        discovered = []\n\n        if \"static_devices\" in self.config:\n            for device in self.config[\"static_devices\"]:\n                discovered.append({\n                    \"id\": device[\"id\"],\n                    \"address\": device[\"address\"],\n                    \"type\": \"ip_device\",\n                    \"model\": device.get(\"model\", \"unknown\")\n                })\n\n        # Implement network discovery here\n\n        return discovered\n\n    async def _poll_devices(self):\n        \"\"\"Poll connected devices for status updates.\"\"\"\n        while self.running:\n            for device in self.devices:\n                try:\n                    url = f\"http://{device['address']}/api/v1/status\"\n                    async with self.session.get(url) as response:\n                        if response.status == 200:\n                            data = await response.json()\n                            message = IPDeviceMessage(\n                                source_id=device[\"id\"],\n                                timestamp=data.get(\"timestamp\", 0),\n                                raw_data=data,\n                                device_type=device.get(\"model\", \"unknown\")\n                            )\n                            for handler in self.handlers:\n                                asyncio.create_task(asyncio.to_thread(handler, message))\n                except Exception as e:\n                    print(f\"Error polling device {device['id']}: {e}\")\n\n            await asyncio.sleep(self.config.get(\"poll_interval\", 5))\n</code></pre>"},{"location":"specs/refactor-backend-structure/#bluetooth-device-implementation","title":"Bluetooth Device Implementation","text":"<pre><code># backend/integrations/bluetooth/interface.py\nimport asyncio\nfrom typing import Any, AsyncIterator, Callable, Dict, List, Optional\n\nfrom backend.integrations.interfaces import IntegrationInterface\nfrom backend.integrations.bluetooth.models import BluetoothMessage\nfrom backend.integrations.bluetooth.scanner import BluetoothScanner\n\nclass BluetoothIntegration(IntegrationInterface):\n    \"\"\"Integration for Bluetooth devices.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.scanner = BluetoothScanner()\n        self.devices = []\n        self.handlers = []\n        self.running = False\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize Bluetooth scanning.\"\"\"\n        await self.scanner.initialize()\n        self.running = True\n        asyncio.create_task(self._scan_loop())\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Stop Bluetooth scanning.\"\"\"\n        self.running = False\n        await self.scanner.stop()\n\n    async def send_message(self, target_id: str, message_data: Any) -&gt; bool:\n        \"\"\"Send a message to a Bluetooth device.\"\"\"\n        device = next((d for d in self.devices if d[\"id\"] == target_id), None)\n        if not device:\n            return False\n\n        return await self.scanner.send_command(device[\"address\"], message_data)\n\n    async def get_message_stream(self) -&gt; AsyncIterator[BluetoothMessage]:\n        \"\"\"Return an async iterator yielding Bluetooth messages.\"\"\"\n        queue = asyncio.Queue()\n\n        def _handler(msg: BluetoothMessage):\n            queue.put_nowait(msg)\n\n        self.register_message_handler(_handler)\n\n        while True:\n            yield await queue.get()\n\n    async def get_available_devices(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"Return a list of available Bluetooth devices.\"\"\"\n        return self.devices\n\n    def register_message_handler(self, handler: Callable[[BluetoothMessage], None]) -&gt; None:\n        \"\"\"Register a handler for Bluetooth messages.\"\"\"\n        self.handlers.append(handler)\n\n    async def _scan_loop(self):\n        \"\"\"Continuously scan for Bluetooth devices.\"\"\"\n        while self.running:\n            devices = await self.scanner.scan()\n            self.devices = [\n                {\n                    \"id\": device.address.replace(\":\", \"\"),\n                    \"address\": device.address,\n                    \"name\": device.name or \"Unknown\",\n                    \"type\": \"bluetooth\",\n                    \"rssi\": device.rssi\n                }\n                for device in devices\n            ]\n\n            # Process advertisement data\n            for device in devices:\n                if device.advertisement_data:\n                    message = BluetoothMessage(\n                        source_id=device.address.replace(\":\", \"\"),\n                        timestamp=device.last_seen,\n                        raw_data=device.advertisement_data,\n                        device_name=device.name or \"Unknown\",\n                        rssi=device.rssi\n                    )\n\n                    for handler in self.handlers:\n                        asyncio.create_task(asyncio.to_thread(handler, message))\n\n            await asyncio.sleep(self.config.get(\"scan_interval\", 30))\n</code></pre>"},{"location":"specs/refactor-backend-structure/#93-integration-factory-and-registry","title":"9.3. Integration Factory and Registry","text":"<p>To make it easy to use different integrations:</p> <pre><code># backend/integrations/factory.py\nfrom typing import Dict, Any, Optional, Type\n\nfrom backend.integrations.interfaces import IntegrationInterface\nfrom backend.integrations.can.interface import CANIntegration\nfrom backend.integrations.ip.interface import IPDeviceIntegration\nfrom backend.integrations.bluetooth.interface import BluetoothIntegration\n\nclass IntegrationRegistry:\n    \"\"\"Registry of available integration types.\"\"\"\n\n    _integrations: Dict[str, Type[IntegrationInterface]] = {\n        \"can\": CANIntegration,\n        \"ip\": IPDeviceIntegration,\n        \"bluetooth\": BluetoothIntegration,\n    }\n\n    @classmethod\n    def register_integration(cls, name: str, integration_class: Type[IntegrationInterface]) -&gt; None:\n        \"\"\"Register a new integration type.\"\"\"\n        cls._integrations[name] = integration_class\n\n    @classmethod\n    def create_integration(cls, name: str, config: Dict[str, Any]) -&gt; Optional[IntegrationInterface]:\n        \"\"\"Create an integration instance by name.\"\"\"\n        if name not in cls._integrations:\n            return None\n\n        return cls._integrations[name](config)\n\n    @classmethod\n    def get_available_integrations(cls) -&gt; Dict[str, Type[IntegrationInterface]]:\n        \"\"\"Get all registered integration types.\"\"\"\n        return cls._integrations.copy()\n</code></pre>"},{"location":"specs/refactor-backend-structure/#10-example-implementations","title":"10. Example Implementations","text":""},{"location":"specs/refactor-backend-structure/#101-new-maintenance-service-example","title":"10.1. New Maintenance Service Example","text":"<p>As an example of how the new architecture would accommodate a coach maintenance tracking feature:</p>"},{"location":"specs/refactor-backend-structure/#models","title":"Models","text":"<pre><code># backend/models/maintenance.py\nfrom datetime import date, datetime\nfrom enum import Enum\nfrom pydantic import BaseModel, Field\nfrom typing import Dict, List, Optional, Union\n\nclass MaintenanceItemType(str, Enum):\n    \"\"\"Types of maintenance items.\"\"\"\n    SCHEDULED = \"scheduled\"\n    MILEAGE = \"mileage\"\n    ENGINE_HOURS = \"engine_hours\"\n    CALENDAR = \"calendar\"\n\nclass MaintenanceStatus(str, Enum):\n    \"\"\"Status of a maintenance item.\"\"\"\n    UPCOMING = \"upcoming\"\n    DUE = \"due\"\n    OVERDUE = \"overdue\"\n    COMPLETED = \"completed\"\n\nclass MaintenanceItem(BaseModel):\n    \"\"\"Represents a maintenance item to be tracked.\"\"\"\n    id: str\n    name: str\n    description: str = \"\"\n    type: MaintenanceItemType\n    interval_value: float\n    interval_unit: str  # days, miles, hours, months\n    last_performed: Optional[datetime] = None\n    last_value: Optional[float] = None  # miles or hours when last performed\n    next_due_date: Optional[date] = None\n    next_due_value: Optional[float] = None  # miles or hours\n    status: MaintenanceStatus = MaintenanceStatus.UPCOMING\n    notes: str = \"\"\n    tags: List[str] = Field(default_factory=list)\n    custom_fields: Dict[str, Union[str, int, float, bool]] = Field(default_factory=dict)\n\nclass MaintenanceRecord(BaseModel):\n    \"\"\"Record of a completed maintenance task.\"\"\"\n    id: str\n    item_id: str\n    completion_date: datetime\n    value_at_completion: Optional[float] = None  # miles or hours\n    technician: Optional[str] = None\n    cost: Optional[float] = None\n    notes: str = \"\"\n    attachments: List[str] = Field(default_factory=list)\n</code></pre>"},{"location":"specs/refactor-backend-structure/#service","title":"Service","text":"<pre><code># backend/services/maintenance/schedule_service.py\nfrom datetime import date, datetime, timedelta\nfrom typing import Dict, List, Optional, Tuple\n\nfrom backend.models.maintenance import (\n    MaintenanceItem,\n    MaintenanceRecord,\n    MaintenanceStatus,\n    MaintenanceItemType\n)\nfrom backend.core.state import get_state_value\nfrom backend.services.entity_service import get_entity_value\n\nclass MaintenanceScheduleService:\n    \"\"\"Service for managing maintenance schedules.\"\"\"\n\n    def __init__(self):\n        self._items: Dict[str, MaintenanceItem] = {}\n        self._records: Dict[str, List[MaintenanceRecord]] = {}\n\n    def add_item(self, item: MaintenanceItem) -&gt; MaintenanceItem:\n        \"\"\"Add a new maintenance item to track.\"\"\"\n        self._items[item.id] = item\n        self._update_item_status(item.id)\n        return item\n\n    def get_item(self, item_id: str) -&gt; Optional[MaintenanceItem]:\n        \"\"\"Get a maintenance item by ID.\"\"\"\n        return self._items.get(item_id)\n\n    def get_all_items(self) -&gt; List[MaintenanceItem]:\n        \"\"\"Get all maintenance items.\"\"\"\n        return list(self._items.values())\n\n    def get_due_items(self) -&gt; List[MaintenanceItem]:\n        \"\"\"Get all items that are due or overdue.\"\"\"\n        return [\n            item for item in self._items.values()\n            if item.status in (MaintenanceStatus.DUE, MaintenanceStatus.OVERDUE)\n        ]\n\n    def add_record(self, record: MaintenanceRecord) -&gt; Tuple[MaintenanceRecord, MaintenanceItem]:\n        \"\"\"Add a new maintenance record and update the item status.\"\"\"\n        if record.item_id not in self._items:\n            raise ValueError(f\"Maintenance item {record.item_id} not found\")\n\n        if record.item_id not in self._records:\n            self._records[record.item_id] = []\n\n        self._records[record.item_id].append(record)\n\n        # Update the maintenance item\n        item = self._items[record.item_id]\n        item.last_performed = record.completion_date\n\n        if record.value_at_completion is not None:\n            item.last_value = record.value_at_completion\n\n        # Recalculate next due date/value\n        self._update_item_status(record.item_id)\n\n        return record, self._items[record.item_id]\n\n    def get_records(self, item_id: str) -&gt; List[MaintenanceRecord]:\n        \"\"\"Get all maintenance records for an item.\"\"\"\n        return self._records.get(item_id, [])\n\n    def _update_item_status(self, item_id: str) -&gt; None:\n        \"\"\"Update the status of a maintenance item.\"\"\"\n        item = self._items[item_id]\n\n        if item.type == MaintenanceItemType.SCHEDULED:\n            if not item.last_performed:\n                # Never performed, set to upcoming\n                item.status = MaintenanceStatus.UPCOMING\n                return\n\n            # Calculate next due date based on interval\n            if item.interval_unit == \"days\":\n                item.next_due_date = (\n                    item.last_performed + timedelta(days=item.interval_value)\n                ).date()\n            elif item.interval_unit == \"months\":\n                # Simple month calculation (not exact)\n                item.next_due_date = (\n                    item.last_performed + timedelta(days=item.interval_value * 30)\n                ).date()\n\n            # Determine status based on due date\n            today = date.today()\n            if item.next_due_date &lt;= today:\n                item.status = MaintenanceStatus.OVERDUE\n            elif (item.next_due_date - today).days &lt;= 7:  # Within a week\n                item.status = MaintenanceStatus.DUE\n            else:\n                item.status = MaintenanceStatus.UPCOMING\n\n        elif item.type == MaintenanceItemType.MILEAGE:\n            if not item.last_value:\n                item.status = MaintenanceStatus.UPCOMING\n                return\n\n            # Get current mileage from entity\n            current_mileage = get_entity_value(\"vehicle\", \"odometer\", 0)\n\n            # Calculate next due mileage\n            item.next_due_value = item.last_value + item.interval_value\n\n            # Determine status based on mileage\n            if current_mileage &gt;= item.next_due_value:\n                item.status = MaintenanceStatus.OVERDUE\n            elif current_mileage &gt;= (item.next_due_value - 500):  # Within 500 miles\n                item.status = MaintenanceStatus.DUE\n            else:\n                item.status = MaintenanceStatus.UPCOMING\n\n        # Similar logic for ENGINE_HOURS and CALENDAR types\n</code></pre>"},{"location":"specs/refactor-backend-structure/#api-router","title":"API Router","text":"<pre><code># backend/api/routers/maintenance.py\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom typing import List\nfrom uuid import uuid4\n\nfrom backend.services.maintenance.schedule_service import MaintenanceScheduleService\nfrom backend.models.maintenance import MaintenanceItem, MaintenanceRecord\n\nrouter = APIRouter(prefix=\"/api/maintenance\", tags=[\"Maintenance\"])\n\ndef get_maintenance_service():\n    \"\"\"Dependency injection for the maintenance service.\"\"\"\n    return MaintenanceScheduleService()\n\n@router.get(\"/items\", response_model=List[MaintenanceItem])\nasync def get_maintenance_items(\n    service: MaintenanceScheduleService = Depends(get_maintenance_service)\n):\n    \"\"\"Get all maintenance items.\"\"\"\n    return service.get_all_items()\n\n@router.get(\"/items/due\", response_model=List[MaintenanceItem])\nasync def get_due_items(\n    service: MaintenanceScheduleService = Depends(get_maintenance_service)\n):\n    \"\"\"Get maintenance items that are due or overdue.\"\"\"\n    return service.get_due_items()\n\n@router.get(\"/items/{item_id}\", response_model=MaintenanceItem)\nasync def get_maintenance_item(\n    item_id: str,\n    service: MaintenanceScheduleService = Depends(get_maintenance_service)\n):\n    \"\"\"Get a specific maintenance item.\"\"\"\n    item = service.get_item(item_id)\n    if not item:\n        raise HTTPException(status_code=404, detail=\"Maintenance item not found\")\n    return item\n\n@router.post(\"/items\", response_model=MaintenanceItem)\nasync def create_maintenance_item(\n    item: MaintenanceItem,\n    service: MaintenanceScheduleService = Depends(get_maintenance_service)\n):\n    \"\"\"Create a new maintenance item.\"\"\"\n    if not item.id:\n        item.id = str(uuid4())\n    return service.add_item(item)\n\n@router.get(\"/records/{item_id}\", response_model=List[MaintenanceRecord])\nasync def get_maintenance_records(\n    item_id: str,\n    service: MaintenanceScheduleService = Depends(get_maintenance_service)\n):\n    \"\"\"Get maintenance records for a specific item.\"\"\"\n    if not service.get_item(item_id):\n        raise HTTPException(status_code=404, detail=\"Maintenance item not found\")\n    return service.get_records(item_id)\n\n@router.post(\"/records\", response_model=MaintenanceRecord)\nasync def create_maintenance_record(\n    record: MaintenanceRecord,\n    service: MaintenanceScheduleService = Depends(get_maintenance_service)\n):\n    \"\"\"Create a new maintenance record.\"\"\"\n    if not record.id:\n        record.id = str(uuid4())\n\n    try:\n        saved_record, _ = service.add_record(record)\n        return saved_record\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n</code></pre>"},{"location":"specs/refactor-backend-structure/#102-main-application-integration","title":"10.2. Main Application Integration","text":"<p>Here's an example of how the main application would initialize and integrate all components:</p> <pre><code># backend/main.py\nimport asyncio\nimport logging\nfrom fastapi import FastAPI, Request\nfrom fastapi.responses import JSONResponse\nfrom fastapi.middleware.cors import CORSMiddleware\n\nfrom backend.core.config import settings, get_settings\nfrom backend.core.state import AppState\nfrom backend.core.events import EventBus\nfrom backend.middleware.http import metrics_middleware\nfrom backend.services.feature_manager import FeatureManager, get_feature_manager\nfrom backend.api.routers import entities, can, websocket, maintenance\nfrom backend.integrations.factory import IntegrationRegistry\nfrom backend.services.feature_manager import FeatureManager\nfrom backend.core.metrics import setup_metrics\n\nlogger = logging.getLogger(__name__)\n\ndef create_app() -&gt; FastAPI:\n    \"\"\"Create and configure the FastAPI application.\"\"\"\n    app = FastAPI(\n        title=settings.app_name,\n        description=settings.app_description,\n        version=settings.app_version,\n    )\n\n    # Configure middleware\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=settings.cors_origins,\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n    app.middleware(\"http\")(metrics_middleware)\n\n    # Configure exception handlers\n    @app.exception_handler(Exception)\n    async def generic_exception_handler(request: Request, exc: Exception):\n        logger.exception(\"Unhandled exception\")\n        return JSONResponse(\n            status_code=500,\n            content={\"detail\": \"Internal server error\"},\n        )\n\n    # Register API routers\n    app.include_router(entities.router)\n    app.include_router(can.router)\n    app.include_router(websocket.router)\n\n    # Initialize feature manager with dependency injection\n    feature_manager = get_feature_manager(settings=settings)\n\n    # Register feature-dependent routers conditionally\n    if feature_manager.is_enabled(\"maintenance_tracking\"):\n        app.include_router(maintenance.router)\n\n    # Setup metrics\n    setup_metrics(app)\n\n    return app\n\nasync def start_background_tasks(app: FastAPI):\n    \"\"\"Start background tasks for the application.\"\"\"\n    app.state.integrations = {}\n\n    # Initialize each configured integration\n    registry = IntegrationRegistry()\n    for integration_config in settings.integrations:\n        name = integration_config[\"type\"]\n        config = integration_config[\"config\"]\n\n        integration = registry.create_integration(name, config)\n        if integration:\n            await integration.initialize()\n            app.state.integrations[name] = integration\n            logger.info(f\"Initialized {name} integration\")\n        else:\n            logger.error(f\"Failed to create integration: {name}\")\n\n    # Initialize application state\n    app.state.app_state = AppState()\n    await app.state.app_state.initialize()\n\n    # Connect integrations to message handlers\n    for name, integration in app.state.integrations.items():\n        if name == \"can\":\n            from backend.integrations.can.processing import process_can_message\n            integration.register_message_handler(process_can_message)\n        elif name == \"ip\":\n            from backend.integrations.ip.processing import process_ip_message\n            integration.register_message_handler(process_ip_message)\n        elif name == \"bluetooth\":\n            from backend.integrations.bluetooth.processing import process_bluetooth_message\n            integration.register_message_handler(process_bluetooth_message)\n\nasync def shutdown_background_tasks(app: FastAPI):\n    \"\"\"Shutdown background tasks for the application.\"\"\"\n    for name, integration in app.state.integrations.items():\n        await integration.shutdown()\n        logger.info(f\"Shutdown {name} integration\")\n\n    # Clean up application state\n    await app.state.app_state.shutdown()\n\napp = create_app()\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    \"\"\"Run startup tasks.\"\"\"\n    await start_background_tasks(app)\n    logger.info(\"Application startup complete\")\n\n@app.on_event(\"shutdown\")\nasync def shutdown_event():\n    \"\"\"Run shutdown tasks.\"\"\"\n    await shutdown_background_tasks(app)\n    logger.info(\"Application shutdown complete\")\n</code></pre>"},{"location":"specs/refactor-backend-structure/#11-detailed-migration-plan","title":"11. Detailed Migration Plan","text":""},{"location":"specs/refactor-backend-structure/#111-expanded-file-migration-path","title":"11.1. Expanded File Migration Path","text":"<p>The following details the specific migration path for each file, with additional details on handling dependencies and refactoring considerations.</p>"},{"location":"specs/refactor-backend-structure/#common-models","title":"Common Models","text":"<ul> <li>Source: <code>src/common/models.py</code></li> <li>Target: <code>backend/models/common.py</code></li> <li>Dependencies: Minimal (Pydantic)</li> <li>Migration Steps:</li> <li>Create <code>backend/models/common.py</code></li> <li>Copy content, update imports if needed</li> <li>Verify imports continue to work in both old and new locations</li> <li>Consider adding a deprecation warning in the original file</li> </ul>"},{"location":"specs/refactor-backend-structure/#configuration","title":"Configuration","text":"<ul> <li>Source: <code>src/core_daemon/config.py</code></li> <li>Target: <code>backend/core/config.py</code></li> <li>Dependencies: Minimal</li> <li>Migration Steps:</li> <li>Create <code>backend/core/config.py</code></li> <li>Copy content, ensuring any absolute paths are updated</li> <li>Add any new configuration options for the refactored structure</li> <li>Consider compatibility for transition period</li> </ul>"},{"location":"specs/refactor-backend-structure/#metrics","title":"Metrics","text":"<ul> <li>Source: <code>src/core_daemon/metrics.py</code></li> <li>Target: <code>backend/core/metrics.py</code></li> <li>Dependencies: Minimal</li> <li>Migration Steps:</li> <li>Create <code>backend/core/metrics.py</code></li> <li>Copy content with minimal changes</li> <li>Consider enhancing with service-specific metrics</li> </ul>"},{"location":"specs/refactor-backend-structure/#rv-c-decoder","title":"RV-C Decoder","text":"<ul> <li>Source: <code>src/rvc_decoder/*</code></li> <li>Target: <code>backend/integrations/rvc/*</code></li> <li>Dependencies: <code>common.models</code></li> <li>Migration Steps:</li> <li>Create <code>backend/integrations/rvc/</code> directory</li> <li>Copy all files, updating imports to use <code>backend/models/common</code></li> <li>Create clear interface boundaries with other components</li> </ul>"},{"location":"specs/refactor-backend-structure/#domain-specific-models","title":"Domain-Specific Models","text":"<ul> <li>Source: <code>src/core_daemon/models.py</code></li> <li>Target: Multiple model files:</li> <li><code>backend/models/entities.py</code></li> <li><code>backend/models/can.py</code></li> <li><code>backend/models/github.py</code></li> <li>Dependencies: <code>common.models</code></li> <li>Migration Steps:</li> <li>Create each target file</li> <li>Carefully split models by domain</li> <li>Update imports across files for split models</li> <li>Create compatibility layer for transition period</li> </ul>"},{"location":"specs/refactor-backend-structure/#can-manager","title":"CAN Manager","text":"<ul> <li>Source: <code>src/core_daemon/can_manager.py</code></li> <li>Target: <code>backend/integrations/can/manager.py</code></li> <li>Dependencies: Several</li> <li>Migration Steps:</li> <li>Create <code>backend/integrations/can/manager.py</code></li> <li>Create <code>backend/integrations/can/interface.py</code> implementing <code>IntegrationInterface</code></li> <li>Adapt manager class to work with the new interface</li> <li>Preserve existing functionality during transition</li> </ul>"},{"location":"specs/refactor-backend-structure/#events-broker-new","title":"Events Broker (New)","text":"<ul> <li>Target: <code>backend/core/events.py</code></li> <li>Purpose: Break circular dependencies between app_state and websocket</li> <li>Implementation Steps:</li> <li>Create event broker system with publish/subscribe pattern</li> <li>Extract shared functionality from app_state and websocket</li> <li>Update both modules to use the event broker instead of direct imports</li> </ul>"},{"location":"specs/refactor-backend-structure/#application-state","title":"Application State","text":"<ul> <li>Source: <code>src/core_daemon/app_state.py</code></li> <li>Target: <code>backend/core/state.py</code></li> <li>Dependencies: Several, including circular dependency with websocket</li> <li>Migration Steps:</li> <li>Create events broker first</li> <li>Create <code>backend/core/state.py</code> with dependency on events broker</li> <li>Refactor to reduce coupling with other components</li> <li>Implement proper service interfaces</li> </ul>"},{"location":"specs/refactor-backend-structure/#websocket-handling","title":"WebSocket Handling","text":"<ul> <li>Source: <code>src/core_daemon/websocket.py</code></li> <li>Target: <code>backend/websocket/handlers.py</code></li> <li>Dependencies: Several, including circular dependency with app_state</li> <li>Migration Steps:</li> <li>Create <code>backend/websocket/handlers.py</code> using events broker</li> <li>Extract business logic to appropriate services</li> <li>Implement clear API for message broadcasting</li> </ul>"},{"location":"specs/refactor-backend-structure/#api-routers","title":"API Routers","text":"<ul> <li>Source: <code>src/core_daemon/api_routers/*.py</code></li> <li>Target: <code>backend/api/routers/*.py</code></li> <li>Dependencies: Many</li> <li>Migration Steps:</li> <li>Create service modules first</li> <li>Extract business logic from routers to services</li> <li>Create new router files with slimmer implementation</li> <li>Ensure backward compatibility during transition</li> </ul>"},{"location":"specs/refactor-backend-structure/#feature-manager-service","title":"Feature Manager Service","text":"<ul> <li>Source: <code>src/core_daemon/feature_manager.py</code>, <code>src/core_daemon/feature_base.py</code></li> <li>Target: <code>backend/services/feature_manager.py</code>, <code>backend/services/feature_base.py</code></li> <li>Dependencies: Core, Events Broker, Settings</li> <li>Migration Steps:</li> <li>Create <code>backend/services/feature_base.py</code> with enhanced <code>Feature</code> base class:<ul> <li>Add dependency management between features</li> <li>Improve type safety and async support</li> <li>Maintain health reporting capabilities</li> <li>Add proper documentation for overridable methods</li> <li>Implement standardized health status reporting</li> </ul> </li> <li>Create <code>backend/services/feature_manager.py</code> as a proper service class:<ul> <li>Implement <code>FeatureManager</code> class with dependency injection support</li> <li>Add methods for feature flag checking (<code>is_enabled</code>)</li> <li>Add enhanced methods for feature querying and management</li> <li>Implement topological sorting for dependency resolution</li> <li>Integrate with the events system for feature state changes</li> <li>Connect feature flags to application settings</li> <li>Maintain existing feature registration and lifecycle management</li> </ul> </li> <li>Create FastAPI dependency function for service injection</li> <li>Implement integration with settings system for feature flags</li> <li>Update references to use the new service-based API</li> <li>Add example modules like maintenance tracking that use the feature flag system</li> </ul>"},{"location":"specs/refactor-backend-structure/#middleware","title":"Middleware","text":"<ul> <li>Source: <code>src/core_daemon/middleware.py</code></li> <li>Target: <code>backend/middleware/http.py</code></li> <li>Dependencies: Metrics</li> <li>Migration Steps:</li> <li>Create <code>backend/middleware/http.py</code></li> <li>Update imports for metrics</li> <li>Consider adding other middleware modules as needed</li> </ul>"},{"location":"specs/refactor-backend-structure/#main-application","title":"Main Application","text":"<ul> <li>Source: <code>src/core_daemon/main.py</code></li> <li>Target: <code>backend/main.py</code></li> <li>Dependencies: All components</li> <li>Migration Steps:</li> <li>Create new main.py after other modules are migrated</li> <li>Implement cleaner initialization logic</li> <li>Add support for integration registry</li> <li>Add feature flag checks for optional routers</li> <li>Implement robust startup/shutdown procedures</li> </ul>"},{"location":"specs/refactor-backend-structure/#112-dependency-resolution-strategy","title":"11.2. Dependency Resolution Strategy","text":"<p>To handle complex dependencies, the following strategies will be used:</p> <ol> <li>Bottom-Up Migration: Start with least dependent files</li> <li>Interface Abstraction: Create clean interfaces between components</li> <li>Events Broker: Implement publish/subscribe patterns for cross-component communication</li> <li>Service Layer: Extract business logic into dedicated services</li> <li>Dependency Injection: Use FastAPI's dependency system where appropriate</li> <li>Staged Deployment: Maintain compatibility during transition period</li> </ol>"},{"location":"specs/refactor-backend-structure/#12-updated-execution-checklist","title":"12. Updated Execution Checklist","text":""},{"location":"specs/refactor-backend-structure/#121-preparation-phase-week-1","title":"12.1. Preparation Phase (Week 1)","text":"<ul> <li>[ ] Create the new directory structure</li> <li>[ ] Create interface definitions in <code>backend/integrations/interfaces.py</code></li> <li>[ ] Create events broker in <code>backend/core/events.py</code></li> <li>[ ] Set up comprehensive testing plan</li> <li>[ ] Document migration strategy for the team</li> <li>[ ] Create compatibility layer plan</li> <li>[ ] Develop rollback procedures</li> </ul>"},{"location":"specs/refactor-backend-structure/#122-foundation-phase-week-1-2","title":"12.2. Foundation Phase (Week 1-2)","text":"<ul> <li>[ ] Migrate core foundational modules:</li> <li>[ ] <code>src/common/models.py</code> \u2192 <code>backend/models/common.py</code></li> <li>[ ] <code>src/core_daemon/config.py</code> \u2192 <code>backend/core/config.py</code></li> <li>[ ] <code>src/core_daemon/metrics.py</code> \u2192 <code>backend/core/metrics.py</code></li> <li>[ ] Create integration interfaces for CAN, IP, and Bluetooth</li> <li>[ ] Create integration factory and registry</li> <li>[ ] Migrate <code>src/rvc_decoder/*</code> \u2192 <code>backend/integrations/rvc/*</code></li> <li>[ ] Create tests for all migrated modules</li> </ul>"},{"location":"specs/refactor-backend-structure/#123-core-components-phase-week-2-3","title":"12.3. Core Components Phase (Week 2-3)","text":"<ul> <li>[x] Split domain-specific models:</li> <li>[x] Create <code>backend/models/entities.py</code>, <code>backend/models/can.py</code>, etc.</li> <li>[x] Update imports in dependent files</li> <li>[x] Create compatibility imports</li> <li>[x] Migrate middleware:</li> <li>[x] <code>src/core_daemon/middleware.py</code> \u2192 <code>backend/middleware/http.py</code></li> <li>[x] Migrate CAN integration:</li> <li>[x] <code>src/core_daemon/can_manager.py</code> \u2192 <code>backend/integrations/can/manager.py</code></li> <li>[x] Create <code>backend/integrations/can/interface.py</code> implementing <code>IntegrationInterface</code></li> <li>[x] Create initial service layer:</li> <li>[x] <code>backend/services/entity_service.py</code></li> <li>[x] <code>backend/services/can_service.py</code></li> <li>[x] Create enhanced feature management:</li> <li>[x] Create <code>backend/services/feature_base.py</code> with improved Feature base class</li> <li>[x] Create <code>backend/services/feature_manager.py</code> with FeatureManager service class</li> <li>[x] Add <code>backend/services/feature_flags.yaml</code> for config-driven feature definitions</li> <li>[x] Require all feature logic and registration to use the new FeatureManager/Feature/YAML pattern</li> <li>[x] Remove legacy feature flag code and update all imports to use new backend module paths</li> <li>[x] Update documentation and OpenAPI specs to reflect feature-conditional endpoints</li> <li>[x] Add feature dependency resolution logic</li> <li>[x] Create tests for all migrated components (to be expanded in later phases)</li> </ul> <p>Phase 2 complete: All core service skeletons, feature management, and migration to the new backend structure are done. Proceed to Phase 3 for state, API, and integration migration.</p>"},{"location":"specs/refactor-backend-structure/#124-state-and-api-phase-week-3-4","title":"12.4. State and API Phase (Week 3-4)","text":"<ul> <li>[ ] Migrate state management:</li> <li>[ ] <code>src/core_daemon/app_state.py</code> \u2192 <code>backend/core/state.py</code></li> <li>[ ] Integrate with events broker</li> <li>[ ] Extract service methods to appropriate services</li> <li>[ ] Migrate WebSocket handling:</li> <li>[ ] <code>src/core_daemon/websocket.py</code> \u2192 <code>backend/websocket/handlers.py</code></li> <li>[ ] Integrate with events broker</li> <li>[ ] Migrate API routers:</li> <li>[ ] Extract business logic to services</li> <li>[ ] Create new router files with service dependencies</li> <li>[ ] Ensure backward compatibility</li> <li>[ ] Migrate feature management:</li> <li>[ ] <code>src/core_daemon/feature_manager.py</code> \u2192 <code>backend/services/feature_manager.py</code></li> <li>[ ] Create tests for all migrated components</li> </ul>"},{"location":"specs/refactor-backend-structure/#125-main-application-phase-week-4-5","title":"12.5. Main Application Phase (Week 4-5)","text":"<ul> <li>[ ] Create new main application:</li> <li>[ ] <code>backend/main.py</code> with clean initialization</li> <li>[ ] Configure router registration based on features</li> <li>[ ] Implement integration registration</li> <li>[ ] Setup startup/shutdown procedures</li> <li>[ ] Run full integration tests</li> <li>[ ] Create comprehensive documentation</li> <li>[ ] Validate backward compatibility</li> </ul>"},{"location":"specs/refactor-backend-structure/#126-new-features-phase-week-5","title":"12.6. New Features Phase (Week 5+)","text":"<ul> <li>[ ] Develop coach maintenance tracking:</li> <li>[ ] Create models, services, and API endpoints</li> <li>[ ] Integrate with existing state management</li> <li>[ ] Add feature flag for enabling/disabling</li> <li>[ ] Implement IP device integration:</li> <li>[ ] Create concrete implementation of <code>IntegrationInterface</code></li> <li>[ ] Develop device discovery and messaging</li> <li>[ ] Implement Bluetooth integration:</li> <li>[ ] Create concrete implementation of <code>IntegrationInterface</code></li> <li>[ ] Develop device scanning and communication</li> </ul>"},{"location":"specs/refactor-backend-structure/#127-transition-and-cleanup-ongoing","title":"12.7. Transition and Cleanup (Ongoing)","text":"<ul> <li>[ ] Update imports across codebase to use new modules</li> <li>[ ] Remove compatibility layers once no longer needed</li> <li>[ ] Deprecate old code paths with clear warnings</li> <li>[ ] Update testing infrastructure</li> <li>[ ] Update CI/CD pipelines</li> <li>[ ] Update documentation to reflect new architecture</li> </ul>"},{"location":"specs/refactor-backend-structure/#13-conclusion-and-technical-benefits","title":"13. Conclusion and Technical Benefits","text":"<p>This refactoring will lead to several key technical improvements:</p> <ol> <li>Modularity: Clear separation of concerns makes the codebase easier to understand and modify</li> <li>Extensibility: New integrations and features can be added without modifying existing code</li> <li>Testability: Clearer interfaces make it easier to write isolated unit tests</li> <li>Maintainability: Business logic in services is easier to understand and maintain</li> <li>Scalability: Components can be improved independently as needs evolve</li> <li>Developer Experience: Clearer structure makes onboarding and development more efficient</li> </ol> <p>By focusing on clean interfaces, dependency injection, and service-oriented patterns, this refactoring lays the groundwork for future feature development while improving the quality and maintainability of the codebase.</p>"},{"location":"specs/refactor-backend-structure/#14-feature-management-best-practices","title":"14. Feature Management Best Practices","text":"<p>Based on research into modern FastAPI feature management patterns, the refactoring will incorporate the following best practices:</p>"},{"location":"specs/refactor-backend-structure/#141-feature-flag-architecture","title":"14.1. Feature Flag Architecture","text":"<ul> <li>Service-Based Pattern: Implement feature management as a dedicated service with dependency injection</li> <li>Feature Classes: Use an enhanced base class with clear lifecycle methods and health reporting</li> <li>Dependency Management: Explicitly declare dependencies between features</li> <li>Async Support: Ensure non-blocking, async-aware implementation throughout</li> </ul>"},{"location":"specs/refactor-backend-structure/#142-feature-flag-implementation","title":"14.2. Feature Flag Implementation","text":"<pre><code># Example of the enhanced feature manager service\nfrom typing import Dict, Any, Optional, List\n\nclass Feature:\n    def __init__(\n        self,\n        name: str,\n        enabled: bool = False,\n        core: bool = False,\n        config: Optional[Dict[str, Any]] = None,\n        dependencies: Optional[List[str]] = None,\n    ) -&gt; None:\n        self.name = name\n        self.enabled = enabled\n        self.core = core\n        self.config = config or {}\n        self.dependencies = dependencies or []\n\n    async def startup(self) -&gt; None:\n        \"\"\"Called when the feature is started.\"\"\"\n        pass\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Called when the feature is stopped.\"\"\"\n        pass\n\n    @property\n    def health(self) -&gt; str:\n        \"\"\"Report health status.\"\"\"\n        return \"unknown\"\n\nclass FeatureManager:\n    def __init__(self):\n        self._features = {}\n\n    def register_feature(self, feature: Feature) -&gt; None:\n        self._features[feature.name] = feature\n\n    def is_enabled(self, feature_name: str) -&gt; bool:\n        feature = self._features.get(feature_name)\n        return feature is not None and feature.enabled\n\n    async def startup(self) -&gt; None:\n        \"\"\"Start all enabled features in dependency order.\"\"\"\n        for feature in self._get_ordered_features():\n            if feature.enabled:\n                await feature.startup()\n</code></pre>"},{"location":"specs/refactor-backend-structure/#143-usage-in-fastapi-endpoints","title":"14.3. Usage in FastAPI Endpoints","text":"<p>Best practices for using feature flags in the API layer:</p> <pre><code># Example router with feature flag check\nfrom fastapi import APIRouter, Depends, HTTPException\n\nfrom backend.services.feature_manager import FeatureManager, get_feature_manager\n\nrouter = APIRouter()\n\n@router.get(\"/maintenance/status\")\nasync def get_maintenance_status(\n    feature_manager: FeatureManager = Depends(get_feature_manager),\n):\n    \"\"\"Get maintenance system status.\"\"\"\n    if not feature_manager.is_enabled(\"maintenance_tracking\"):\n        raise HTTPException(status_code=404, detail=\"Maintenance tracking not enabled\")\n\n    # Continue with maintenance status logic\n    return {\"status\": \"operational\"}\n</code></pre>"},{"location":"specs/refactor-backend-structure/#144-integration-with-settings-and-configuration","title":"14.4. Integration with Settings and Configuration","text":"<p>The feature manager will integrate with the application's settings system to allow: - Environment variable-based feature enabling/disabling - Configuration file-based feature settings - Per-environment feature profiles</p>"},{"location":"specs/refactor-backend-structure/#145-feature-health-monitoring","title":"14.5. Feature Health Monitoring","text":"<p>Features will report health status through the enhanced health check endpoint: - Each feature provides its own health status - System aggregates feature health for overall status - Unhealthy features are highlighted in monitoring</p>"},{"location":"specs/refactor-backend-structure/#15-references","title":"15. References","text":"<ul> <li>FastAPI Project Structure</li> <li>Python Application Layouts</li> <li>Clean Architecture in Python</li> <li>Dependency Injection in FastAPI</li> <li>Feature Flag Best Practices</li> <li>Feature-Driven FastAPI Services</li> <li>Current <code>docs/architecture/backend.md</code> documentation</li> <li>Event-Driven Architecture Patterns</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/","title":"Refactor Web UI to Standalone React App","text":""},{"location":"specs/refactor-web-ui-to-react/#1-refactoring-objective","title":"1. Refactoring Objective","text":""},{"location":"specs/refactor-web-ui-to-react/#11-purpose","title":"1.1. Purpose","text":"<ul> <li>Decouple the web UI from the FastAPI backend, enabling independent development and deployment.</li> <li>Modernize the frontend using React (with Vite for tooling), improving maintainability, scalability, and developer experience.</li> <li>Prepare for future enhancements (e.g., richer UI, real-time features, easier testing).</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#12-scope","title":"1.2. Scope","text":"<ul> <li>Affected: <code>src/core_daemon/web_ui/</code> (all templates, static assets, and related backend integration), API endpoints serving UI assets.</li> <li>Unchanged: Backend API logic, WebSocket endpoints, business logic, and backend models/services.</li> <li>Boundaries: Only the UI layer and its integration with the backend; no changes to core API or backend state management.</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#2-current-state-analysis","title":"2. Current State Analysis","text":""},{"location":"specs/refactor-web-ui-to-react/#21-code-structure","title":"2.1. Code Structure","text":"<ul> <li>Check in with context7 before starting to refactor to ensure we use the latest recommended practices for use with the languages being proposed.</li> <li>UI is implemented as Jinja2 templates in <code>src/core_daemon/web_ui/templates/</code> and static files in <code>src/core_daemon/web_ui/static/</code>.</li> <li>Served directly by FastAPI backend.</li> <li>Tightly coupled: UI changes require backend restarts; limited frontend tooling.</li> <li>Pain points: Difficult to modernize, limited interactivity, slow iteration, hard to test UI in isolation.</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#22-code-quality-concerns","title":"2.2. Code Quality Concerns","text":"<ul> <li>Technical debt: Outdated template-based UI, minimal JS/CSS modularity.</li> <li>Patterns: No componentization, limited state management, no frontend build pipeline.</li> <li>Inconsistencies: UI/UX drift, hard to maintain styles/scripts.</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#23-test-coverage","title":"2.3. Test Coverage","text":"<ul> <li>Minimal automated UI testing; backend tests focus on API.</li> <li>No frontend unit/integration tests.</li> <li>Refactoring will require new test strategy for React components.</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#3-refactoring-plan","title":"3. Refactoring Plan","text":""},{"location":"specs/refactor-web-ui-to-react/#31-architectural-changes","title":"3.1. Architectural Changes","text":"<ul> <li>Scaffold a new React app (using Vite) in a new <code>web_ui/</code> directory at the project root.</li> <li>UI will communicate with backend via REST/WebSocket APIs (no backend modernization or FastAPI changes in this phase).</li> <li>Decouple static asset serving from FastAPI completely - FastAPI will provide API services only.</li> <li>The React frontend will be served directly by Caddy (which already reverse-proxies the FastAPI service).</li> <li>Design goal: Create a beautiful, modern UI using curved lines, contemporary themes, and visually appealing layouts. Leverage modern CSS frameworks (e.g., Tailwind CSS, Material UI) to ensure a polished, user-friendly experience.</li> <li>Ignore authentication and backend modernization for this phase; these will be handled separately.</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#32-code-structure-changes","title":"3.2. Code Structure Changes","text":"<ul> <li>Create <code>web_ui/</code> at project root: contains all React source, assets, and build config.</li> <li>Remove or archive <code>src/core_daemon/web_ui/</code>.</li> <li>Update backend to serve built frontend (optional: only in production; no backend code changes in this phase).</li> <li>Update all relevant <code>.nix</code> files in the project root (e.g., <code>flake.nix</code>, <code>devshell.nix</code>) to include Node.js, frontend build tools, and React app development dependencies for a unified dev environment.</li> <li>Update <code>pyproject.toml</code> as appropriate to reflect any changes in backend/frontend integration or developer workflow (but do not change backend logic).</li> <li>Use modern naming conventions (PascalCase for components, camelCase for variables).</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#33-interface-changes","title":"3.3. Interface Changes","text":"<ul> <li>Public API endpoints remain unchanged.</li> <li>UI endpoints (HTML pages) will be replaced by static file serving.</li> <li>Backward compatibility: maintain API contract; document UI migration.</li> <li>Deprecate old template routes with clear warnings (no backend code changes in this phase).</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#34-testing-strategy","title":"3.4. Testing Strategy","text":"<ul> <li>Add unit and integration tests for React components (Jest, React Testing Library).</li> <li>Manual and automated E2E tests for critical UI flows.</li> <li>Backend tests and authentication will be addressed in a separate phase.</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#4-implementation-strategy","title":"4. Implementation Strategy","text":""},{"location":"specs/refactor-web-ui-to-react/#41-phased-approach","title":"4.1. Phased Approach","text":"<ul> <li>Phase 1: Scaffold React app, set up Vite, basic routing, and API integration.</li> <li>Phase 2: Migrate core UI features (dashboard, device views, etc.).</li> <li>Phase 3: Remove/disable old templates; update backend static serving.</li> <li>Phase 4: Add tests, update docs, finalize migration.</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#42-risk-mitigation","title":"4.2. Risk Mitigation","text":"<ul> <li>Risks: API drift, deployment misconfiguration, user confusion.</li> <li>Mitigation: Maintain API contract, dual-serve old/new UI during transition, clear migration docs.</li> <li>Fallback: Re-enable old templates if needed.</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#43-validation-checkpoints","title":"4.3. Validation Checkpoints","text":"<ul> <li>Each phase: run backend and frontend tests, verify UI functionality, check API compatibility.</li> <li>Metrics: UI feature parity, test pass rate, user feedback.</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#5-code-migration-guide","title":"5. Code Migration Guide","text":""},{"location":"specs/refactor-web-ui-to-react/#51-old-vs-new-patterns","title":"5.1. Old vs. New Patterns","text":"<ul> <li>BEFORE: Jinja2 templates, static JS/CSS, backend-coupled rendering.</li> <li>AFTER: React components, modular JS/CSS, API-driven UI, independent dev server.</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#52-deprecation-path","title":"5.2. Deprecation Path","text":"<ul> <li>Mark old template routes as deprecated in backend.</li> <li>Timeline: Remove after 1-2 releases.</li> <li>Provide migration guide in docs.</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#6-documentation-updates","title":"6. Documentation Updates","text":""},{"location":"specs/refactor-web-ui-to-react/#61-code-documentation","title":"6.1. Code Documentation","text":"<ul> <li>Update backend docstrings for UI endpoints.</li> <li>Add README to <code>web_ui/</code> with setup/dev instructions.</li> <li>Update architecture docs to reflect new UI structure.</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#62-user-documentation","title":"6.2. User Documentation","text":"<ul> <li>Update user-facing docs to reference new UI.</li> <li>Communicate API stability and UI migration path.</li> <li>Provide troubleshooting and migration guides.</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#7-execution-checklist","title":"7. Execution Checklist","text":""},{"location":"specs/refactor-web-ui-to-react/#71-preparation","title":"7.1. Preparation","text":"<ul> <li>[x] Analyze current code structure</li> <li>[x] Create test cases for critical functionality</li> <li>[x] Document current behavior</li> <li>[x] Create backup branch</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#72-implementation","title":"7.2. Implementation","text":"<ul> <li>[ ] Create new React app structure</li> <li>[ ] Implement core UI features</li> <li>[ ] Update backend static serving</li> <li>[ ] Update tests</li> <li>[ ] Update documentation</li> <li>[ ] Create deprecation notices</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#73-validation","title":"7.3. Validation","text":"<ul> <li>[ ] Run all tests</li> <li>[ ] Verify UI feature parity</li> <li>[ ] Validate API compatibility</li> <li>[ ] Review code quality</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#74-deployment","title":"7.4. Deployment","text":"<ul> <li>[ ] Create release plan</li> <li>[ ] Update changelog</li> <li>[ ] Communicate changes to users</li> <li>[ ] Monitor for issues</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#8-references","title":"8. References","text":""},{"location":"specs/refactor-web-ui-to-react/#81-design-patterns","title":"8.1. Design Patterns","text":"<ul> <li>React component architecture</li> <li>API-driven UI</li> <li>Vite for fast frontend tooling</li> <li>See: https://vitejs.dev/guide/</li> </ul>"},{"location":"specs/refactor-web-ui-to-react/#82-best-practices","title":"8.2. Best Practices","text":"<ul> <li>Python/JS code separation</li> <li>REST/WebSocket API contracts</li> <li>Modern frontend testing (Jest, React Testing Library)</li> <li>See: https://react.dev/learn, https://testing-library.com/docs/react-testing-library/intro/</li> </ul>"},{"location":"specs/spec-aware-decoder/","title":"Spec-Aware Decoder: Live RV-C Definition and Validation via FAISS","text":""},{"location":"specs/spec-aware-decoder/#1-objective","title":"1. Objective","text":""},{"location":"specs/spec-aware-decoder/#11-purpose","title":"1.1. Purpose","text":"<ul> <li>Automatically identify and suggest decoder structures for unknown DGNs observed on the CANbus.</li> <li>Validate and improve existing <code>rvc.json</code> entries against the official RV-C spec (via semantic embedding).</li> <li>Enable faster, more accurate development of coach-specific decoder mappings.</li> </ul>"},{"location":"specs/spec-aware-decoder/#12-scope","title":"1.2. Scope","text":"<ul> <li>Affected: <code>rvc.json</code>, FastAPI backend, decoder engine, UI (developer panel).</li> <li>Unchanged: CANbus reader, core FastAPI routing, spec chunking/indexing.</li> <li>Boundaries: This feature reads FAISS index and logs or suggests decoder changes \u2014 it does not automatically update persistent files.</li> </ul>"},{"location":"specs/spec-aware-decoder/#2-current-state-analysis","title":"2. Current State Analysis","text":""},{"location":"specs/spec-aware-decoder/#21-decoder-structure","title":"2.1. Decoder Structure","text":"<ul> <li><code>rvc.json</code> contains hard-coded decoder definitions keyed by DGN ID.</li> <li>Unknown DGNs are either dropped or logged with no semantic analysis.</li> <li>Validation of existing entries requires manual review of PDF spec.</li> </ul>"},{"location":"specs/spec-aware-decoder/#22-limitations","title":"2.2. Limitations","text":"<ul> <li>Unknown DGNs require manual research and YAML entry.</li> <li>No mechanism to detect stale, inaccurate, or incomplete <code>rvc.json</code> entries.</li> <li>Missed opportunity to leverage the existing FAISS spec embedding index.</li> </ul>"},{"location":"specs/spec-aware-decoder/#3-functional-design","title":"3. Functional Design","text":""},{"location":"specs/spec-aware-decoder/#31-runtime-decoder-pipeline-enhancements","title":"3.1. Runtime Decoder Pipeline Enhancements","text":"<ul> <li>For each CAN message:</li> <li>If DGN is unknown:<ul> <li>Query FAISS for spec chunk</li> <li>Suggest decoder structure in UI/API</li> </ul> </li> <li>If DGN is known:<ul> <li>Query FAISS</li> <li>Compare structure to <code>rvc.json</code></li> <li>Log or expose mismatches</li> </ul> </li> </ul>"},{"location":"specs/spec-aware-decoder/#32-suggested-decoder-structure-output","title":"3.2. Suggested Decoder Structure Output","text":"<ul> <li>Section title and text from spec</li> <li>Proposed JSON structure with field names, types, and units</li> <li>Optional UI copy-paste block</li> </ul>"},{"location":"specs/spec-aware-decoder/#33-mismatch-detection","title":"3.3. Mismatch Detection","text":"<ul> <li>Field-level diff between <code>rvc.json</code> and spec:</li> <li>Missing bytes</li> <li>Name differences</li> <li>Byte offset misalignment</li> <li>Displayed in a validation panel in UI or exposed via:   <pre><code>GET /spec/mismatches\n</code></pre></li> </ul>"},{"location":"specs/spec-aware-decoder/#4-implementation-strategy","title":"4. Implementation Strategy","text":""},{"location":"specs/spec-aware-decoder/#41-modules-and-interfaces","title":"4.1. Modules and Interfaces","text":"<ul> <li><code>seen_dgn_cache.py</code>: In-memory (or persistent) cache of unknown DGNs + suggestions</li> <li><code>validate_dgn_fields.py</code>: Validator for known DGNs</li> <li><code>GET /spec/unrecognized</code>: List of undefined DGNs + spec matches</li> <li><code>GET /spec/mismatches</code>: List of mismatched DGN validations</li> <li>UI: \u201cNew DGNs\u201d panel for spec-based decoder suggestions</li> <li>UI: \u201cDecoder Conflicts\u201d panel for existing entry validation</li> </ul>"},{"location":"specs/spec-aware-decoder/#42-ui-enhancements","title":"4.2. UI Enhancements","text":"<ul> <li>\u201cNew DGNs\u201d panel for spec-based decoder suggestions</li> <li>\u201cDecoder Conflicts\u201d panel for existing entry validation</li> </ul>"},{"location":"specs/spec-aware-decoder/#5-testing-strategy","title":"5. Testing Strategy","text":"<ul> <li>Unit tests for suggestion and validation logic</li> <li>Mocked FAISS index queries with synthetic DGN inputs</li> <li>UI tests to validate developer panels render expected output</li> <li>Optional golden test set comparing <code>rvc.json</code> against fixed FAISS chunks</li> </ul>"},{"location":"specs/spec-aware-decoder/#6-documentation-updates","title":"6. Documentation Updates","text":"<ul> <li>Update <code>rvc.json</code> format documentation to include <code>\"proposed\": true</code> and <code>\"source\": \"faiss\"</code> fields.</li> <li>Add dev guide for running decoder validator tools.</li> <li>Include reference to <code>validate_rvc_json.py</code> and <code>/spec/mismatches</code> endpoint.</li> </ul>"},{"location":"specs/spec-aware-decoder/#7-execution-checklist","title":"7. Execution Checklist","text":""},{"location":"specs/spec-aware-decoder/#71-api-and-decoder-engine","title":"7.1. API and Decoder Engine","text":"<ul> <li>[ ] Add runtime DGN hook for unknown DGN capture</li> <li>[ ] Implement FAISS lookup for unknown DGN</li> <li>[ ] Build <code>seen_dgn_cache</code> structure</li> <li>[ ] Build validation function for existing DGN entries</li> <li>[ ] Add FastAPI endpoints</li> </ul>"},{"location":"specs/spec-aware-decoder/#72-ui-integration","title":"7.2. UI Integration","text":"<ul> <li>[ ] Add \u201cNew DGNs\u201d panel</li> <li>[ ] Add \u201cDecoder Conflicts\u201d panel</li> </ul>"},{"location":"specs/spec-aware-decoder/#73-developer-tooling","title":"7.3. Developer Tooling","text":"<ul> <li>[ ] Integrate <code>validate_rvc_json.py</code> into dev workflow</li> <li>[ ] Add support for exporting proposed decoders</li> </ul>"},{"location":"specs/spec-aware-decoder/#8-future-enhancements","title":"8. Future Enhancements","text":"<ul> <li>Allow user confirmation of decoder suggestions via UI</li> <li>Auto-generate pull requests for <code>rvc.json</code> updates</li> <li>Add similarity confidence scoring to UI</li> <li>Periodic batch re-validation of all DGNs</li> </ul>"},{"location":"specs/spec-aware-decoder/#9-references","title":"9. References","text":"<ul> <li>LangChain FAISS integration</li> <li>[RV-C Specification PDF, 2023 Edition]</li> <li>[<code>generate_embeddings.py</code> / <code>generate_faiss_index.py</code> scripts]</li> <li>[Existing spec: Refactor Web UI to Standalone React App]</li> </ul>"}]}